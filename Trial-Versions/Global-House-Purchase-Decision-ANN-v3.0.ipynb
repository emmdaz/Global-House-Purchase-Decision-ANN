{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras import regularizers, models, layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `wandb.require('core')` is a no-op as it is now the default behavior.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import optuna\n",
    "\n",
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "\n",
    "wandb.require(\"core\")\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>property_type</th>\n",
       "      <th>furnishing_status</th>\n",
       "      <th>property_size_sqft</th>\n",
       "      <th>price</th>\n",
       "      <th>constructed_year</th>\n",
       "      <th>previous_owners</th>\n",
       "      <th>rooms</th>\n",
       "      <th>...</th>\n",
       "      <th>customer_salary</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_tenure_years</th>\n",
       "      <th>monthly_expenses</th>\n",
       "      <th>down_payment</th>\n",
       "      <th>emi_to_income_ratio</th>\n",
       "      <th>satisfaction_score</th>\n",
       "      <th>neighbourhood_rating</th>\n",
       "      <th>connectivity_score</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>France</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>Farmhouse</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>991</td>\n",
       "      <td>412935</td>\n",
       "      <td>1989</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>10745</td>\n",
       "      <td>193949</td>\n",
       "      <td>15</td>\n",
       "      <td>6545</td>\n",
       "      <td>218986</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Cape Town</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>1244</td>\n",
       "      <td>224538</td>\n",
       "      <td>1990</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>16970</td>\n",
       "      <td>181465</td>\n",
       "      <td>20</td>\n",
       "      <td>8605</td>\n",
       "      <td>43073</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Johannesburg</td>\n",
       "      <td>Farmhouse</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>4152</td>\n",
       "      <td>745104</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>21914</td>\n",
       "      <td>307953</td>\n",
       "      <td>30</td>\n",
       "      <td>2510</td>\n",
       "      <td>437151</td>\n",
       "      <td>0.09</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>Farmhouse</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>3714</td>\n",
       "      <td>1110959</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>17980</td>\n",
       "      <td>674720</td>\n",
       "      <td>15</td>\n",
       "      <td>8805</td>\n",
       "      <td>436239</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Johannesburg</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>Fully-Furnished</td>\n",
       "      <td>531</td>\n",
       "      <td>99041</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>17676</td>\n",
       "      <td>65833</td>\n",
       "      <td>25</td>\n",
       "      <td>8965</td>\n",
       "      <td>33208</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   property_id       country          city property_type furnishing_status  \\\n",
       "0            1        France     Marseille     Farmhouse    Semi-Furnished   \n",
       "1            2  South Africa     Cape Town     Apartment    Semi-Furnished   \n",
       "2            3  South Africa  Johannesburg     Farmhouse    Semi-Furnished   \n",
       "3            4       Germany     Frankfurt     Farmhouse    Semi-Furnished   \n",
       "4            5  South Africa  Johannesburg     Townhouse   Fully-Furnished   \n",
       "\n",
       "   property_size_sqft    price  constructed_year  previous_owners  rooms  ...  \\\n",
       "0                 991   412935              1989                6      6  ...   \n",
       "1                1244   224538              1990                4      8  ...   \n",
       "2                4152   745104              2019                5      2  ...   \n",
       "3                3714  1110959              2008                1      3  ...   \n",
       "4                 531    99041              2007                6      3  ...   \n",
       "\n",
       "   customer_salary  loan_amount  loan_tenure_years  monthly_expenses  \\\n",
       "0            10745       193949                 15              6545   \n",
       "1            16970       181465                 20              8605   \n",
       "2            21914       307953                 30              2510   \n",
       "3            17980       674720                 15              8805   \n",
       "4            17676        65833                 25              8965   \n",
       "\n",
       "   down_payment  emi_to_income_ratio  satisfaction_score  \\\n",
       "0        218986                 0.16                   1   \n",
       "1         43073                 0.08                   9   \n",
       "2        437151                 0.09                   6   \n",
       "3        436239                 0.33                   2   \n",
       "4         33208                 0.03                   3   \n",
       "\n",
       "   neighbourhood_rating  connectivity_score  decision  \n",
       "0                     5                   6         0  \n",
       "1                     1                   2         0  \n",
       "2                     8                   1         0  \n",
       "3                     6                   6         0  \n",
       "4                     3                   4         0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de los datos\n",
    "\n",
    "ds = pd.read_csv(\"/global_house_purchase_dataset.csv\")\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values: \n",
      " \n",
      "  property_id                0\n",
      "country                    0\n",
      "city                       0\n",
      "property_type              0\n",
      "furnishing_status          0\n",
      "property_size_sqft         0\n",
      "price                      0\n",
      "constructed_year           0\n",
      "previous_owners            0\n",
      "rooms                      0\n",
      "bathrooms                  0\n",
      "garage                     0\n",
      "garden                     0\n",
      "crime_cases_reported       0\n",
      "legal_cases_on_property    0\n",
      "customer_salary            0\n",
      "loan_amount                0\n",
      "loan_tenure_years          0\n",
      "monthly_expenses           0\n",
      "down_payment               0\n",
      "emi_to_income_ratio        0\n",
      "satisfaction_score         0\n",
      "neighbourhood_rating       0\n",
      "connectivity_score         0\n",
      "decision                   0\n",
      "dtype: int64 \n",
      " \n",
      " Types: \n",
      " \n",
      " property_id                  int64\n",
      "country                     object\n",
      "city                        object\n",
      "property_type               object\n",
      "furnishing_status           object\n",
      "property_size_sqft           int64\n",
      "price                        int64\n",
      "constructed_year             int64\n",
      "previous_owners              int64\n",
      "rooms                        int64\n",
      "bathrooms                    int64\n",
      "garage                       int64\n",
      "garden                       int64\n",
      "crime_cases_reported         int64\n",
      "legal_cases_on_property      int64\n",
      "customer_salary              int64\n",
      "loan_amount                  int64\n",
      "loan_tenure_years            int64\n",
      "monthly_expenses             int64\n",
      "down_payment                 int64\n",
      "emi_to_income_ratio        float64\n",
      "satisfaction_score           int64\n",
      "neighbourhood_rating         int64\n",
      "connectivity_score           int64\n",
      "decision                     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN values: \\n \\n \", ds.isna().sum(),\n",
    "      \"\\n \\n Types: \\n \\n\", ds.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize = (10,10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "sns.countplot(ds, x = \"country\", color = \"purple\", ax = axes[0])\n",
    "axes[0].tick_params(axis=\"x\", rotation=90)\n",
    "axes[0].set_title(\"country\")\n",
    "\n",
    "sns.countplot(ds, x = \"city\", color = \"grey\", ax = axes[1])\n",
    "axes[1].tick_params(rotation = 90)\n",
    "axes[1].set_title(\"city\")\n",
    "\n",
    "sns.countplot(ds, x = \"property_type\", color = \"orange\", ax = axes[2])\n",
    "axes[2].tick_params(rotation = 90)\n",
    "axes[2].set_title(\"property_type\")\n",
    "\n",
    "sns.countplot(ds, x = \"furnishing_status\", color = \"green\", ax = axes[3])\n",
    "axes[3].tick_params(rotation = 90)\n",
    "axes[3].set_title(\"furnishing_status\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_size_sqft</th>\n",
       "      <th>price</th>\n",
       "      <th>constructed_year</th>\n",
       "      <th>previous_owners</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>garage</th>\n",
       "      <th>garden</th>\n",
       "      <th>crime_cases_reported</th>\n",
       "      <th>legal_cases_on_property</th>\n",
       "      <th>...</th>\n",
       "      <th>city_Vancouver</th>\n",
       "      <th>property_type_Apartment</th>\n",
       "      <th>property_type_Farmhouse</th>\n",
       "      <th>property_type_Independent House</th>\n",
       "      <th>property_type_Studio</th>\n",
       "      <th>property_type_Townhouse</th>\n",
       "      <th>property_type_Villa</th>\n",
       "      <th>furnishing_status_Fully-Furnished</th>\n",
       "      <th>furnishing_status_Semi-Furnished</th>\n",
       "      <th>furnishing_status_Unfurnished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>991.0</td>\n",
       "      <td>412935.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244.0</td>\n",
       "      <td>224538.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4152.0</td>\n",
       "      <td>745104.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3714.0</td>\n",
       "      <td>1110959.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>531.0</td>\n",
       "      <td>99041.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   property_size_sqft      price  constructed_year  previous_owners  rooms  \\\n",
       "0               991.0   412935.0            1989.0              6.0    6.0   \n",
       "1              1244.0   224538.0            1990.0              4.0    8.0   \n",
       "2              4152.0   745104.0            2019.0              5.0    2.0   \n",
       "3              3714.0  1110959.0            2008.0              1.0    3.0   \n",
       "4               531.0    99041.0            2007.0              6.0    3.0   \n",
       "\n",
       "   bathrooms  garage  garden  crime_cases_reported  legal_cases_on_property  \\\n",
       "0        2.0     1.0     1.0                   1.0                      0.0   \n",
       "1        8.0     1.0     1.0                   1.0                      1.0   \n",
       "2        1.0     1.0     1.0                   0.0                      0.0   \n",
       "3        3.0     0.0     1.0                   0.0                      0.0   \n",
       "4        3.0     1.0     1.0                   3.0                      1.0   \n",
       "\n",
       "   ...  city_Vancouver  property_type_Apartment  property_type_Farmhouse  \\\n",
       "0  ...             0.0                      0.0                      1.0   \n",
       "1  ...             0.0                      1.0                      0.0   \n",
       "2  ...             0.0                      0.0                      1.0   \n",
       "3  ...             0.0                      0.0                      1.0   \n",
       "4  ...             0.0                      0.0                      0.0   \n",
       "\n",
       "   property_type_Independent House  property_type_Studio  \\\n",
       "0                              0.0                   0.0   \n",
       "1                              0.0                   0.0   \n",
       "2                              0.0                   0.0   \n",
       "3                              0.0                   0.0   \n",
       "4                              0.0                   0.0   \n",
       "\n",
       "   property_type_Townhouse  property_type_Villa  \\\n",
       "0                      0.0                  0.0   \n",
       "1                      0.0                  0.0   \n",
       "2                      0.0                  0.0   \n",
       "3                      0.0                  0.0   \n",
       "4                      1.0                  0.0   \n",
       "\n",
       "   furnishing_status_Fully-Furnished  furnishing_status_Semi-Furnished  \\\n",
       "0                                0.0                               1.0   \n",
       "1                                0.0                               1.0   \n",
       "2                                0.0                               1.0   \n",
       "3                                0.0                               1.0   \n",
       "4                                1.0                               0.0   \n",
       "\n",
       "   furnishing_status_Unfurnished  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding\n",
    "\n",
    "ds = pd.get_dummies(ds, columns = [\"country\", \"city\", \"property_type\", \"furnishing_status\"],\n",
    "                            drop_first = False)\n",
    "ds.drop(\"property_id\", axis = 1, inplace = True)\n",
    "ds = ds.astype(\"float32\")\n",
    "\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Types: \n",
      " \n",
      " property_size_sqft                   float32\n",
      "price                                float32\n",
      "constructed_year                     float32\n",
      "previous_owners                      float32\n",
      "rooms                                float32\n",
      "                                      ...   \n",
      "property_type_Townhouse              float32\n",
      "property_type_Villa                  float32\n",
      "furnishing_status_Fully-Furnished    float32\n",
      "furnishing_status_Semi-Furnished     float32\n",
      "furnishing_status_Unfurnished        float32\n",
      "Length: 82, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n \\n Types: \\n \\n\", ds.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = ds.drop(\"decision\", axis=1)\n",
    "y = ds[\"decision\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 140000\n",
      "Validation size: 40000\n",
      "Test size: 20000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(x, y, test_size = 0.3, random_state = 5)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size = 1/3, random_state = 5)\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Validation size:\", len(X_val))\n",
    "print(\"Test size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "X_train = StandardScaler.fit_transform(X_train)\n",
    "X_val = StandardScaler.transform(X_val)\n",
    "X_test = StandardScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Optuna suggest first layer's neuron units and activation function\n",
    "    n_units1 = trial.suggest_int(\"Layer_1_units\", 32, 128)\n",
    "    activation_1 = trial.suggest_categorical(\"Activation_1\", [\"relu\", \"sigmoid\"])\n",
    "    model.add(layers.Dense(n_units1, activation=activation_1, input_shape=(X_train.shape[1],)))\n",
    "\n",
    "    # Optuna suggests number of layers\n",
    "    \n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n",
    "\n",
    "    units_per_layer = [n_units1]\n",
    "    activations_per_layer = [activation_1]\n",
    "    \n",
    "    # Optuna suggests activation function, dropout and regularizers\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        \n",
    "        n_units = trial.suggest_int(f\"Layer_{i+2}_units\", 32, 128)\n",
    "        activation = trial.suggest_categorical(f\"Activation_{i+2}\", [\"relu\", \"sigmoid\"])\n",
    "        regularizers = trial.suggest_categorical(f\"Regularizer_{i+2}\", [\"L1\",\"L2\",\"L1L2\"])\n",
    "        r_value = trial.suggest_float(\"regularizer_value\", 1e-6, 1e-4, log = True)\n",
    "        \n",
    "        if relgulu\n",
    "        \n",
    "        model.add(layers.Dense(n_units, activation=activation, kernel_regularizer = tf.keras.regularizers.l2(1e-4)))\n",
    "        \n",
    "        units_per_layer.append(n_units)\n",
    "        activations_per_layer.append(activation)\n",
    "\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    units_per_layer.append(1)\n",
    "    activations_per_layer.append(\"sigmoid\")\n",
    "\n",
    "    # Optuna suggests learning rate and optimizer\n",
    "    \n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"sgd\", \"rmsprop\"])\n",
    "\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"Global-House-Purchase-Decision-ANN-Trials-3\",\n",
    "        name=f\"Trial_{trial.number}\",\n",
    "        reinit=True,\n",
    "        config={\n",
    "            \"n_layers\": n_layers,\n",
    "            \"units_per_layer\": units_per_layer,\n",
    "            \"activations_per_layer\": activations_per_layer,\n",
    "            \"learning_rate\": lr,\n",
    "            \"optimizer\": optimizer_name,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [20, 40, 50, 100])\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0, \n",
    "        callbacks=[WandbMetricsLogger(log_freq=5)]\n",
    "    )\n",
    "\n",
    "    val_loss = min(history.history[\"val_loss\"])\n",
    "    train_loss = min(history.history[\"loss\"])\n",
    "\n",
    "    # Penalize overfitting\n",
    "    score = val_loss + 0.1 * (train_loss - val_loss)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 00:49:50,136] A new study created in memory with name: Proyecto\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmdaz\u001b[0m (\u001b[33memmdaz-zzz\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_004950-e8fmdbae</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/e8fmdbae' target=\"_blank\">Trial_0</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/e8fmdbae' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/e8fmdbae</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1400/1400 [==============================] - 3s 2ms/step - loss: 0.5683 - accuracy: 0.7495 - val_loss: 0.5113 - val_accuracy: 0.7689\n",
      "Epoch 2/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.3061 - accuracy: 0.8773 - val_loss: 0.1780 - val_accuracy: 0.9436\n",
      "Epoch 3/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1642 - accuracy: 0.9451 - val_loss: 0.1550 - val_accuracy: 0.9471\n",
      "Epoch 4/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1505 - accuracy: 0.9496 - val_loss: 0.1456 - val_accuracy: 0.9503\n",
      "Epoch 5/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1416 - accuracy: 0.9533 - val_loss: 0.1375 - val_accuracy: 0.9540\n",
      "Epoch 6/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1334 - accuracy: 0.9570 - val_loss: 0.1303 - val_accuracy: 0.9573\n",
      "Epoch 7/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1252 - accuracy: 0.9603 - val_loss: 0.1226 - val_accuracy: 0.9607\n",
      "Epoch 8/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1164 - accuracy: 0.9639 - val_loss: 0.1139 - val_accuracy: 0.9653\n",
      "Epoch 9/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1069 - accuracy: 0.9680 - val_loss: 0.1049 - val_accuracy: 0.9689\n",
      "Epoch 10/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0974 - accuracy: 0.9723 - val_loss: 0.0966 - val_accuracy: 0.9724\n",
      "Epoch 11/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0884 - accuracy: 0.9764 - val_loss: 0.0878 - val_accuracy: 0.9760\n",
      "Epoch 12/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0805 - accuracy: 0.9798 - val_loss: 0.0810 - val_accuracy: 0.9789\n",
      "Epoch 13/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0736 - accuracy: 0.9828 - val_loss: 0.0751 - val_accuracy: 0.9825\n",
      "Epoch 14/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0677 - accuracy: 0.9855 - val_loss: 0.0700 - val_accuracy: 0.9839\n",
      "Epoch 15/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0624 - accuracy: 0.9875 - val_loss: 0.0654 - val_accuracy: 0.9863\n",
      "Epoch 16/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0576 - accuracy: 0.9895 - val_loss: 0.0609 - val_accuracy: 0.9885\n",
      "Epoch 17/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0530 - accuracy: 0.9909 - val_loss: 0.0563 - val_accuracy: 0.9900\n",
      "Epoch 18/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0490 - accuracy: 0.9922 - val_loss: 0.0527 - val_accuracy: 0.9906\n",
      "Epoch 19/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0452 - accuracy: 0.9933 - val_loss: 0.0489 - val_accuracy: 0.9916\n",
      "Epoch 20/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0419 - accuracy: 0.9941 - val_loss: 0.0461 - val_accuracy: 0.9929\n",
      "Epoch 21/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0390 - accuracy: 0.9949 - val_loss: 0.0432 - val_accuracy: 0.9931\n",
      "Epoch 22/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0364 - accuracy: 0.9957 - val_loss: 0.0407 - val_accuracy: 0.9937\n",
      "Epoch 23/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0343 - accuracy: 0.9962 - val_loss: 0.0383 - val_accuracy: 0.9941\n",
      "Epoch 24/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0323 - accuracy: 0.9968 - val_loss: 0.0366 - val_accuracy: 0.9947\n",
      "Epoch 25/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0307 - accuracy: 0.9973 - val_loss: 0.0349 - val_accuracy: 0.9948\n",
      "Epoch 26/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0292 - accuracy: 0.9977 - val_loss: 0.0332 - val_accuracy: 0.9951\n",
      "Epoch 27/100\n",
      "1400/1400 [==============================] - 3s 2ms/step - loss: 0.0278 - accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.9956\n",
      "Epoch 28/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0266 - accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.9957\n",
      "Epoch 29/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0256 - accuracy: 0.9984 - val_loss: 0.0297 - val_accuracy: 0.9961\n",
      "Epoch 30/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0246 - accuracy: 0.9986 - val_loss: 0.0287 - val_accuracy: 0.9959\n",
      "Epoch 31/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0237 - accuracy: 0.9987 - val_loss: 0.0279 - val_accuracy: 0.9961\n",
      "Epoch 32/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0229 - accuracy: 0.9989 - val_loss: 0.0270 - val_accuracy: 0.9962\n",
      "Epoch 33/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0221 - accuracy: 0.9989 - val_loss: 0.0260 - val_accuracy: 0.9966\n",
      "Epoch 34/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0214 - accuracy: 0.9991 - val_loss: 0.0255 - val_accuracy: 0.9965\n",
      "Epoch 35/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0207 - accuracy: 0.9993 - val_loss: 0.0249 - val_accuracy: 0.9966\n",
      "Epoch 36/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0201 - accuracy: 0.9993 - val_loss: 0.0245 - val_accuracy: 0.9966\n",
      "Epoch 37/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0195 - accuracy: 0.9994 - val_loss: 0.0237 - val_accuracy: 0.9965\n",
      "Epoch 38/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0190 - accuracy: 0.9994 - val_loss: 0.0234 - val_accuracy: 0.9966\n",
      "Epoch 39/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0185 - accuracy: 0.9995 - val_loss: 0.0228 - val_accuracy: 0.9966\n",
      "Epoch 40/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0180 - accuracy: 0.9995 - val_loss: 0.0220 - val_accuracy: 0.9968\n",
      "Epoch 41/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0176 - accuracy: 0.9996 - val_loss: 0.0218 - val_accuracy: 0.9968\n",
      "Epoch 42/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0172 - accuracy: 0.9996 - val_loss: 0.0214 - val_accuracy: 0.9969\n",
      "Epoch 43/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0168 - accuracy: 0.9996 - val_loss: 0.0208 - val_accuracy: 0.9969\n",
      "Epoch 44/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0164 - accuracy: 0.9997 - val_loss: 0.0205 - val_accuracy: 0.9969\n",
      "Epoch 45/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0160 - accuracy: 0.9997 - val_loss: 0.0202 - val_accuracy: 0.9969\n",
      "Epoch 46/100\n",
      "1400/1400 [==============================] - 3s 2ms/step - loss: 0.0157 - accuracy: 0.9997 - val_loss: 0.0198 - val_accuracy: 0.9969\n",
      "Epoch 47/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0154 - accuracy: 0.9997 - val_loss: 0.0197 - val_accuracy: 0.9967\n",
      "Epoch 48/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0151 - accuracy: 0.9997 - val_loss: 0.0192 - val_accuracy: 0.9969\n",
      "Epoch 49/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0148 - accuracy: 0.9997 - val_loss: 0.0190 - val_accuracy: 0.9969\n",
      "Epoch 50/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0145 - accuracy: 0.9998 - val_loss: 0.0187 - val_accuracy: 0.9970\n",
      "Epoch 51/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0142 - accuracy: 0.9998 - val_loss: 0.0189 - val_accuracy: 0.9969\n",
      "Epoch 52/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0140 - accuracy: 0.9998 - val_loss: 0.0183 - val_accuracy: 0.9970\n",
      "Epoch 53/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0137 - accuracy: 0.9998 - val_loss: 0.0179 - val_accuracy: 0.9970\n",
      "Epoch 54/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0135 - accuracy: 0.9999 - val_loss: 0.0181 - val_accuracy: 0.9969\n",
      "Epoch 55/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0133 - accuracy: 0.9998 - val_loss: 0.0176 - val_accuracy: 0.9970\n",
      "Epoch 56/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0131 - accuracy: 0.9998 - val_loss: 0.0171 - val_accuracy: 0.9973\n",
      "Epoch 57/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0128 - accuracy: 0.9998 - val_loss: 0.0169 - val_accuracy: 0.9973\n",
      "Epoch 58/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0127 - accuracy: 0.9999 - val_loss: 0.0169 - val_accuracy: 0.9970\n",
      "Epoch 59/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0125 - accuracy: 0.9999 - val_loss: 0.0169 - val_accuracy: 0.9971\n",
      "Epoch 60/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0123 - accuracy: 0.9999 - val_loss: 0.0165 - val_accuracy: 0.9974\n",
      "Epoch 61/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0121 - accuracy: 0.9999 - val_loss: 0.0163 - val_accuracy: 0.9970\n",
      "Epoch 62/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0119 - accuracy: 0.9999 - val_loss: 0.0159 - val_accuracy: 0.9975\n",
      "Epoch 63/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0118 - accuracy: 0.9999 - val_loss: 0.0161 - val_accuracy: 0.9972\n",
      "Epoch 64/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0117 - accuracy: 0.9999 - val_loss: 0.0158 - val_accuracy: 0.9973\n",
      "Epoch 65/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0115 - accuracy: 0.9999 - val_loss: 0.0155 - val_accuracy: 0.9973\n",
      "Epoch 66/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0113 - accuracy: 0.9999 - val_loss: 0.0156 - val_accuracy: 0.9973\n",
      "Epoch 67/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0112 - accuracy: 0.9999 - val_loss: 0.0153 - val_accuracy: 0.9973\n",
      "Epoch 68/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0111 - accuracy: 0.9999 - val_loss: 0.0154 - val_accuracy: 0.9970\n",
      "Epoch 69/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9975\n",
      "Epoch 70/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0108 - accuracy: 0.9999 - val_loss: 0.0149 - val_accuracy: 0.9973\n",
      "Epoch 71/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0107 - accuracy: 0.9999 - val_loss: 0.0148 - val_accuracy: 0.9975\n",
      "Epoch 72/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0106 - accuracy: 0.9999 - val_loss: 0.0148 - val_accuracy: 0.9973\n",
      "Epoch 73/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9974\n",
      "Epoch 74/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0104 - accuracy: 0.9999 - val_loss: 0.0145 - val_accuracy: 0.9974\n",
      "Epoch 75/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0102 - accuracy: 0.9999 - val_loss: 0.0144 - val_accuracy: 0.9975\n",
      "Epoch 76/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0101 - accuracy: 0.9999 - val_loss: 0.0147 - val_accuracy: 0.9971\n",
      "Epoch 77/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9972\n",
      "Epoch 78/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9973\n",
      "Epoch 79/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9974\n",
      "Epoch 80/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9976\n",
      "Epoch 81/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9973\n",
      "Epoch 82/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9973\n",
      "Epoch 83/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9974\n",
      "Epoch 84/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9976\n",
      "Epoch 85/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9973\n",
      "Epoch 86/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9973\n",
      "Epoch 87/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9973\n",
      "Epoch 88/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
      "Epoch 89/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0090 - accuracy: 0.9999 - val_loss: 0.0131 - val_accuracy: 0.9973\n",
      "Epoch 90/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9973\n",
      "Epoch 91/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9973\n",
      "Epoch 92/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9977\n",
      "Epoch 93/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9976\n",
      "Epoch 94/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9976\n",
      "Epoch 95/100\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9976\n",
      "Epoch 96/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9976\n",
      "Epoch 97/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9972\n",
      "Epoch 98/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9976\n",
      "Epoch 99/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9973\n",
      "Epoch 100/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9976\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99999</td></tr><tr><td>batch/batch_step</td><td>139995</td></tr><tr><td>batch/learning_rate</td><td>5e-05</td></tr><tr><td>batch/loss</td><td>0.00822</td></tr><tr><td>epoch/accuracy</td><td>0.99999</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>5e-05</td></tr><tr><td>epoch/loss</td><td>0.00822</td></tr><tr><td>epoch/val_accuracy</td><td>0.99755</td></tr><tr><td>epoch/val_loss</td><td>0.0125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_0</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/e8fmdbae' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/e8fmdbae</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_004950-e8fmdbae/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 00:53:13,979] Trial 0 finished with value: 0.012046323250979185 and parameters: {'Layer_1_units': 125, 'Activation_1': 'relu', 'n_layers': 3, 'Layer_2_units': 93, 'Activation_2': 'sigmoid', 'Layer_3_units': 61, 'Activation_3': 'sigmoid', 'Layer_4_units': 102, 'Activation_4': 'sigmoid', 'learning_rate': 4.647762722809324e-05, 'optimizer': 'adam', 'batch_size': 100}. Best is trial 0 with value: 0.012046323250979185.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_005314-736hxmcx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/736hxmcx' target=\"_blank\">Trial_1</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/736hxmcx' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/736hxmcx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.5649 - accuracy: 0.7692 - val_loss: 0.5460 - val_accuracy: 0.7689\n",
      "Epoch 2/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.5397 - accuracy: 0.7692 - val_loss: 0.5320 - val_accuracy: 0.7689\n",
      "Epoch 3/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.5177 - accuracy: 0.7692 - val_loss: 0.4994 - val_accuracy: 0.7689\n",
      "Epoch 4/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.4715 - accuracy: 0.7692 - val_loss: 0.4379 - val_accuracy: 0.7692\n",
      "Epoch 5/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.3981 - accuracy: 0.7979 - val_loss: 0.3546 - val_accuracy: 0.8353\n",
      "Epoch 6/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.3130 - accuracy: 0.8837 - val_loss: 0.2716 - val_accuracy: 0.9132\n",
      "Epoch 7/100\n",
      "3500/3500 [==============================] - 3s 987us/step - loss: 0.2414 - accuracy: 0.9267 - val_loss: 0.2139 - val_accuracy: 0.9338\n",
      "Epoch 8/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1975 - accuracy: 0.9380 - val_loss: 0.1829 - val_accuracy: 0.9390\n",
      "Epoch 9/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1751 - accuracy: 0.9401 - val_loss: 0.1677 - val_accuracy: 0.9399\n",
      "Epoch 10/100\n",
      "3500/3500 [==============================] - 3s 987us/step - loss: 0.1638 - accuracy: 0.9413 - val_loss: 0.1598 - val_accuracy: 0.9420\n",
      "Epoch 11/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1579 - accuracy: 0.9420 - val_loss: 0.1553 - val_accuracy: 0.9428\n",
      "Epoch 12/100\n",
      "3500/3500 [==============================] - 3s 979us/step - loss: 0.1544 - accuracy: 0.9424 - val_loss: 0.1526 - val_accuracy: 0.9431\n",
      "Epoch 13/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1521 - accuracy: 0.9426 - val_loss: 0.1507 - val_accuracy: 0.9434\n",
      "Epoch 14/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1505 - accuracy: 0.9429 - val_loss: 0.1494 - val_accuracy: 0.9440\n",
      "Epoch 15/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1494 - accuracy: 0.9434 - val_loss: 0.1485 - val_accuracy: 0.9438\n",
      "Epoch 16/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1484 - accuracy: 0.9434 - val_loss: 0.1476 - val_accuracy: 0.9442\n",
      "Epoch 17/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1476 - accuracy: 0.9437 - val_loss: 0.1468 - val_accuracy: 0.9447\n",
      "Epoch 18/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1470 - accuracy: 0.9439 - val_loss: 0.1462 - val_accuracy: 0.9456\n",
      "Epoch 19/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1464 - accuracy: 0.9444 - val_loss: 0.1457 - val_accuracy: 0.9453\n",
      "Epoch 20/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1459 - accuracy: 0.9443 - val_loss: 0.1452 - val_accuracy: 0.9452\n",
      "Epoch 21/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1454 - accuracy: 0.9445 - val_loss: 0.1447 - val_accuracy: 0.9456\n",
      "Epoch 22/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1449 - accuracy: 0.9448 - val_loss: 0.1444 - val_accuracy: 0.9461\n",
      "Epoch 23/100\n",
      "3500/3500 [==============================] - 3s 985us/step - loss: 0.1445 - accuracy: 0.9448 - val_loss: 0.1439 - val_accuracy: 0.9455\n",
      "Epoch 24/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1441 - accuracy: 0.9450 - val_loss: 0.1435 - val_accuracy: 0.9456\n",
      "Epoch 25/100\n",
      "3500/3500 [==============================] - 3s 980us/step - loss: 0.1438 - accuracy: 0.9450 - val_loss: 0.1433 - val_accuracy: 0.9470\n",
      "Epoch 26/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1434 - accuracy: 0.9454 - val_loss: 0.1430 - val_accuracy: 0.9469\n",
      "Epoch 27/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1431 - accuracy: 0.9457 - val_loss: 0.1426 - val_accuracy: 0.9466\n",
      "Epoch 28/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1427 - accuracy: 0.9457 - val_loss: 0.1422 - val_accuracy: 0.9466\n",
      "Epoch 29/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1424 - accuracy: 0.9456 - val_loss: 0.1419 - val_accuracy: 0.9470\n",
      "Epoch 30/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1421 - accuracy: 0.9458 - val_loss: 0.1416 - val_accuracy: 0.9470\n",
      "Epoch 31/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1418 - accuracy: 0.9459 - val_loss: 0.1412 - val_accuracy: 0.9471\n",
      "Epoch 32/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1415 - accuracy: 0.9459 - val_loss: 0.1412 - val_accuracy: 0.9473\n",
      "Epoch 33/100\n",
      "3500/3500 [==============================] - 3s 999us/step - loss: 0.1411 - accuracy: 0.9458 - val_loss: 0.1405 - val_accuracy: 0.9466\n",
      "Epoch 34/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1409 - accuracy: 0.9463 - val_loss: 0.1404 - val_accuracy: 0.9472\n",
      "Epoch 35/100\n",
      "3500/3500 [==============================] - 3s 994us/step - loss: 0.1405 - accuracy: 0.9463 - val_loss: 0.1400 - val_accuracy: 0.9479\n",
      "Epoch 36/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1402 - accuracy: 0.9464 - val_loss: 0.1397 - val_accuracy: 0.9475\n",
      "Epoch 37/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1399 - accuracy: 0.9464 - val_loss: 0.1396 - val_accuracy: 0.9478\n",
      "Epoch 38/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1396 - accuracy: 0.9464 - val_loss: 0.1391 - val_accuracy: 0.9480\n",
      "Epoch 39/100\n",
      "3500/3500 [==============================] - 3s 971us/step - loss: 0.1393 - accuracy: 0.9468 - val_loss: 0.1387 - val_accuracy: 0.9477\n",
      "Epoch 40/100\n",
      "3500/3500 [==============================] - 3s 963us/step - loss: 0.1389 - accuracy: 0.9467 - val_loss: 0.1384 - val_accuracy: 0.9477\n",
      "Epoch 41/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1386 - accuracy: 0.9469 - val_loss: 0.1380 - val_accuracy: 0.9471\n",
      "Epoch 42/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1383 - accuracy: 0.9469 - val_loss: 0.1377 - val_accuracy: 0.9474\n",
      "Epoch 43/100\n",
      "3500/3500 [==============================] - 3s 964us/step - loss: 0.1379 - accuracy: 0.9473 - val_loss: 0.1373 - val_accuracy: 0.9468\n",
      "Epoch 44/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1376 - accuracy: 0.9472 - val_loss: 0.1371 - val_accuracy: 0.9484\n",
      "Epoch 45/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1372 - accuracy: 0.9474 - val_loss: 0.1367 - val_accuracy: 0.9485\n",
      "Epoch 46/100\n",
      "3500/3500 [==============================] - 3s 982us/step - loss: 0.1368 - accuracy: 0.9476 - val_loss: 0.1362 - val_accuracy: 0.9484\n",
      "Epoch 47/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1364 - accuracy: 0.9477 - val_loss: 0.1358 - val_accuracy: 0.9477\n",
      "Epoch 48/100\n",
      "3500/3500 [==============================] - 3s 939us/step - loss: 0.1360 - accuracy: 0.9480 - val_loss: 0.1355 - val_accuracy: 0.9479\n",
      "Epoch 49/100\n",
      "3500/3500 [==============================] - 3s 948us/step - loss: 0.1356 - accuracy: 0.9480 - val_loss: 0.1351 - val_accuracy: 0.9487\n",
      "Epoch 50/100\n",
      "3500/3500 [==============================] - 3s 999us/step - loss: 0.1352 - accuracy: 0.9481 - val_loss: 0.1346 - val_accuracy: 0.9481\n",
      "Epoch 51/100\n",
      "3500/3500 [==============================] - 3s 985us/step - loss: 0.1347 - accuracy: 0.9483 - val_loss: 0.1341 - val_accuracy: 0.9485\n",
      "Epoch 52/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1342 - accuracy: 0.9484 - val_loss: 0.1337 - val_accuracy: 0.9482\n",
      "Epoch 53/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1338 - accuracy: 0.9488 - val_loss: 0.1333 - val_accuracy: 0.9497\n",
      "Epoch 54/100\n",
      "3500/3500 [==============================] - 3s 985us/step - loss: 0.1333 - accuracy: 0.9486 - val_loss: 0.1329 - val_accuracy: 0.9498\n",
      "Epoch 55/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1328 - accuracy: 0.9492 - val_loss: 0.1322 - val_accuracy: 0.9495\n",
      "Epoch 56/100\n",
      "3500/3500 [==============================] - 3s 990us/step - loss: 0.1323 - accuracy: 0.9492 - val_loss: 0.1317 - val_accuracy: 0.9502\n",
      "Epoch 57/100\n",
      "3500/3500 [==============================] - 3s 992us/step - loss: 0.1317 - accuracy: 0.9496 - val_loss: 0.1311 - val_accuracy: 0.9502\n",
      "Epoch 58/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1311 - accuracy: 0.9497 - val_loss: 0.1308 - val_accuracy: 0.9509\n",
      "Epoch 59/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1305 - accuracy: 0.9499 - val_loss: 0.1301 - val_accuracy: 0.9506\n",
      "Epoch 60/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1299 - accuracy: 0.9504 - val_loss: 0.1294 - val_accuracy: 0.9504\n",
      "Epoch 61/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1293 - accuracy: 0.9507 - val_loss: 0.1287 - val_accuracy: 0.9503\n",
      "Epoch 62/100\n",
      "3500/3500 [==============================] - 3s 977us/step - loss: 0.1287 - accuracy: 0.9510 - val_loss: 0.1283 - val_accuracy: 0.9523\n",
      "Epoch 63/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1280 - accuracy: 0.9513 - val_loss: 0.1276 - val_accuracy: 0.9522\n",
      "Epoch 64/100\n",
      "3500/3500 [==============================] - 3s 989us/step - loss: 0.1273 - accuracy: 0.9517 - val_loss: 0.1269 - val_accuracy: 0.9528\n",
      "Epoch 65/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1266 - accuracy: 0.9521 - val_loss: 0.1263 - val_accuracy: 0.9530\n",
      "Epoch 66/100\n",
      "3500/3500 [==============================] - 3s 979us/step - loss: 0.1259 - accuracy: 0.9526 - val_loss: 0.1255 - val_accuracy: 0.9530\n",
      "Epoch 67/100\n",
      "3500/3500 [==============================] - 3s 988us/step - loss: 0.1251 - accuracy: 0.9529 - val_loss: 0.1246 - val_accuracy: 0.9522\n",
      "Epoch 68/100\n",
      "3500/3500 [==============================] - 3s 999us/step - loss: 0.1244 - accuracy: 0.9531 - val_loss: 0.1240 - val_accuracy: 0.9538\n",
      "Epoch 69/100\n",
      "3500/3500 [==============================] - 3s 977us/step - loss: 0.1235 - accuracy: 0.9537 - val_loss: 0.1231 - val_accuracy: 0.9543\n",
      "Epoch 70/100\n",
      "3500/3500 [==============================] - 3s 976us/step - loss: 0.1227 - accuracy: 0.9542 - val_loss: 0.1223 - val_accuracy: 0.9547\n",
      "Epoch 71/100\n",
      "3500/3500 [==============================] - 3s 978us/step - loss: 0.1219 - accuracy: 0.9547 - val_loss: 0.1215 - val_accuracy: 0.9548\n",
      "Epoch 72/100\n",
      "3500/3500 [==============================] - 3s 981us/step - loss: 0.1211 - accuracy: 0.9552 - val_loss: 0.1207 - val_accuracy: 0.9553\n",
      "Epoch 73/100\n",
      "3500/3500 [==============================] - 3s 985us/step - loss: 0.1202 - accuracy: 0.9555 - val_loss: 0.1199 - val_accuracy: 0.9564\n",
      "Epoch 74/100\n",
      "3500/3500 [==============================] - 3s 975us/step - loss: 0.1193 - accuracy: 0.9561 - val_loss: 0.1191 - val_accuracy: 0.9567\n",
      "Epoch 75/100\n",
      "3500/3500 [==============================] - 3s 972us/step - loss: 0.1184 - accuracy: 0.9567 - val_loss: 0.1182 - val_accuracy: 0.9567\n",
      "Epoch 76/100\n",
      "3500/3500 [==============================] - 3s 970us/step - loss: 0.1175 - accuracy: 0.9573 - val_loss: 0.1171 - val_accuracy: 0.9569\n",
      "Epoch 77/100\n",
      "3500/3500 [==============================] - 3s 968us/step - loss: 0.1165 - accuracy: 0.9578 - val_loss: 0.1162 - val_accuracy: 0.9579\n",
      "Epoch 78/100\n",
      "3500/3500 [==============================] - 3s 970us/step - loss: 0.1155 - accuracy: 0.9582 - val_loss: 0.1158 - val_accuracy: 0.9583\n",
      "Epoch 79/100\n",
      "3500/3500 [==============================] - 3s 973us/step - loss: 0.1146 - accuracy: 0.9589 - val_loss: 0.1143 - val_accuracy: 0.9588\n",
      "Epoch 80/100\n",
      "3500/3500 [==============================] - 3s 971us/step - loss: 0.1136 - accuracy: 0.9593 - val_loss: 0.1133 - val_accuracy: 0.9595\n",
      "Epoch 81/100\n",
      "3500/3500 [==============================] - 3s 968us/step - loss: 0.1126 - accuracy: 0.9598 - val_loss: 0.1124 - val_accuracy: 0.9599\n",
      "Epoch 82/100\n",
      "3500/3500 [==============================] - 3s 968us/step - loss: 0.1116 - accuracy: 0.9605 - val_loss: 0.1114 - val_accuracy: 0.9603\n",
      "Epoch 83/100\n",
      "3500/3500 [==============================] - 3s 969us/step - loss: 0.1106 - accuracy: 0.9609 - val_loss: 0.1104 - val_accuracy: 0.9607\n",
      "Epoch 84/100\n",
      "3500/3500 [==============================] - 3s 968us/step - loss: 0.1095 - accuracy: 0.9617 - val_loss: 0.1096 - val_accuracy: 0.9610\n",
      "Epoch 85/100\n",
      "3500/3500 [==============================] - 3s 972us/step - loss: 0.1085 - accuracy: 0.9624 - val_loss: 0.1084 - val_accuracy: 0.9615\n",
      "Epoch 86/100\n",
      "3500/3500 [==============================] - 3s 968us/step - loss: 0.1074 - accuracy: 0.9628 - val_loss: 0.1075 - val_accuracy: 0.9625\n",
      "Epoch 87/100\n",
      "3500/3500 [==============================] - 3s 971us/step - loss: 0.1064 - accuracy: 0.9633 - val_loss: 0.1064 - val_accuracy: 0.9627\n",
      "Epoch 88/100\n",
      "3500/3500 [==============================] - 3s 973us/step - loss: 0.1053 - accuracy: 0.9640 - val_loss: 0.1054 - val_accuracy: 0.9632\n",
      "Epoch 89/100\n",
      "3500/3500 [==============================] - 3s 972us/step - loss: 0.1043 - accuracy: 0.9647 - val_loss: 0.1043 - val_accuracy: 0.9636\n",
      "Epoch 90/100\n",
      "3500/3500 [==============================] - 3s 970us/step - loss: 0.1032 - accuracy: 0.9651 - val_loss: 0.1034 - val_accuracy: 0.9638\n",
      "Epoch 91/100\n",
      "3500/3500 [==============================] - 3s 969us/step - loss: 0.1022 - accuracy: 0.9655 - val_loss: 0.1024 - val_accuracy: 0.9640\n",
      "Epoch 92/100\n",
      "3500/3500 [==============================] - 3s 974us/step - loss: 0.1011 - accuracy: 0.9660 - val_loss: 0.1014 - val_accuracy: 0.9647\n",
      "Epoch 93/100\n",
      "3500/3500 [==============================] - 3s 970us/step - loss: 0.1001 - accuracy: 0.9666 - val_loss: 0.1004 - val_accuracy: 0.9655\n",
      "Epoch 94/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0990 - accuracy: 0.9672 - val_loss: 0.0994 - val_accuracy: 0.9659\n",
      "Epoch 95/100\n",
      "3500/3500 [==============================] - 3s 975us/step - loss: 0.0980 - accuracy: 0.9674 - val_loss: 0.0984 - val_accuracy: 0.9664\n",
      "Epoch 96/100\n",
      "3500/3500 [==============================] - 3s 974us/step - loss: 0.0970 - accuracy: 0.9679 - val_loss: 0.0976 - val_accuracy: 0.9663\n",
      "Epoch 97/100\n",
      "3500/3500 [==============================] - 3s 970us/step - loss: 0.0959 - accuracy: 0.9685 - val_loss: 0.0965 - val_accuracy: 0.9677\n",
      "Epoch 98/100\n",
      "3500/3500 [==============================] - 3s 974us/step - loss: 0.0949 - accuracy: 0.9690 - val_loss: 0.0956 - val_accuracy: 0.9678\n",
      "Epoch 99/100\n",
      "3500/3500 [==============================] - 3s 975us/step - loss: 0.0939 - accuracy: 0.9695 - val_loss: 0.0948 - val_accuracy: 0.9682\n",
      "Epoch 100/100\n",
      "3500/3500 [==============================] - 3s 971us/step - loss: 0.0929 - accuracy: 0.9701 - val_loss: 0.0937 - val_accuracy: 0.9686\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–‡â–†â–†â–…â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‡â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ƒâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.97018</td></tr><tr><td>batch/batch_step</td><td>349995</td></tr><tr><td>batch/learning_rate</td><td>1e-05</td></tr><tr><td>batch/loss</td><td>0.09289</td></tr><tr><td>epoch/accuracy</td><td>0.97015</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>1e-05</td></tr><tr><td>epoch/loss</td><td>0.09294</td></tr><tr><td>epoch/val_accuracy</td><td>0.9686</td></tr><tr><td>epoch/val_loss</td><td>0.09373</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_1</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/736hxmcx' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/736hxmcx</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_005314-736hxmcx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 00:59:09,366] Trial 1 finished with value: 0.09365014433860779 and parameters: {'Layer_1_units': 97, 'Activation_1': 'sigmoid', 'n_layers': 2, 'Layer_2_units': 54, 'Activation_2': 'sigmoid', 'Layer_3_units': 39, 'Activation_3': 'sigmoid', 'learning_rate': 1.1618992481573763e-05, 'optimizer': 'adam', 'batch_size': 40}. Best is trial 0 with value: 0.012046323250979185.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_005909-39nos6kh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/39nos6kh' target=\"_blank\">Trial_2</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/39nos6kh' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/39nos6kh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0896 - accuracy: 0.9671 - val_loss: 0.0196 - val_accuracy: 0.9963\n",
      "Epoch 2/100\n",
      "2800/2800 [==============================] - 3s 994us/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 0.0304 - val_accuracy: 0.9906\n",
      "Epoch 3/100\n",
      "2800/2800 [==============================] - 3s 990us/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0113 - val_accuracy: 0.9967\n",
      "Epoch 4/100\n",
      "2800/2800 [==============================] - 3s 994us/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.0075 - val_accuracy: 0.9977\n",
      "Epoch 5/100\n",
      "2800/2800 [==============================] - 3s 1000us/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 6/100\n",
      "2800/2800 [==============================] - 3s 995us/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0152 - val_accuracy: 0.9948\n",
      "Epoch 7/100\n",
      "2800/2800 [==============================] - 3s 992us/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0091 - val_accuracy: 0.9966\n",
      "Epoch 8/100\n",
      "2800/2800 [==============================] - 3s 995us/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 9/100\n",
      "2800/2800 [==============================] - 3s 991us/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0093 - val_accuracy: 0.9979\n",
      "Epoch 10/100\n",
      "2800/2800 [==============================] - 3s 993us/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.0103 - val_accuracy: 0.9957\n",
      "Epoch 11/100\n",
      "2800/2800 [==============================] - 3s 999us/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0067 - val_accuracy: 0.9979\n",
      "Epoch 12/100\n",
      "2800/2800 [==============================] - 3s 992us/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0083 - val_accuracy: 0.9977\n",
      "Epoch 13/100\n",
      "2800/2800 [==============================] - 3s 994us/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0139 - val_accuracy: 0.9960\n",
      "Epoch 14/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0052 - val_accuracy: 0.9982\n",
      "Epoch 15/100\n",
      "2800/2800 [==============================] - 3s 992us/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0061 - val_accuracy: 0.9979\n",
      "Epoch 16/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0149 - val_accuracy: 0.9959\n",
      "Epoch 17/100\n",
      "2800/2800 [==============================] - 3s 995us/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0099 - val_accuracy: 0.9977\n",
      "Epoch 18/100\n",
      "2800/2800 [==============================] - 3s 995us/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0073 - val_accuracy: 0.9978\n",
      "Epoch 19/100\n",
      "2800/2800 [==============================] - 3s 993us/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0183 - val_accuracy: 0.9959\n",
      "Epoch 20/100\n",
      "2800/2800 [==============================] - 3s 997us/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0074 - val_accuracy: 0.9972\n",
      "Epoch 21/100\n",
      "2800/2800 [==============================] - 3s 990us/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0095 - val_accuracy: 0.9971\n",
      "Epoch 22/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0103 - val_accuracy: 0.9976\n",
      "Epoch 23/100\n",
      "2800/2800 [==============================] - 3s 993us/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0055 - val_accuracy: 0.9981\n",
      "Epoch 24/100\n",
      "2800/2800 [==============================] - 3s 997us/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0083 - val_accuracy: 0.9977\n",
      "Epoch 25/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 26/100\n",
      "2800/2800 [==============================] - 3s 997us/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
      "Epoch 27/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0076 - val_accuracy: 0.9976\n",
      "Epoch 28/100\n",
      "2800/2800 [==============================] - 3s 997us/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
      "Epoch 29/100\n",
      "2800/2800 [==============================] - 3s 999us/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0066 - val_accuracy: 0.9984\n",
      "Epoch 30/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0069 - val_accuracy: 0.9981\n",
      "Epoch 31/100\n",
      "2800/2800 [==============================] - 3s 996us/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0118 - val_accuracy: 0.9973\n",
      "Epoch 32/100\n",
      "2800/2800 [==============================] - 3s 999us/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0081 - val_accuracy: 0.9973\n",
      "Epoch 33/100\n",
      "2800/2800 [==============================] - 3s 999us/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 34/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0072 - val_accuracy: 0.9983\n",
      "Epoch 35/100\n",
      "2800/2800 [==============================] - 3s 996us/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0077 - val_accuracy: 0.9981\n",
      "Epoch 36/100\n",
      "2800/2800 [==============================] - 3s 998us/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
      "Epoch 37/100\n",
      "2800/2800 [==============================] - 3s 998us/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0673 - val_accuracy: 0.9854\n",
      "Epoch 38/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0070 - val_accuracy: 0.9980\n",
      "Epoch 39/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0062 - val_accuracy: 0.9982\n",
      "Epoch 40/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
      "Epoch 41/100\n",
      "2800/2800 [==============================] - 3s 999us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
      "Epoch 42/100\n",
      "2800/2800 [==============================] - 3s 997us/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0182 - val_accuracy: 0.9966\n",
      "Epoch 43/100\n",
      "2800/2800 [==============================] - 3s 998us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
      "Epoch 44/100\n",
      "2800/2800 [==============================] - 3s 997us/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0091 - val_accuracy: 0.9977\n",
      "Epoch 45/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 46/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0052 - val_accuracy: 0.9984\n",
      "Epoch 47/100\n",
      "2800/2800 [==============================] - 3s 997us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 48/100\n",
      "2800/2800 [==============================] - 3s 996us/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0072 - val_accuracy: 0.9985\n",
      "Epoch 49/100\n",
      "2800/2800 [==============================] - 3s 1000us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0141 - val_accuracy: 0.9975\n",
      "Epoch 50/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0078 - val_accuracy: 0.9983\n",
      "Epoch 51/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0065 - val_accuracy: 0.9982\n",
      "Epoch 52/100\n",
      "2800/2800 [==============================] - 3s 998us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0065 - val_accuracy: 0.9984\n",
      "Epoch 53/100\n",
      "2800/2800 [==============================] - 3s 999us/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0066 - val_accuracy: 0.9983\n",
      "Epoch 54/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Epoch 55/100\n",
      "2800/2800 [==============================] - 3s 998us/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0168 - val_accuracy: 0.9966\n",
      "Epoch 56/100\n",
      "2800/2800 [==============================] - 3s 995us/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0060 - val_accuracy: 0.9989\n",
      "Epoch 57/100\n",
      "2800/2800 [==============================] - 3s 997us/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0078 - val_accuracy: 0.9981\n",
      "Epoch 58/100\n",
      "2800/2800 [==============================] - 3s 1000us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
      "Epoch 59/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0057 - val_accuracy: 0.9985\n",
      "Epoch 60/100\n",
      "2800/2800 [==============================] - 3s 996us/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0121 - val_accuracy: 0.9973\n",
      "Epoch 61/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0075 - val_accuracy: 0.9983\n",
      "Epoch 62/100\n",
      "2800/2800 [==============================] - 3s 994us/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0060 - val_accuracy: 0.9986\n",
      "Epoch 63/100\n",
      "2800/2800 [==============================] - 3s 991us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0107 - val_accuracy: 0.9973\n",
      "Epoch 64/100\n",
      "2800/2800 [==============================] - 3s 999us/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0068 - val_accuracy: 0.9983\n",
      "Epoch 65/100\n",
      "2800/2800 [==============================] - 3s 997us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0121 - val_accuracy: 0.9978\n",
      "Epoch 66/100\n",
      "2800/2800 [==============================] - 3s 999us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
      "Epoch 67/100\n",
      "2800/2800 [==============================] - 3s 994us/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0066 - val_accuracy: 0.9983\n",
      "Epoch 68/100\n",
      "2800/2800 [==============================] - 3s 999us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 69/100\n",
      "2800/2800 [==============================] - 3s 992us/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0050 - val_accuracy: 0.9985\n",
      "Epoch 70/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0205 - val_accuracy: 0.9966\n",
      "Epoch 71/100\n",
      "2800/2800 [==============================] - 3s 998us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
      "Epoch 72/100\n",
      "2800/2800 [==============================] - 3s 999us/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0048 - val_accuracy: 0.9986\n",
      "Epoch 73/100\n",
      "2800/2800 [==============================] - 3s 995us/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 74/100\n",
      "2800/2800 [==============================] - 3s 998us/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0062 - val_accuracy: 0.9982\n",
      "Epoch 75/100\n",
      "2800/2800 [==============================] - 3s 994us/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0050 - val_accuracy: 0.9982\n",
      "Epoch 76/100\n",
      "2800/2800 [==============================] - 3s 999us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0048 - val_accuracy: 0.9985\n",
      "Epoch 77/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0077 - val_accuracy: 0.9985\n",
      "Epoch 78/100\n",
      "2800/2800 [==============================] - 3s 998us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0085 - val_accuracy: 0.9982\n",
      "Epoch 79/100\n",
      "2800/2800 [==============================] - 3s 994us/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
      "Epoch 80/100\n",
      "2800/2800 [==============================] - 3s 999us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
      "Epoch 81/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9990\n",
      "Epoch 82/100\n",
      "2800/2800 [==============================] - 3s 992us/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 83/100\n",
      "2800/2800 [==============================] - 3s 997us/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0062 - val_accuracy: 0.9984\n",
      "Epoch 84/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
      "Epoch 85/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9985\n",
      "Epoch 86/100\n",
      "2800/2800 [==============================] - 3s 998us/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0084 - val_accuracy: 0.9980\n",
      "Epoch 87/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 88/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0142 - val_accuracy: 0.9971\n",
      "Epoch 89/100\n",
      "2800/2800 [==============================] - 3s 996us/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0144 - val_accuracy: 0.9967\n",
      "Epoch 90/100\n",
      "2800/2800 [==============================] - 3s 999us/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0103 - val_accuracy: 0.9981\n",
      "Epoch 91/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0080 - val_accuracy: 0.9983\n",
      "Epoch 92/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
      "Epoch 93/100\n",
      "2800/2800 [==============================] - 3s 998us/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0068 - val_accuracy: 0.9985\n",
      "Epoch 94/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 95/100\n",
      "2800/2800 [==============================] - 3s 998us/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 96/100\n",
      "2800/2800 [==============================] - 3s 995us/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0088 - val_accuracy: 0.9979\n",
      "Epoch 97/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
      "Epoch 98/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0118 - val_accuracy: 0.9974\n",
      "Epoch 99/100\n",
      "2800/2800 [==============================] - 3s 997us/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
      "Epoch 100/100\n",
      "2800/2800 [==============================] - 3s 998us/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0042 - val_accuracy: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–‚â–â–â–â–‚â–ƒâ–‚â–ƒâ–„â–ƒâ–ˆâ–…â–…â–„â–…â–…â–…â–…â–„â–…â–†â–…â–†â–†â–†â–†â–†â–†â–…â–…â–†â–‡â–†â–†â–†â–†â–…â–†â–†â–†</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–â–„â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚</td></tr><tr><td>epoch/accuracy</td><td>â–â–…â–…â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‡â–†â–†â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–‚â–ƒâ–…â–†â–â–…â–„â–†â–†â–‡â–‡â–„â–‡â–†â–†â–†â–…â–‡â–‡â–‡â–†â–‡â–ˆâ–…â–„â–…â–†â–†â–ˆâ–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–†â–ƒâ–†</td></tr><tr><td>epoch/val_loss</td><td>â–…â–ˆâ–ƒâ–‚â–‚â–„â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–â–â–ƒâ–‚â–ƒâ–‚â–â–â–‚â–â–â–‚â–â–‚â–‚â–ƒâ–‚â–â–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99948</td></tr><tr><td>batch/batch_step</td><td>279995</td></tr><tr><td>batch/learning_rate</td><td>0.00562</td></tr><tr><td>batch/loss</td><td>0.00217</td></tr><tr><td>epoch/accuracy</td><td>0.99949</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00562</td></tr><tr><td>epoch/loss</td><td>0.00216</td></tr><tr><td>epoch/val_accuracy</td><td>0.9987</td></tr><tr><td>epoch/val_loss</td><td>0.00415</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_2</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/39nos6kh' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/39nos6kh</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_005909-39nos6kh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 01:03:51,398] Trial 2 finished with value: 0.003322927176486701 and parameters: {'Layer_1_units': 87, 'Activation_1': 'sigmoid', 'n_layers': 2, 'Layer_2_units': 106, 'Activation_2': 'sigmoid', 'Layer_3_units': 62, 'Activation_3': 'relu', 'learning_rate': 0.005615079340542057, 'optimizer': 'rmsprop', 'batch_size': 50}. Best is trial 2 with value: 0.003322927176486701.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_010351-k0efe97t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/k0efe97t' target=\"_blank\">Trial_3</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/k0efe97t' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/k0efe97t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0729 - accuracy: 0.9736 - val_loss: 0.0228 - val_accuracy: 0.9937\n",
      "Epoch 2/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.0114 - val_accuracy: 0.9970\n",
      "Epoch 3/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.0095 - val_accuracy: 0.9970\n",
      "Epoch 4/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.0128 - val_accuracy: 0.9965\n",
      "Epoch 5/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.0097 - val_accuracy: 0.9965\n",
      "Epoch 6/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0196 - val_accuracy: 0.9936\n",
      "Epoch 7/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 8/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 9/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0063 - val_accuracy: 0.9979\n",
      "Epoch 10/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0072 - val_accuracy: 0.9974\n",
      "Epoch 11/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0054 - val_accuracy: 0.9982\n",
      "Epoch 12/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0050 - val_accuracy: 0.9984\n",
      "Epoch 13/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
      "Epoch 14/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0055 - val_accuracy: 0.9980\n",
      "Epoch 15/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 16/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0056 - val_accuracy: 0.9982\n",
      "Epoch 17/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 18/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0080 - val_accuracy: 0.9975\n",
      "Epoch 19/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0085 - val_accuracy: 0.9977\n",
      "Epoch 20/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0056 - val_accuracy: 0.9980\n",
      "Epoch 21/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0090 - val_accuracy: 0.9967\n",
      "Epoch 22/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0098 - val_accuracy: 0.9973\n",
      "Epoch 23/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0070 - val_accuracy: 0.9977\n",
      "Epoch 24/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0054 - val_accuracy: 0.9982\n",
      "Epoch 25/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0079 - val_accuracy: 0.9976\n",
      "Epoch 26/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0093 - val_accuracy: 0.9970\n",
      "Epoch 27/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0057 - val_accuracy: 0.9982\n",
      "Epoch 28/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0087 - val_accuracy: 0.9976\n",
      "Epoch 29/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
      "Epoch 30/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 0.9978\n",
      "Epoch 31/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0079 - val_accuracy: 0.9979\n",
      "Epoch 32/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0068 - val_accuracy: 0.9980\n",
      "Epoch 33/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0074 - val_accuracy: 0.9981\n",
      "Epoch 34/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0068 - val_accuracy: 0.9981\n",
      "Epoch 35/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 36/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0070 - val_accuracy: 0.9981\n",
      "Epoch 37/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0082 - val_accuracy: 0.9979\n",
      "Epoch 38/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0083 - val_accuracy: 0.9979\n",
      "Epoch 39/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0087 - val_accuracy: 0.9976\n",
      "Epoch 40/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0079 - val_accuracy: 0.9979\n",
      "Epoch 41/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0107 - val_accuracy: 0.9973\n",
      "Epoch 42/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0094 - val_accuracy: 0.9979\n",
      "Epoch 43/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0063 - val_accuracy: 0.9980\n",
      "Epoch 44/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0070 - val_accuracy: 0.9981\n",
      "Epoch 45/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0077 - val_accuracy: 0.9977\n",
      "Epoch 46/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0084 - val_accuracy: 0.9976\n",
      "Epoch 47/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
      "Epoch 48/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0080 - val_accuracy: 0.9980\n",
      "Epoch 49/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0109 - val_accuracy: 0.9974\n",
      "Epoch 50/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0092 - val_accuracy: 0.9977\n",
      "Epoch 51/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0098 - val_accuracy: 0.9974\n",
      "Epoch 52/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0075 - val_accuracy: 0.9977\n",
      "Epoch 53/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0100 - val_accuracy: 0.9975\n",
      "Epoch 54/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0084 - val_accuracy: 0.9978\n",
      "Epoch 55/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0103 - val_accuracy: 0.9977\n",
      "Epoch 56/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0092 - val_accuracy: 0.9977\n",
      "Epoch 57/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0080 - val_accuracy: 0.9981\n",
      "Epoch 58/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 59/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0088 - val_accuracy: 0.9978\n",
      "Epoch 60/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0067 - val_accuracy: 0.9983\n",
      "Epoch 61/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0105 - val_accuracy: 0.9979\n",
      "Epoch 62/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0105 - val_accuracy: 0.9979\n",
      "Epoch 63/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
      "Epoch 64/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0077 - val_accuracy: 0.9979\n",
      "Epoch 65/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0096 - val_accuracy: 0.9979\n",
      "Epoch 66/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0099 - val_accuracy: 0.9977\n",
      "Epoch 67/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0068 - val_accuracy: 0.9982\n",
      "Epoch 68/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0110 - val_accuracy: 0.9975\n",
      "Epoch 69/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0082 - val_accuracy: 0.9981\n",
      "Epoch 70/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0090 - val_accuracy: 0.9981\n",
      "Epoch 71/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0081 - val_accuracy: 0.9980\n",
      "Epoch 72/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0098 - val_accuracy: 0.9977\n",
      "Epoch 73/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0085 - val_accuracy: 0.9980\n",
      "Epoch 74/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0097 - val_accuracy: 0.9977\n",
      "Epoch 75/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0106 - val_accuracy: 0.9977\n",
      "Epoch 76/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0100 - val_accuracy: 0.9977\n",
      "Epoch 77/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0113 - val_accuracy: 0.9975\n",
      "Epoch 78/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
      "Epoch 79/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0120 - val_accuracy: 0.9976\n",
      "Epoch 80/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0084 - val_accuracy: 0.9981\n",
      "Epoch 81/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0095 - val_accuracy: 0.9977\n",
      "Epoch 82/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0107 - val_accuracy: 0.9977\n",
      "Epoch 83/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0123 - val_accuracy: 0.9977\n",
      "Epoch 84/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0088 - val_accuracy: 0.9977\n",
      "Epoch 85/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0122 - val_accuracy: 0.9973\n",
      "Epoch 86/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0117 - val_accuracy: 0.9977\n",
      "Epoch 87/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0090 - val_accuracy: 0.9979\n",
      "Epoch 88/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0120 - val_accuracy: 0.9975\n",
      "Epoch 89/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9983\n",
      "Epoch 90/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0108 - val_accuracy: 0.9977\n",
      "Epoch 91/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0140 - val_accuracy: 0.9974\n",
      "Epoch 92/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0082 - val_accuracy: 0.9980\n",
      "Epoch 93/100\n",
      "2800/2800 [==============================] - 3s 972us/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0098 - val_accuracy: 0.9979\n",
      "Epoch 94/100\n",
      "2800/2800 [==============================] - 3s 982us/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0122 - val_accuracy: 0.9977\n",
      "Epoch 95/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0085 - val_accuracy: 0.9980\n",
      "Epoch 96/100\n",
      "2800/2800 [==============================] - 3s 995us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0108 - val_accuracy: 0.9979\n",
      "Epoch 97/100\n",
      "2800/2800 [==============================] - 3s 974us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0086 - val_accuracy: 0.9984\n",
      "Epoch 98/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0092 - val_accuracy: 0.9979\n",
      "Epoch 99/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0094 - val_accuracy: 0.9981\n",
      "Epoch 100/100\n",
      "2800/2800 [==============================] - 3s 991us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0126 - val_accuracy: 0.9973\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–…â–…â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–†â–†â–…â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–„â–…â–…â–†â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–ˆâ–‡â–†â–‡â–…â–…â–†â–â–„â–†â–†â–†â–„â–…â–…â–…â–„â–…â–…â–„â–„â–„â–‡â–…â–…â–…â–„â–…â–„â–„â–…â–…â–„â–„â–…â–ƒâ–†â–„â–‡â–ƒ</td></tr><tr><td>epoch/val_loss</td><td>â–‡â–…â–â–‚â–‚â–‚â–â–â–â–†â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–‚â–„â–„â–‡â–†â–ƒâ–†â–…â–†â–ƒâ–„â–ƒâ–†â–„â–†â–‡â–ˆâ–…â–ˆâ–…â–ˆâ–…</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.9998</td></tr><tr><td>batch/batch_step</td><td>279995</td></tr><tr><td>batch/learning_rate</td><td>0.00331</td></tr><tr><td>batch/loss</td><td>0.00129</td></tr><tr><td>epoch/accuracy</td><td>0.9998</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00331</td></tr><tr><td>epoch/loss</td><td>0.00129</td></tr><tr><td>epoch/val_accuracy</td><td>0.99725</td></tr><tr><td>epoch/val_loss</td><td>0.01264</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_3</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/k0efe97t' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/k0efe97t</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_010351-k0efe97t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 01:08:37,875] Trial 3 finished with value: 0.004633556527551264 and parameters: {'Layer_1_units': 34, 'Activation_1': 'relu', 'n_layers': 3, 'Layer_2_units': 42, 'Activation_2': 'relu', 'Layer_3_units': 46, 'Activation_3': 'relu', 'Layer_4_units': 99, 'Activation_4': 'sigmoid', 'learning_rate': 0.003309262944811404, 'optimizer': 'adam', 'batch_size': 50}. Best is trial 2 with value: 0.003322927176486701.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_010837-gr98aehv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/gr98aehv' target=\"_blank\">Trial_4</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/gr98aehv' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/gr98aehv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.6400 - accuracy: 0.7692 - val_loss: 0.6180 - val_accuracy: 0.7689\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6133 - accuracy: 0.7692 - val_loss: 0.6113 - val_accuracy: 0.7689\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6103 - accuracy: 0.7692 - val_loss: 0.6102 - val_accuracy: 0.7689\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6097 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6100 - val_accuracy: 0.7689\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6095 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6095 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6095 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6095 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6095 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6095 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6095 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.6096 - accuracy: 0.7692 - val_loss: 0.6099 - val_accuracy: 0.7689\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–†â–ˆâ–…â–†â–‡â–†â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–â–†â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–†</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.76921</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>2e-05</td></tr><tr><td>batch/loss</td><td>0.60955</td></tr><tr><td>epoch/accuracy</td><td>0.76921</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>2e-05</td></tr><tr><td>epoch/loss</td><td>0.60956</td></tr><tr><td>epoch/val_accuracy</td><td>0.7689</td></tr><tr><td>epoch/val_loss</td><td>0.60991</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_4</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/gr98aehv' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/gr98aehv</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_010837-gr98aehv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 01:22:16,037] Trial 4 finished with value: 0.6098681926727295 and parameters: {'Layer_1_units': 43, 'Activation_1': 'relu', 'n_layers': 10, 'Layer_2_units': 36, 'Activation_2': 'relu', 'Layer_3_units': 99, 'Activation_3': 'sigmoid', 'Layer_4_units': 86, 'Activation_4': 'sigmoid', 'Layer_5_units': 34, 'Activation_5': 'sigmoid', 'Layer_6_units': 128, 'Activation_6': 'sigmoid', 'Layer_7_units': 74, 'Activation_7': 'sigmoid', 'Layer_8_units': 75, 'Activation_8': 'sigmoid', 'Layer_9_units': 103, 'Activation_9': 'sigmoid', 'Layer_10_units': 103, 'Activation_10': 'relu', 'Layer_11_units': 34, 'Activation_11': 'relu', 'learning_rate': 1.7624292663175482e-05, 'optimizer': 'sgd', 'batch_size': 20}. Best is trial 2 with value: 0.003322927176486701.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_012216-u1yxibd7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/u1yxibd7' target=\"_blank\">Trial_5</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/u1yxibd7' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/u1yxibd7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3500/3500 [==============================] - 4s 976us/step - loss: 0.5755 - accuracy: 0.7692 - val_loss: 0.5649 - val_accuracy: 0.7689\n",
      "Epoch 2/100\n",
      "3500/3500 [==============================] - 3s 957us/step - loss: 0.5643 - accuracy: 0.7692 - val_loss: 0.5644 - val_accuracy: 0.7689\n",
      "Epoch 3/100\n",
      "3500/3500 [==============================] - 3s 947us/step - loss: 0.5639 - accuracy: 0.7692 - val_loss: 0.5640 - val_accuracy: 0.7689\n",
      "Epoch 4/100\n",
      "3500/3500 [==============================] - 3s 942us/step - loss: 0.5635 - accuracy: 0.7692 - val_loss: 0.5636 - val_accuracy: 0.7689\n",
      "Epoch 5/100\n",
      "3500/3500 [==============================] - 3s 946us/step - loss: 0.5631 - accuracy: 0.7692 - val_loss: 0.5631 - val_accuracy: 0.7689\n",
      "Epoch 6/100\n",
      "3500/3500 [==============================] - 3s 945us/step - loss: 0.5626 - accuracy: 0.7692 - val_loss: 0.5627 - val_accuracy: 0.7689\n",
      "Epoch 7/100\n",
      "3500/3500 [==============================] - 3s 945us/step - loss: 0.5621 - accuracy: 0.7692 - val_loss: 0.5621 - val_accuracy: 0.7689\n",
      "Epoch 8/100\n",
      "3500/3500 [==============================] - 3s 944us/step - loss: 0.5616 - accuracy: 0.7692 - val_loss: 0.5615 - val_accuracy: 0.7689\n",
      "Epoch 9/100\n",
      "3500/3500 [==============================] - 3s 948us/step - loss: 0.5609 - accuracy: 0.7692 - val_loss: 0.5608 - val_accuracy: 0.7689\n",
      "Epoch 10/100\n",
      "3500/3500 [==============================] - 3s 943us/step - loss: 0.5602 - accuracy: 0.7692 - val_loss: 0.5601 - val_accuracy: 0.7689\n",
      "Epoch 11/100\n",
      "3500/3500 [==============================] - 3s 949us/step - loss: 0.5594 - accuracy: 0.7692 - val_loss: 0.5592 - val_accuracy: 0.7689\n",
      "Epoch 12/100\n",
      "3500/3500 [==============================] - 3s 951us/step - loss: 0.5585 - accuracy: 0.7692 - val_loss: 0.5581 - val_accuracy: 0.7689\n",
      "Epoch 13/100\n",
      "3500/3500 [==============================] - 3s 944us/step - loss: 0.5573 - accuracy: 0.7692 - val_loss: 0.5566 - val_accuracy: 0.7689\n",
      "Epoch 14/100\n",
      "3500/3500 [==============================] - 3s 947us/step - loss: 0.5556 - accuracy: 0.7692 - val_loss: 0.5550 - val_accuracy: 0.7689\n",
      "Epoch 15/100\n",
      "3500/3500 [==============================] - 3s 946us/step - loss: 0.5540 - accuracy: 0.7692 - val_loss: 0.5531 - val_accuracy: 0.7689\n",
      "Epoch 16/100\n",
      "3500/3500 [==============================] - 3s 943us/step - loss: 0.5518 - accuracy: 0.7692 - val_loss: 0.5505 - val_accuracy: 0.7689\n",
      "Epoch 17/100\n",
      "3500/3500 [==============================] - 3s 940us/step - loss: 0.5490 - accuracy: 0.7692 - val_loss: 0.5475 - val_accuracy: 0.7689\n",
      "Epoch 18/100\n",
      "3500/3500 [==============================] - 3s 947us/step - loss: 0.5458 - accuracy: 0.7692 - val_loss: 0.5439 - val_accuracy: 0.7689\n",
      "Epoch 19/100\n",
      "3500/3500 [==============================] - 3s 942us/step - loss: 0.5416 - accuracy: 0.7692 - val_loss: 0.5389 - val_accuracy: 0.7689\n",
      "Epoch 20/100\n",
      "3500/3500 [==============================] - 3s 943us/step - loss: 0.5359 - accuracy: 0.7692 - val_loss: 0.5326 - val_accuracy: 0.7689\n",
      "Epoch 21/100\n",
      "3500/3500 [==============================] - 3s 947us/step - loss: 0.5288 - accuracy: 0.7692 - val_loss: 0.5244 - val_accuracy: 0.7689\n",
      "Epoch 22/100\n",
      "3500/3500 [==============================] - 3s 941us/step - loss: 0.5192 - accuracy: 0.7692 - val_loss: 0.5131 - val_accuracy: 0.7689\n",
      "Epoch 23/100\n",
      "3500/3500 [==============================] - 3s 945us/step - loss: 0.5061 - accuracy: 0.7692 - val_loss: 0.4975 - val_accuracy: 0.7689\n",
      "Epoch 24/100\n",
      "3500/3500 [==============================] - 3s 941us/step - loss: 0.4878 - accuracy: 0.7692 - val_loss: 0.4759 - val_accuracy: 0.7689\n",
      "Epoch 25/100\n",
      "3500/3500 [==============================] - 3s 946us/step - loss: 0.4622 - accuracy: 0.7711 - val_loss: 0.4459 - val_accuracy: 0.7768\n",
      "Epoch 26/100\n",
      "3500/3500 [==============================] - 3s 983us/step - loss: 0.4282 - accuracy: 0.7912 - val_loss: 0.4073 - val_accuracy: 0.8082\n",
      "Epoch 27/100\n",
      "3500/3500 [==============================] - 3s 957us/step - loss: 0.3859 - accuracy: 0.8315 - val_loss: 0.3619 - val_accuracy: 0.8590\n",
      "Epoch 28/100\n",
      "3500/3500 [==============================] - 3s 941us/step - loss: 0.3397 - accuracy: 0.8691 - val_loss: 0.3161 - val_accuracy: 0.8850\n",
      "Epoch 29/100\n",
      "3500/3500 [==============================] - 3s 945us/step - loss: 0.2965 - accuracy: 0.8940 - val_loss: 0.2763 - val_accuracy: 0.9020\n",
      "Epoch 30/100\n",
      "3500/3500 [==============================] - 3s 948us/step - loss: 0.2610 - accuracy: 0.9085 - val_loss: 0.2454 - val_accuracy: 0.9130\n",
      "Epoch 31/100\n",
      "3500/3500 [==============================] - 3s 939us/step - loss: 0.2344 - accuracy: 0.9181 - val_loss: 0.2232 - val_accuracy: 0.9193\n",
      "Epoch 32/100\n",
      "3500/3500 [==============================] - 3s 942us/step - loss: 0.2154 - accuracy: 0.9247 - val_loss: 0.2076 - val_accuracy: 0.9251\n",
      "Epoch 33/100\n",
      "3500/3500 [==============================] - 3s 945us/step - loss: 0.2022 - accuracy: 0.9286 - val_loss: 0.1969 - val_accuracy: 0.9276\n",
      "Epoch 34/100\n",
      "3500/3500 [==============================] - 3s 940us/step - loss: 0.1930 - accuracy: 0.9315 - val_loss: 0.1893 - val_accuracy: 0.9312\n",
      "Epoch 35/100\n",
      "3500/3500 [==============================] - 3s 943us/step - loss: 0.1863 - accuracy: 0.9336 - val_loss: 0.1837 - val_accuracy: 0.9321\n",
      "Epoch 36/100\n",
      "3500/3500 [==============================] - 3s 951us/step - loss: 0.1813 - accuracy: 0.9354 - val_loss: 0.1799 - val_accuracy: 0.9328\n",
      "Epoch 37/100\n",
      "3500/3500 [==============================] - 3s 948us/step - loss: 0.1774 - accuracy: 0.9366 - val_loss: 0.1762 - val_accuracy: 0.9362\n",
      "Epoch 38/100\n",
      "3500/3500 [==============================] - 3s 951us/step - loss: 0.1742 - accuracy: 0.9376 - val_loss: 0.1734 - val_accuracy: 0.9366\n",
      "Epoch 39/100\n",
      "3500/3500 [==============================] - 3s 949us/step - loss: 0.1716 - accuracy: 0.9387 - val_loss: 0.1710 - val_accuracy: 0.9378\n",
      "Epoch 40/100\n",
      "3500/3500 [==============================] - 3s 941us/step - loss: 0.1693 - accuracy: 0.9394 - val_loss: 0.1693 - val_accuracy: 0.9380\n",
      "Epoch 41/100\n",
      "3500/3500 [==============================] - 3s 946us/step - loss: 0.1673 - accuracy: 0.9402 - val_loss: 0.1672 - val_accuracy: 0.9393\n",
      "Epoch 42/100\n",
      "3500/3500 [==============================] - 3s 980us/step - loss: 0.1655 - accuracy: 0.9409 - val_loss: 0.1657 - val_accuracy: 0.9401\n",
      "Epoch 43/100\n",
      "3500/3500 [==============================] - 3s 941us/step - loss: 0.1638 - accuracy: 0.9414 - val_loss: 0.1641 - val_accuracy: 0.9409\n",
      "Epoch 44/100\n",
      "3500/3500 [==============================] - 3s 943us/step - loss: 0.1623 - accuracy: 0.9420 - val_loss: 0.1626 - val_accuracy: 0.9416\n",
      "Epoch 45/100\n",
      "3500/3500 [==============================] - 3s 948us/step - loss: 0.1608 - accuracy: 0.9426 - val_loss: 0.1612 - val_accuracy: 0.9426\n",
      "Epoch 46/100\n",
      "3500/3500 [==============================] - 3s 948us/step - loss: 0.1595 - accuracy: 0.9432 - val_loss: 0.1602 - val_accuracy: 0.9426\n",
      "Epoch 47/100\n",
      "3500/3500 [==============================] - 3s 945us/step - loss: 0.1582 - accuracy: 0.9438 - val_loss: 0.1587 - val_accuracy: 0.9439\n",
      "Epoch 48/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.1569 - accuracy: 0.9442 - val_loss: 0.1576 - val_accuracy: 0.9446\n",
      "Epoch 49/100\n",
      "3500/3500 [==============================] - 3s 944us/step - loss: 0.1557 - accuracy: 0.9448 - val_loss: 0.1564 - val_accuracy: 0.9450\n",
      "Epoch 50/100\n",
      "3500/3500 [==============================] - 3s 963us/step - loss: 0.1546 - accuracy: 0.9452 - val_loss: 0.1552 - val_accuracy: 0.9455\n",
      "Epoch 51/100\n",
      "3500/3500 [==============================] - 3s 946us/step - loss: 0.1534 - accuracy: 0.9461 - val_loss: 0.1541 - val_accuracy: 0.9459\n",
      "Epoch 52/100\n",
      "3500/3500 [==============================] - 3s 959us/step - loss: 0.1523 - accuracy: 0.9465 - val_loss: 0.1530 - val_accuracy: 0.9464\n",
      "Epoch 53/100\n",
      "3500/3500 [==============================] - 3s 948us/step - loss: 0.1513 - accuracy: 0.9470 - val_loss: 0.1519 - val_accuracy: 0.9470\n",
      "Epoch 54/100\n",
      "3500/3500 [==============================] - 3s 957us/step - loss: 0.1502 - accuracy: 0.9475 - val_loss: 0.1511 - val_accuracy: 0.9474\n",
      "Epoch 55/100\n",
      "3500/3500 [==============================] - 3s 954us/step - loss: 0.1491 - accuracy: 0.9479 - val_loss: 0.1500 - val_accuracy: 0.9479\n",
      "Epoch 56/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.1481 - accuracy: 0.9484 - val_loss: 0.1489 - val_accuracy: 0.9487\n",
      "Epoch 57/100\n",
      "3500/3500 [==============================] - 3s 945us/step - loss: 0.1471 - accuracy: 0.9489 - val_loss: 0.1479 - val_accuracy: 0.9488\n",
      "Epoch 58/100\n",
      "3500/3500 [==============================] - 3s 964us/step - loss: 0.1460 - accuracy: 0.9493 - val_loss: 0.1468 - val_accuracy: 0.9491\n",
      "Epoch 59/100\n",
      "3500/3500 [==============================] - 3s 947us/step - loss: 0.1450 - accuracy: 0.9498 - val_loss: 0.1459 - val_accuracy: 0.9502\n",
      "Epoch 60/100\n",
      "3500/3500 [==============================] - 3s 944us/step - loss: 0.1440 - accuracy: 0.9503 - val_loss: 0.1448 - val_accuracy: 0.9495\n",
      "Epoch 61/100\n",
      "3500/3500 [==============================] - 3s 946us/step - loss: 0.1429 - accuracy: 0.9510 - val_loss: 0.1439 - val_accuracy: 0.9508\n",
      "Epoch 62/100\n",
      "3500/3500 [==============================] - 3s 947us/step - loss: 0.1419 - accuracy: 0.9517 - val_loss: 0.1427 - val_accuracy: 0.9513\n",
      "Epoch 63/100\n",
      "3500/3500 [==============================] - 3s 942us/step - loss: 0.1408 - accuracy: 0.9523 - val_loss: 0.1418 - val_accuracy: 0.9517\n",
      "Epoch 64/100\n",
      "3500/3500 [==============================] - 3s 955us/step - loss: 0.1397 - accuracy: 0.9530 - val_loss: 0.1408 - val_accuracy: 0.9517\n",
      "Epoch 65/100\n",
      "3500/3500 [==============================] - 3s 949us/step - loss: 0.1386 - accuracy: 0.9536 - val_loss: 0.1400 - val_accuracy: 0.9521\n",
      "Epoch 66/100\n",
      "3500/3500 [==============================] - 3s 956us/step - loss: 0.1375 - accuracy: 0.9540 - val_loss: 0.1385 - val_accuracy: 0.9525\n",
      "Epoch 67/100\n",
      "3500/3500 [==============================] - 3s 944us/step - loss: 0.1364 - accuracy: 0.9546 - val_loss: 0.1374 - val_accuracy: 0.9537\n",
      "Epoch 68/100\n",
      "3500/3500 [==============================] - 3s 945us/step - loss: 0.1353 - accuracy: 0.9551 - val_loss: 0.1364 - val_accuracy: 0.9541\n",
      "Epoch 69/100\n",
      "3500/3500 [==============================] - 3s 948us/step - loss: 0.1342 - accuracy: 0.9556 - val_loss: 0.1353 - val_accuracy: 0.9545\n",
      "Epoch 70/100\n",
      "3500/3500 [==============================] - 3s 945us/step - loss: 0.1330 - accuracy: 0.9562 - val_loss: 0.1341 - val_accuracy: 0.9555\n",
      "Epoch 71/100\n",
      "3500/3500 [==============================] - 3s 941us/step - loss: 0.1318 - accuracy: 0.9569 - val_loss: 0.1330 - val_accuracy: 0.9560\n",
      "Epoch 72/100\n",
      "3500/3500 [==============================] - 3s 949us/step - loss: 0.1306 - accuracy: 0.9574 - val_loss: 0.1322 - val_accuracy: 0.9563\n",
      "Epoch 73/100\n",
      "3500/3500 [==============================] - 3s 952us/step - loss: 0.1294 - accuracy: 0.9579 - val_loss: 0.1306 - val_accuracy: 0.9571\n",
      "Epoch 74/100\n",
      "3500/3500 [==============================] - 3s 945us/step - loss: 0.1282 - accuracy: 0.9588 - val_loss: 0.1294 - val_accuracy: 0.9578\n",
      "Epoch 75/100\n",
      "3500/3500 [==============================] - 3s 948us/step - loss: 0.1269 - accuracy: 0.9592 - val_loss: 0.1283 - val_accuracy: 0.9582\n",
      "Epoch 76/100\n",
      "3500/3500 [==============================] - 3s 943us/step - loss: 0.1256 - accuracy: 0.9598 - val_loss: 0.1271 - val_accuracy: 0.9586\n",
      "Epoch 77/100\n",
      "3500/3500 [==============================] - 3s 959us/step - loss: 0.1244 - accuracy: 0.9605 - val_loss: 0.1259 - val_accuracy: 0.9594\n",
      "Epoch 78/100\n",
      "3500/3500 [==============================] - 3s 947us/step - loss: 0.1230 - accuracy: 0.9612 - val_loss: 0.1245 - val_accuracy: 0.9599\n",
      "Epoch 79/100\n",
      "3500/3500 [==============================] - 3s 947us/step - loss: 0.1217 - accuracy: 0.9618 - val_loss: 0.1232 - val_accuracy: 0.9603\n",
      "Epoch 80/100\n",
      "3500/3500 [==============================] - 3s 941us/step - loss: 0.1204 - accuracy: 0.9626 - val_loss: 0.1222 - val_accuracy: 0.9611\n",
      "Epoch 81/100\n",
      "3500/3500 [==============================] - 3s 943us/step - loss: 0.1191 - accuracy: 0.9630 - val_loss: 0.1207 - val_accuracy: 0.9614\n",
      "Epoch 82/100\n",
      "3500/3500 [==============================] - 3s 948us/step - loss: 0.1177 - accuracy: 0.9637 - val_loss: 0.1194 - val_accuracy: 0.9617\n",
      "Epoch 83/100\n",
      "3500/3500 [==============================] - 3s 961us/step - loss: 0.1164 - accuracy: 0.9643 - val_loss: 0.1182 - val_accuracy: 0.9622\n",
      "Epoch 84/100\n",
      "3500/3500 [==============================] - 3s 948us/step - loss: 0.1150 - accuracy: 0.9649 - val_loss: 0.1171 - val_accuracy: 0.9631\n",
      "Epoch 85/100\n",
      "3500/3500 [==============================] - 3s 941us/step - loss: 0.1137 - accuracy: 0.9655 - val_loss: 0.1160 - val_accuracy: 0.9638\n",
      "Epoch 86/100\n",
      "3500/3500 [==============================] - 3s 968us/step - loss: 0.1123 - accuracy: 0.9662 - val_loss: 0.1143 - val_accuracy: 0.9640\n",
      "Epoch 87/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.1110 - accuracy: 0.9667 - val_loss: 0.1131 - val_accuracy: 0.9653\n",
      "Epoch 88/100\n",
      "3500/3500 [==============================] - 3s 941us/step - loss: 0.1097 - accuracy: 0.9673 - val_loss: 0.1119 - val_accuracy: 0.9654\n",
      "Epoch 89/100\n",
      "3500/3500 [==============================] - 3s 943us/step - loss: 0.1084 - accuracy: 0.9680 - val_loss: 0.1107 - val_accuracy: 0.9665\n",
      "Epoch 90/100\n",
      "3500/3500 [==============================] - 3s 944us/step - loss: 0.1070 - accuracy: 0.9689 - val_loss: 0.1094 - val_accuracy: 0.9671\n",
      "Epoch 91/100\n",
      "3500/3500 [==============================] - 3s 946us/step - loss: 0.1057 - accuracy: 0.9693 - val_loss: 0.1081 - val_accuracy: 0.9676\n",
      "Epoch 92/100\n",
      "3500/3500 [==============================] - 3s 947us/step - loss: 0.1044 - accuracy: 0.9700 - val_loss: 0.1068 - val_accuracy: 0.9686\n",
      "Epoch 93/100\n",
      "3500/3500 [==============================] - 3s 947us/step - loss: 0.1031 - accuracy: 0.9708 - val_loss: 0.1057 - val_accuracy: 0.9695\n",
      "Epoch 94/100\n",
      "3500/3500 [==============================] - 3s 941us/step - loss: 0.1018 - accuracy: 0.9715 - val_loss: 0.1044 - val_accuracy: 0.9699\n",
      "Epoch 95/100\n",
      "3500/3500 [==============================] - 3s 946us/step - loss: 0.1006 - accuracy: 0.9722 - val_loss: 0.1031 - val_accuracy: 0.9707\n",
      "Epoch 96/100\n",
      "3500/3500 [==============================] - 3s 945us/step - loss: 0.0993 - accuracy: 0.9729 - val_loss: 0.1019 - val_accuracy: 0.9711\n",
      "Epoch 97/100\n",
      "3500/3500 [==============================] - 3s 946us/step - loss: 0.0981 - accuracy: 0.9735 - val_loss: 0.1007 - val_accuracy: 0.9717\n",
      "Epoch 98/100\n",
      "3500/3500 [==============================] - 3s 943us/step - loss: 0.0969 - accuracy: 0.9742 - val_loss: 0.0995 - val_accuracy: 0.9722\n",
      "Epoch 99/100\n",
      "3500/3500 [==============================] - 3s 946us/step - loss: 0.0957 - accuracy: 0.9749 - val_loss: 0.0983 - val_accuracy: 0.9728\n",
      "Epoch 100/100\n",
      "3500/3500 [==============================] - 3s 947us/step - loss: 0.0945 - accuracy: 0.9753 - val_loss: 0.0972 - val_accuracy: 0.9732\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–‚â–â–â–â–â–â–â–â–â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–â–â–â–â–â–â–â–â–â–‚â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–†â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–â–â–â–â–â–â–„â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.97525</td></tr><tr><td>batch/batch_step</td><td>349995</td></tr><tr><td>batch/learning_rate</td><td>0.00045</td></tr><tr><td>batch/loss</td><td>0.09451</td></tr><tr><td>epoch/accuracy</td><td>0.97525</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00045</td></tr><tr><td>epoch/loss</td><td>0.09451</td></tr><tr><td>epoch/val_accuracy</td><td>0.97315</td></tr><tr><td>epoch/val_loss</td><td>0.09719</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_5</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/u1yxibd7' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/u1yxibd7</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_012216-u1yxibd7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 01:27:49,761] Trial 5 finished with value: 0.09692402780056 and parameters: {'Layer_1_units': 74, 'Activation_1': 'relu', 'n_layers': 4, 'Layer_2_units': 42, 'Activation_2': 'sigmoid', 'Layer_3_units': 55, 'Activation_3': 'sigmoid', 'Layer_4_units': 81, 'Activation_4': 'relu', 'Layer_5_units': 115, 'Activation_5': 'relu', 'learning_rate': 0.0004506876885288704, 'optimizer': 'sgd', 'batch_size': 40}. Best is trial 2 with value: 0.003322927176486701.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_012749-bwkhuibv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/bwkhuibv' target=\"_blank\">Trial_6</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/bwkhuibv' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/bwkhuibv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.5850 - accuracy: 0.7645 - val_loss: 0.5814 - val_accuracy: 0.7689\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 7s 988us/step - loss: 0.5809 - accuracy: 0.7692 - val_loss: 0.5811 - val_accuracy: 0.7689\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 7s 994us/step - loss: 0.5807 - accuracy: 0.7692 - val_loss: 0.5808 - val_accuracy: 0.7689\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.5804 - accuracy: 0.7692 - val_loss: 0.5807 - val_accuracy: 0.7689\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.5801 - accuracy: 0.7692 - val_loss: 0.5803 - val_accuracy: 0.7689\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5798 - accuracy: 0.7692 - val_loss: 0.5801 - val_accuracy: 0.7689\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 7s 996us/step - loss: 0.5795 - accuracy: 0.7692 - val_loss: 0.5797 - val_accuracy: 0.7689\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 7s 997us/step - loss: 0.5792 - accuracy: 0.7692 - val_loss: 0.5794 - val_accuracy: 0.7689\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5789 - accuracy: 0.7692 - val_loss: 0.5791 - val_accuracy: 0.7689\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 7s 997us/step - loss: 0.5787 - accuracy: 0.7692 - val_loss: 0.5789 - val_accuracy: 0.7689\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.5784 - accuracy: 0.7692 - val_loss: 0.5788 - val_accuracy: 0.7689\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 7s 992us/step - loss: 0.5781 - accuracy: 0.7692 - val_loss: 0.5784 - val_accuracy: 0.7689\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 7s 997us/step - loss: 0.5779 - accuracy: 0.7692 - val_loss: 0.5781 - val_accuracy: 0.7689\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.5776 - accuracy: 0.7692 - val_loss: 0.5778 - val_accuracy: 0.7689\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.5774 - accuracy: 0.7692 - val_loss: 0.5777 - val_accuracy: 0.7689\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 7s 995us/step - loss: 0.5771 - accuracy: 0.7692 - val_loss: 0.5773 - val_accuracy: 0.7689\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 7s 994us/step - loss: 0.5768 - accuracy: 0.7692 - val_loss: 0.5771 - val_accuracy: 0.7689\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 7s 999us/step - loss: 0.5766 - accuracy: 0.7692 - val_loss: 0.5769 - val_accuracy: 0.7689\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 7s 987us/step - loss: 0.5763 - accuracy: 0.7692 - val_loss: 0.5765 - val_accuracy: 0.7689\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 7s 995us/step - loss: 0.5760 - accuracy: 0.7692 - val_loss: 0.5765 - val_accuracy: 0.7689\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.5758 - accuracy: 0.7692 - val_loss: 0.5760 - val_accuracy: 0.7689\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 7s 996us/step - loss: 0.5756 - accuracy: 0.7692 - val_loss: 0.5758 - val_accuracy: 0.7689\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 7s 988us/step - loss: 0.5753 - accuracy: 0.7692 - val_loss: 0.5755 - val_accuracy: 0.7689\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.5751 - accuracy: 0.7692 - val_loss: 0.5753 - val_accuracy: 0.7689\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.5748 - accuracy: 0.7692 - val_loss: 0.5750 - val_accuracy: 0.7689\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 7s 988us/step - loss: 0.5746 - accuracy: 0.7692 - val_loss: 0.5749 - val_accuracy: 0.7689\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 7s 996us/step - loss: 0.5743 - accuracy: 0.7692 - val_loss: 0.5746 - val_accuracy: 0.7689\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5741 - accuracy: 0.7692 - val_loss: 0.5743 - val_accuracy: 0.7689\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 7s 989us/step - loss: 0.5738 - accuracy: 0.7692 - val_loss: 0.5740 - val_accuracy: 0.7689\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.5736 - accuracy: 0.7692 - val_loss: 0.5740 - val_accuracy: 0.7689\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 7s 996us/step - loss: 0.5734 - accuracy: 0.7692 - val_loss: 0.5736 - val_accuracy: 0.7689\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.5732 - accuracy: 0.7692 - val_loss: 0.5733 - val_accuracy: 0.7689\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 7s 992us/step - loss: 0.5729 - accuracy: 0.7692 - val_loss: 0.5731 - val_accuracy: 0.7689\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 7s 988us/step - loss: 0.5727 - accuracy: 0.7692 - val_loss: 0.5729 - val_accuracy: 0.7689\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 7s 987us/step - loss: 0.5725 - accuracy: 0.7692 - val_loss: 0.5727 - val_accuracy: 0.7689\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 7s 993us/step - loss: 0.5722 - accuracy: 0.7692 - val_loss: 0.5724 - val_accuracy: 0.7689\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 7s 996us/step - loss: 0.5719 - accuracy: 0.7692 - val_loss: 0.5729 - val_accuracy: 0.7689\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.5718 - accuracy: 0.7692 - val_loss: 0.5720 - val_accuracy: 0.7689\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 7s 992us/step - loss: 0.5716 - accuracy: 0.7692 - val_loss: 0.5718 - val_accuracy: 0.7689\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 7s 993us/step - loss: 0.5713 - accuracy: 0.7692 - val_loss: 0.5715 - val_accuracy: 0.7689\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5711 - accuracy: 0.7692 - val_loss: 0.5713 - val_accuracy: 0.7689\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.5709 - accuracy: 0.7692 - val_loss: 0.5711 - val_accuracy: 0.7689\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.5707 - accuracy: 0.7692 - val_loss: 0.5709 - val_accuracy: 0.7689\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 7s 988us/step - loss: 0.5705 - accuracy: 0.7692 - val_loss: 0.5708 - val_accuracy: 0.7689\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5703 - accuracy: 0.7692 - val_loss: 0.5705 - val_accuracy: 0.7689\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.5701 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5700 - val_accuracy: 0.7689\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5696 - accuracy: 0.7692 - val_loss: 0.5700 - val_accuracy: 0.7689\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5694 - accuracy: 0.7692 - val_loss: 0.5697 - val_accuracy: 0.7689\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 7s 996us/step - loss: 0.5692 - accuracy: 0.7692 - val_loss: 0.5695 - val_accuracy: 0.7689\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 7s 993us/step - loss: 0.5690 - accuracy: 0.7692 - val_loss: 0.5692 - val_accuracy: 0.7689\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 7s 994us/step - loss: 0.5688 - accuracy: 0.7692 - val_loss: 0.5690 - val_accuracy: 0.7689\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 7s 995us/step - loss: 0.5686 - accuracy: 0.7692 - val_loss: 0.5688 - val_accuracy: 0.7689\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 7s 993us/step - loss: 0.5684 - accuracy: 0.7692 - val_loss: 0.5687 - val_accuracy: 0.7689\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5682 - accuracy: 0.7692 - val_loss: 0.5685 - val_accuracy: 0.7689\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 7s 987us/step - loss: 0.5680 - accuracy: 0.7692 - val_loss: 0.5682 - val_accuracy: 0.7689\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 7s 995us/step - loss: 0.5678 - accuracy: 0.7692 - val_loss: 0.5680 - val_accuracy: 0.7689\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.5676 - accuracy: 0.7692 - val_loss: 0.5680 - val_accuracy: 0.7689\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5674 - accuracy: 0.7692 - val_loss: 0.5679 - val_accuracy: 0.7689\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5672 - accuracy: 0.7692 - val_loss: 0.5675 - val_accuracy: 0.7689\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5670 - accuracy: 0.7692 - val_loss: 0.5673 - val_accuracy: 0.7689\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5669 - accuracy: 0.7692 - val_loss: 0.5671 - val_accuracy: 0.7689\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 7s 992us/step - loss: 0.5667 - accuracy: 0.7692 - val_loss: 0.5670 - val_accuracy: 0.7689\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.5665 - accuracy: 0.7692 - val_loss: 0.5667 - val_accuracy: 0.7689\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 7s 992us/step - loss: 0.5663 - accuracy: 0.7692 - val_loss: 0.5665 - val_accuracy: 0.7689\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 7s 993us/step - loss: 0.5661 - accuracy: 0.7692 - val_loss: 0.5664 - val_accuracy: 0.7689\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 7s 992us/step - loss: 0.5659 - accuracy: 0.7692 - val_loss: 0.5661 - val_accuracy: 0.7689\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.5657 - accuracy: 0.7692 - val_loss: 0.5660 - val_accuracy: 0.7689\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.5655 - accuracy: 0.7692 - val_loss: 0.5660 - val_accuracy: 0.7689\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.5654 - accuracy: 0.7692 - val_loss: 0.5656 - val_accuracy: 0.7689\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 7s 989us/step - loss: 0.5652 - accuracy: 0.7692 - val_loss: 0.5654 - val_accuracy: 0.7689\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 7s 992us/step - loss: 0.5650 - accuracy: 0.7692 - val_loss: 0.5654 - val_accuracy: 0.7689\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5648 - accuracy: 0.7692 - val_loss: 0.5652 - val_accuracy: 0.7689\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 7s 994us/step - loss: 0.5647 - accuracy: 0.7692 - val_loss: 0.5651 - val_accuracy: 0.7689\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 7s 989us/step - loss: 0.5645 - accuracy: 0.7692 - val_loss: 0.5648 - val_accuracy: 0.7689\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 7s 993us/step - loss: 0.5644 - accuracy: 0.7692 - val_loss: 0.5646 - val_accuracy: 0.7689\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5642 - accuracy: 0.7692 - val_loss: 0.5650 - val_accuracy: 0.7689\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.5640 - accuracy: 0.7692 - val_loss: 0.5643 - val_accuracy: 0.7689\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 7s 989us/step - loss: 0.5638 - accuracy: 0.7692 - val_loss: 0.5644 - val_accuracy: 0.7689\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 7s 995us/step - loss: 0.5637 - accuracy: 0.7692 - val_loss: 0.5639 - val_accuracy: 0.7689\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 7s 992us/step - loss: 0.5635 - accuracy: 0.7692 - val_loss: 0.5643 - val_accuracy: 0.7689\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5634 - accuracy: 0.7692 - val_loss: 0.5636 - val_accuracy: 0.7689\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 7s 994us/step - loss: 0.5632 - accuracy: 0.7692 - val_loss: 0.5634 - val_accuracy: 0.7689\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 7s 993us/step - loss: 0.5630 - accuracy: 0.7692 - val_loss: 0.5633 - val_accuracy: 0.7689\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5628 - accuracy: 0.7692 - val_loss: 0.5631 - val_accuracy: 0.7689\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.5627 - accuracy: 0.7692 - val_loss: 0.5629 - val_accuracy: 0.7689\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 7s 993us/step - loss: 0.5625 - accuracy: 0.7692 - val_loss: 0.5628 - val_accuracy: 0.7689\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.5624 - accuracy: 0.7692 - val_loss: 0.5626 - val_accuracy: 0.7689\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 7s 992us/step - loss: 0.5622 - accuracy: 0.7692 - val_loss: 0.5625 - val_accuracy: 0.7689\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 7s 993us/step - loss: 0.5621 - accuracy: 0.7692 - val_loss: 0.5623 - val_accuracy: 0.7689\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 7s 996us/step - loss: 0.5619 - accuracy: 0.7692 - val_loss: 0.5622 - val_accuracy: 0.7689\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 7s 997us/step - loss: 0.5618 - accuracy: 0.7692 - val_loss: 0.5620 - val_accuracy: 0.7689\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 7s 994us/step - loss: 0.5616 - accuracy: 0.7692 - val_loss: 0.5619 - val_accuracy: 0.7689\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 7s 989us/step - loss: 0.5615 - accuracy: 0.7692 - val_loss: 0.5617 - val_accuracy: 0.7689\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 7s 994us/step - loss: 0.5613 - accuracy: 0.7692 - val_loss: 0.5616 - val_accuracy: 0.7689\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 7s 994us/step - loss: 0.5612 - accuracy: 0.7692 - val_loss: 0.5614 - val_accuracy: 0.7689\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 7s 992us/step - loss: 0.5610 - accuracy: 0.7692 - val_loss: 0.5613 - val_accuracy: 0.7689\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5609 - accuracy: 0.7692 - val_loss: 0.5612 - val_accuracy: 0.7689\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.5607 - accuracy: 0.7692 - val_loss: 0.5610 - val_accuracy: 0.7689\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 7s 996us/step - loss: 0.5606 - accuracy: 0.7692 - val_loss: 0.5609 - val_accuracy: 0.7689\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–†â–‡â–†â–ˆâ–‡â–‡â–†â–‡â–†â–‡â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–†â–†â–†â–†â–†</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–‡â–ˆâ–ˆâ–‡â–‡â–†â–‡â–†â–†â–†â–…â–…â–…â–…â–ƒâ–ƒâ–…â–…â–„â–…â–„â–„â–†â–„â–„â–„â–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚</td></tr><tr><td>epoch/accuracy</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.76919</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00253</td></tr><tr><td>batch/loss</td><td>0.56058</td></tr><tr><td>epoch/accuracy</td><td>0.76921</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00253</td></tr><tr><td>epoch/loss</td><td>0.56056</td></tr><tr><td>epoch/val_accuracy</td><td>0.7689</td></tr><tr><td>epoch/val_loss</td><td>0.56086</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_6</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/bwkhuibv' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/bwkhuibv</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_012749-bwkhuibv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 01:39:26,891] Trial 6 finished with value: 0.5608305037021637 and parameters: {'Layer_1_units': 58, 'Activation_1': 'sigmoid', 'n_layers': 8, 'Layer_2_units': 41, 'Activation_2': 'sigmoid', 'Layer_3_units': 46, 'Activation_3': 'relu', 'Layer_4_units': 40, 'Activation_4': 'sigmoid', 'Layer_5_units': 93, 'Activation_5': 'sigmoid', 'Layer_6_units': 40, 'Activation_6': 'sigmoid', 'Layer_7_units': 63, 'Activation_7': 'sigmoid', 'Layer_8_units': 86, 'Activation_8': 'relu', 'Layer_9_units': 32, 'Activation_9': 'sigmoid', 'learning_rate': 0.0025346866923988405, 'optimizer': 'sgd', 'batch_size': 20}. Best is trial 2 with value: 0.003322927176486701.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_013926-6wukx4e8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/6wukx4e8' target=\"_blank\">Trial_7</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/6wukx4e8' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/6wukx4e8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5971 - accuracy: 0.7692 - val_loss: 0.5786 - val_accuracy: 0.7689\n",
      "Epoch 2/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5736 - accuracy: 0.7692 - val_loss: 0.5715 - val_accuracy: 0.7689\n",
      "Epoch 3/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5704 - accuracy: 0.7692 - val_loss: 0.5704 - val_accuracy: 0.7689\n",
      "Epoch 4/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 5/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 6/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 7/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 8/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 9/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 10/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 11/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 12/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 13/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 14/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 15/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 16/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 17/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 18/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 19/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 20/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 21/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 22/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 23/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 24/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 25/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 26/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 27/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 28/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 29/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 30/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 31/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 32/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 33/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 34/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 35/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 36/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 37/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 38/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5702 - val_accuracy: 0.7689\n",
      "Epoch 39/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 40/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 41/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 42/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 43/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 44/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 45/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 46/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 47/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 48/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 49/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 50/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 51/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 52/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 53/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 54/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 55/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 56/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 57/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 58/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 59/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 60/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 61/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 62/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 63/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 64/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 65/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 66/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 67/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 68/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 69/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 70/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 71/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 72/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 73/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 74/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 75/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 76/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 77/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 78/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 79/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 80/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 81/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 82/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 83/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 84/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 85/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 86/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 87/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 88/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 89/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 90/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 91/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 92/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 93/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 94/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 95/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 96/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 97/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 98/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 99/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n",
      "Epoch 100/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7692 - val_loss: 0.5701 - val_accuracy: 0.7689\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–…â–„â–‡â–‡â–†â–†â–â–ƒâ–†â–†â–†â–†â–‡â–…â–ƒâ–†â–†â–†â–†â–†â–†â–‚â–†â–†â–†â–‡â–…â–‡â–„â–„â–†â–‡â–ˆâ–†â–†â–†â–†â–‡â–†â–…</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–†â–‚â–â–„â–„â–…â–…â–„â–„â–„â–…â–…â–ƒâ–…â–…â–„â–„â–…â–…â–„â–„â–…â–…â–„â–„â–„â–…â–„â–â–…â–ˆâ–„â–…â–…â–…â–…â–„â–„â–…â–…</td></tr><tr><td>epoch/accuracy</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.76918</td></tr><tr><td>batch/batch_step</td><td>279995</td></tr><tr><td>batch/learning_rate</td><td>9e-05</td></tr><tr><td>batch/loss</td><td>0.56971</td></tr><tr><td>epoch/accuracy</td><td>0.76921</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>9e-05</td></tr><tr><td>epoch/loss</td><td>0.56969</td></tr><tr><td>epoch/val_accuracy</td><td>0.7689</td></tr><tr><td>epoch/val_loss</td><td>0.57005</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_7</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/6wukx4e8' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/6wukx4e8</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_013926-6wukx4e8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 01:44:12,172] Trial 7 finished with value: 0.5700165152549743 and parameters: {'Layer_1_units': 58, 'Activation_1': 'sigmoid', 'n_layers': 5, 'Layer_2_units': 54, 'Activation_2': 'relu', 'Layer_3_units': 73, 'Activation_3': 'sigmoid', 'Layer_4_units': 33, 'Activation_4': 'sigmoid', 'Layer_5_units': 110, 'Activation_5': 'relu', 'Layer_6_units': 71, 'Activation_6': 'sigmoid', 'learning_rate': 8.62521745301915e-05, 'optimizer': 'sgd', 'batch_size': 50}. Best is trial 2 with value: 0.003322927176486701.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_014412-cbsfyp2a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/cbsfyp2a' target=\"_blank\">Trial_8</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/cbsfyp2a' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/cbsfyp2a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1775 - accuracy: 0.9310 - val_loss: 0.0803 - val_accuracy: 0.9778\n",
      "Epoch 2/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0528 - accuracy: 0.9876 - val_loss: 0.0291 - val_accuracy: 0.9955\n",
      "Epoch 3/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0264 - accuracy: 0.9960 - val_loss: 0.0228 - val_accuracy: 0.9967\n",
      "Epoch 4/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0211 - accuracy: 0.9968 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
      "Epoch 5/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0180 - accuracy: 0.9973 - val_loss: 0.0155 - val_accuracy: 0.9981\n",
      "Epoch 6/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0160 - accuracy: 0.9976 - val_loss: 0.0148 - val_accuracy: 0.9979\n",
      "Epoch 7/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0147 - accuracy: 0.9977 - val_loss: 0.0133 - val_accuracy: 0.9977\n",
      "Epoch 8/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0136 - accuracy: 0.9980 - val_loss: 0.0123 - val_accuracy: 0.9983\n",
      "Epoch 9/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0127 - accuracy: 0.9982 - val_loss: 0.0156 - val_accuracy: 0.9968\n",
      "Epoch 10/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.0134 - val_accuracy: 0.9975\n",
      "Epoch 11/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0117 - accuracy: 0.9981 - val_loss: 0.0118 - val_accuracy: 0.9979\n",
      "Epoch 12/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0109 - accuracy: 0.9984 - val_loss: 0.0127 - val_accuracy: 0.9973\n",
      "Epoch 13/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.0116 - val_accuracy: 0.9975\n",
      "Epoch 14/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0102 - accuracy: 0.9984 - val_loss: 0.0107 - val_accuracy: 0.9981\n",
      "Epoch 15/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
      "Epoch 16/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0095 - accuracy: 0.9986 - val_loss: 0.0091 - val_accuracy: 0.9985\n",
      "Epoch 17/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0092 - accuracy: 0.9987 - val_loss: 0.0087 - val_accuracy: 0.9987\n",
      "Epoch 18/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0087 - val_accuracy: 0.9984\n",
      "Epoch 19/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.0080 - val_accuracy: 0.9989\n",
      "Epoch 20/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.0083 - val_accuracy: 0.9987\n",
      "Epoch 21/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0084 - accuracy: 0.9987 - val_loss: 0.0105 - val_accuracy: 0.9979\n",
      "Epoch 22/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0082 - accuracy: 0.9987 - val_loss: 0.0113 - val_accuracy: 0.9976\n",
      "Epoch 23/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.0081 - val_accuracy: 0.9986\n",
      "Epoch 24/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0077 - accuracy: 0.9989 - val_loss: 0.0113 - val_accuracy: 0.9977\n",
      "Epoch 25/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.0082 - val_accuracy: 0.9985\n",
      "Epoch 26/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.0177 - val_accuracy: 0.9958\n",
      "Epoch 27/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0075 - accuracy: 0.9989 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
      "Epoch 28/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.0081 - val_accuracy: 0.9982\n",
      "Epoch 29/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.0088 - val_accuracy: 0.9984\n",
      "Epoch 30/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.0165 - val_accuracy: 0.9962\n",
      "Epoch 31/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.0093 - val_accuracy: 0.9979\n",
      "Epoch 32/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 0.0069 - val_accuracy: 0.9990\n",
      "Epoch 33/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0067 - accuracy: 0.9990 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
      "Epoch 34/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.0079 - val_accuracy: 0.9983\n",
      "Epoch 35/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0070 - val_accuracy: 0.9990\n",
      "Epoch 36/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.0076 - val_accuracy: 0.9985\n",
      "Epoch 37/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.0093 - val_accuracy: 0.9981\n",
      "Epoch 38/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.0123 - val_accuracy: 0.9977\n",
      "Epoch 39/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.0075 - val_accuracy: 0.9986\n",
      "Epoch 40/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.0101 - val_accuracy: 0.9975\n",
      "Epoch 41/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.0123 - val_accuracy: 0.9974\n",
      "Epoch 42/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
      "Epoch 43/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.0077 - val_accuracy: 0.9980\n",
      "Epoch 44/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0066 - val_accuracy: 0.9985\n",
      "Epoch 45/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.0076 - val_accuracy: 0.9983\n",
      "Epoch 46/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.0079 - val_accuracy: 0.9983\n",
      "Epoch 47/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.0112 - val_accuracy: 0.9973\n",
      "Epoch 48/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0064 - val_accuracy: 0.9984\n",
      "Epoch 49/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 0.0071 - val_accuracy: 0.9985\n",
      "Epoch 50/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
      "Epoch 51/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.0082 - val_accuracy: 0.9983\n",
      "Epoch 52/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0085 - val_accuracy: 0.9980\n",
      "Epoch 53/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0070 - val_accuracy: 0.9984\n",
      "Epoch 54/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
      "Epoch 55/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.0071 - val_accuracy: 0.9985\n",
      "Epoch 56/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.0114 - val_accuracy: 0.9972\n",
      "Epoch 57/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0070 - val_accuracy: 0.9983\n",
      "Epoch 58/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.0075 - val_accuracy: 0.9983\n",
      "Epoch 59/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
      "Epoch 60/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0098 - val_accuracy: 0.9976\n",
      "Epoch 61/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0069 - val_accuracy: 0.9984\n",
      "Epoch 62/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.0064 - val_accuracy: 0.9985\n",
      "Epoch 63/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
      "Epoch 64/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.0068 - val_accuracy: 0.9983\n",
      "Epoch 65/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.0070 - val_accuracy: 0.9984\n",
      "Epoch 66/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0063 - val_accuracy: 0.9983\n",
      "Epoch 67/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.0091 - val_accuracy: 0.9976\n",
      "Epoch 68/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.0057 - val_accuracy: 0.9987\n",
      "Epoch 69/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.0112 - val_accuracy: 0.9970\n",
      "Epoch 70/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
      "Epoch 71/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
      "Epoch 72/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.0060 - val_accuracy: 0.9984\n",
      "Epoch 73/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0062 - val_accuracy: 0.9983\n",
      "Epoch 74/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0066 - val_accuracy: 0.9984\n",
      "Epoch 75/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0069 - val_accuracy: 0.9984\n",
      "Epoch 76/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 77/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.0078 - val_accuracy: 0.9977\n",
      "Epoch 78/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.0061 - val_accuracy: 0.9983\n",
      "Epoch 79/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
      "Epoch 80/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0057 - val_accuracy: 0.9986\n",
      "Epoch 81/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.0096 - val_accuracy: 0.9976\n",
      "Epoch 82/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0069 - val_accuracy: 0.9981\n",
      "Epoch 83/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
      "Epoch 84/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
      "Epoch 85/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
      "Epoch 86/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0060 - val_accuracy: 0.9983\n",
      "Epoch 87/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0061 - val_accuracy: 0.9981\n",
      "Epoch 88/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0061 - val_accuracy: 0.9981\n",
      "Epoch 89/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0052 - val_accuracy: 0.9986\n",
      "Epoch 90/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9983\n",
      "Epoch 91/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
      "Epoch 92/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 0.9982\n",
      "Epoch 93/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0064 - val_accuracy: 0.9980\n",
      "Epoch 94/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
      "Epoch 95/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0056 - val_accuracy: 0.9988\n",
      "Epoch 96/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 97/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 98/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0056 - val_accuracy: 0.9985\n",
      "Epoch 99/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
      "Epoch 100/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0054 - val_accuracy: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‡â–‡â–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–ƒâ–†â–ƒâ–†â–„â–‡â–ˆâ–…â–â–‡â–ˆâ–ˆâ–‡â–…â–‡â–‡â–†â–†â–„â–‡â–†â–‡â–„â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–†â–†â–†â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–†â–„â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–ƒâ–‚â–ƒâ–„â–†â–‚â–ƒâ–ƒâ–…â–‚â–‚â–…â–„â–‚â–‚â–‚â–‚â–„â–â–â–‚â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99966</td></tr><tr><td>batch/batch_step</td><td>139995</td></tr><tr><td>batch/learning_rate</td><td>0.00076</td></tr><tr><td>batch/loss</td><td>0.00301</td></tr><tr><td>epoch/accuracy</td><td>0.99966</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00076</td></tr><tr><td>epoch/loss</td><td>0.00301</td></tr><tr><td>epoch/val_accuracy</td><td>0.99875</td></tr><tr><td>epoch/val_loss</td><td>0.00536</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_8</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/cbsfyp2a' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/cbsfyp2a</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_014412-cbsfyp2a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 01:47:05,926] Trial 8 finished with value: 0.004947717906907201 and parameters: {'Layer_1_units': 78, 'Activation_1': 'sigmoid', 'n_layers': 4, 'Layer_2_units': 34, 'Activation_2': 'relu', 'Layer_3_units': 68, 'Activation_3': 'sigmoid', 'Layer_4_units': 117, 'Activation_4': 'relu', 'Layer_5_units': 95, 'Activation_5': 'sigmoid', 'learning_rate': 0.0007567530479686451, 'optimizer': 'rmsprop', 'batch_size': 100}. Best is trial 2 with value: 0.003322927176486701.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_014705-4dfejufd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4dfejufd' target=\"_blank\">Trial_9</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4dfejufd' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4dfejufd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 6s 862us/step - loss: 0.2311 - accuracy: 0.9024 - val_loss: 0.1418 - val_accuracy: 0.9416\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.1388 - accuracy: 0.9438 - val_loss: 0.1328 - val_accuracy: 0.9459\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.1283 - accuracy: 0.9482 - val_loss: 0.1193 - val_accuracy: 0.9524\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.1047 - accuracy: 0.9613 - val_loss: 0.0913 - val_accuracy: 0.9705\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0779 - accuracy: 0.9758 - val_loss: 0.0689 - val_accuracy: 0.9808\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0596 - accuracy: 0.9838 - val_loss: 0.0539 - val_accuracy: 0.9857\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0462 - accuracy: 0.9879 - val_loss: 0.0436 - val_accuracy: 0.9882\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0349 - accuracy: 0.9918 - val_loss: 0.0310 - val_accuracy: 0.9927\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0261 - accuracy: 0.9948 - val_loss: 0.0255 - val_accuracy: 0.9944\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0211 - accuracy: 0.9967 - val_loss: 0.0202 - val_accuracy: 0.9973\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 6s 876us/step - loss: 0.0184 - accuracy: 0.9974 - val_loss: 0.0183 - val_accuracy: 0.9970\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0167 - accuracy: 0.9978 - val_loss: 0.0172 - val_accuracy: 0.9974\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 6s 911us/step - loss: 0.0154 - accuracy: 0.9979 - val_loss: 0.0165 - val_accuracy: 0.9973\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 6s 872us/step - loss: 0.0145 - accuracy: 0.9980 - val_loss: 0.0152 - val_accuracy: 0.9976\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0137 - accuracy: 0.9981 - val_loss: 0.0146 - val_accuracy: 0.9973\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 6s 921us/step - loss: 0.0130 - accuracy: 0.9982 - val_loss: 0.0142 - val_accuracy: 0.9972\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 0.0131 - val_accuracy: 0.9977\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 6s 896us/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.0135 - val_accuracy: 0.9972\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0114 - accuracy: 0.9983 - val_loss: 0.0122 - val_accuracy: 0.9979\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 6s 879us/step - loss: 0.0111 - accuracy: 0.9984 - val_loss: 0.0120 - val_accuracy: 0.9976\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 6s 876us/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 0.0115 - val_accuracy: 0.9980\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.0112 - val_accuracy: 0.9979\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 6s 849us/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 0.0132 - val_accuracy: 0.9965\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 0.0112 - val_accuracy: 0.9975\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0096 - accuracy: 0.9984 - val_loss: 0.0107 - val_accuracy: 0.9977\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 7s 972us/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0106 - val_accuracy: 0.9977\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.0096 - val_accuracy: 0.9983\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 7s 956us/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.0103 - val_accuracy: 0.9976\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 7s 997us/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.0101 - val_accuracy: 0.9976\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 7s 967us/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.0096 - val_accuracy: 0.9979\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 7s 975us/step - loss: 0.0081 - accuracy: 0.9986 - val_loss: 0.0096 - val_accuracy: 0.9976\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.0095 - val_accuracy: 0.9977\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 7s 995us/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.0091 - val_accuracy: 0.9980\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0081 - val_accuracy: 0.9984\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 6s 912us/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0082 - val_accuracy: 0.9983\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 6s 871us/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 0.0081 - val_accuracy: 0.9983\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0093 - val_accuracy: 0.9974\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0090 - val_accuracy: 0.9974\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0085 - val_accuracy: 0.9980\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.0090 - val_accuracy: 0.9973\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.0078 - val_accuracy: 0.9982\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0071 - val_accuracy: 0.9985\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.0075 - val_accuracy: 0.9984\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.0078 - val_accuracy: 0.9980\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 6s 849us/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0069 - val_accuracy: 0.9986\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 6s 878us/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0075 - val_accuracy: 0.9983\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 6s 880us/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.0074 - val_accuracy: 0.9981\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 6s 911us/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0082 - val_accuracy: 0.9976\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0069 - val_accuracy: 0.9984\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 6s 884us/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0069 - val_accuracy: 0.9986\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 6s 888us/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0075 - val_accuracy: 0.9978\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 6s 889us/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0069 - val_accuracy: 0.9981\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 6s 891us/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 6s 884us/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0073 - val_accuracy: 0.9979\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 6s 885us/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0064 - val_accuracy: 0.9984\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 6s 885us/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0063 - val_accuracy: 0.9983\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 6s 882us/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.0067 - val_accuracy: 0.9980\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 6s 885us/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0066 - val_accuracy: 0.9979\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 6s 885us/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 6s 881us/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0064 - val_accuracy: 0.9984\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 6s 883us/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 6s 883us/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0072 - val_accuracy: 0.9975\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 6s 886us/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 6s 884us/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 6s 883us/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0078 - val_accuracy: 0.9974\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 6s 889us/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 6s 887us/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 6s 887us/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 6s 885us/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 6s 886us/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 6s 883us/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 6s 885us/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 6s 885us/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0058 - val_accuracy: 0.9982\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 6s 885us/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0048 - val_accuracy: 0.9986\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 6s 885us/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0056 - val_accuracy: 0.9981\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 6s 882us/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0048 - val_accuracy: 0.9986\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 6s 886us/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 6s 885us/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 6s 885us/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0071 - val_accuracy: 0.9977\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 6s 887us/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 6s 888us/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 6s 886us/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0044 - val_accuracy: 0.9985\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 6s 888us/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 6s 886us/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 7s 957us/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0046 - val_accuracy: 0.9986\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0054 - val_accuracy: 0.9982\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0065 - val_accuracy: 0.9980\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 6s 889us/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 6s 887us/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 6s 886us/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0045 - val_accuracy: 0.9983\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 6s 886us/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0045 - val_accuracy: 0.9984\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0058 - val_accuracy: 0.9979\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9983\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 7s 943us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0042 - val_accuracy: 0.9985\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 7s 957us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0052 - val_accuracy: 0.9982\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 6s 910us/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0042 - val_accuracy: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ƒâ–„â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–…â–…â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–„â–„â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‡â–…â–„â–„â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99915</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>8e-05</td></tr><tr><td>batch/loss</td><td>0.00334</td></tr><tr><td>epoch/accuracy</td><td>0.99915</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>8e-05</td></tr><tr><td>epoch/loss</td><td>0.00333</td></tr><tr><td>epoch/val_accuracy</td><td>0.9985</td></tr><tr><td>epoch/val_loss</td><td>0.00422</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_9</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4dfejufd' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4dfejufd</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_014705-4dfejufd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 01:57:38,505] Trial 9 finished with value: 0.003962169075384736 and parameters: {'Layer_1_units': 46, 'Activation_1': 'sigmoid', 'n_layers': 2, 'Layer_2_units': 94, 'Activation_2': 'relu', 'Layer_3_units': 39, 'Activation_3': 'relu', 'learning_rate': 7.844852210756445e-05, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 2 with value: 0.003322927176486701.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_015738-lphlyn1i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/lphlyn1i' target=\"_blank\">Trial_10</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/lphlyn1i' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/lphlyn1i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2800/2800 [==============================] - 6s 2ms/step - loss: 0.5485 - accuracy: 0.7689 - val_loss: 0.5457 - val_accuracy: 0.7689\n",
      "Epoch 2/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5436 - accuracy: 0.7692 - val_loss: 0.5417 - val_accuracy: 0.7689\n",
      "Epoch 3/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5421 - accuracy: 0.7692 - val_loss: 0.5433 - val_accuracy: 0.7689\n",
      "Epoch 4/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5415 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 5/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5412 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 6/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5422 - val_accuracy: 0.7689\n",
      "Epoch 7/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 8/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5424 - val_accuracy: 0.7689\n",
      "Epoch 9/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5420 - val_accuracy: 0.7689\n",
      "Epoch 10/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5414 - val_accuracy: 0.7689\n",
      "Epoch 11/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5430 - val_accuracy: 0.7689\n",
      "Epoch 12/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5407 - accuracy: 0.7692 - val_loss: 0.5415 - val_accuracy: 0.7689\n",
      "Epoch 13/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5416 - val_accuracy: 0.7689\n",
      "Epoch 14/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5407 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 15/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5430 - val_accuracy: 0.7689\n",
      "Epoch 16/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 17/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5407 - accuracy: 0.7692 - val_loss: 0.5412 - val_accuracy: 0.7689\n",
      "Epoch 18/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5407 - accuracy: 0.7692 - val_loss: 0.5413 - val_accuracy: 0.7689\n",
      "Epoch 19/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5406 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 20/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5407 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 21/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5406 - accuracy: 0.7692 - val_loss: 0.5417 - val_accuracy: 0.7689\n",
      "Epoch 22/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5407 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 23/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5406 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 24/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5406 - accuracy: 0.7692 - val_loss: 0.5411 - val_accuracy: 0.7689\n",
      "Epoch 25/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5406 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 26/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5406 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 27/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 28/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5406 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 29/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 30/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5406 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 31/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 32/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5406 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 33/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 34/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5406 - accuracy: 0.7692 - val_loss: 0.5410 - val_accuracy: 0.7689\n",
      "Epoch 35/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5417 - val_accuracy: 0.7689\n",
      "Epoch 36/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5411 - val_accuracy: 0.7689\n",
      "Epoch 37/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 38/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 39/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 40/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5411 - val_accuracy: 0.7689\n",
      "Epoch 41/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5420 - val_accuracy: 0.7689\n",
      "Epoch 42/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 43/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 44/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 45/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 46/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 47/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 48/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5410 - val_accuracy: 0.7689\n",
      "Epoch 49/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 50/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 51/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 52/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 53/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 54/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 55/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 56/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 57/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 58/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5413 - val_accuracy: 0.7689\n",
      "Epoch 59/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5411 - val_accuracy: 0.7689\n",
      "Epoch 60/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5410 - val_accuracy: 0.7689\n",
      "Epoch 61/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 62/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5410 - val_accuracy: 0.7689\n",
      "Epoch 63/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 64/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 65/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 66/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 67/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5414 - val_accuracy: 0.7689\n",
      "Epoch 68/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 69/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 70/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 71/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 72/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 73/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 74/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 75/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 76/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 77/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 78/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 79/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 80/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 81/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5414 - val_accuracy: 0.7689\n",
      "Epoch 82/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 83/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 84/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 85/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 86/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 87/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 88/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 89/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 90/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 91/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 92/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 93/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5410 - val_accuracy: 0.7689\n",
      "Epoch 94/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 95/100\n",
      "2800/2800 [==============================] - 5s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5411 - val_accuracy: 0.7689\n",
      "Epoch 96/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 97/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 98/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 99/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 100/100\n",
      "2800/2800 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–ƒâ–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–ƒâ–„â–ˆâ–„â–„â–…â–â–ƒâ–„â–„</td></tr><tr><td>batch/batch_step</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–â–‚â–‚â–â–ƒâ–…â–‚â–‚â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–…â–‚â–‚â–ƒâ–‚â–ƒâ–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚</td></tr><tr><td>epoch/accuracy</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‚â–…â–â–ƒâ–â–„â–‚â–â–â–â–â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.76929</td></tr><tr><td>batch/batch_step</td><td>279995</td></tr><tr><td>batch/learning_rate</td><td>0.0068</td></tr><tr><td>batch/loss</td><td>0.54031</td></tr><tr><td>epoch/accuracy</td><td>0.76921</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.0068</td></tr><tr><td>epoch/loss</td><td>0.54041</td></tr><tr><td>epoch/val_accuracy</td><td>0.7689</td></tr><tr><td>epoch/val_loss</td><td>0.5408</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_10</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/lphlyn1i' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/lphlyn1i</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_015738-lphlyn1i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 02:05:08,454] Trial 10 finished with value: 0.5406358420848847 and parameters: {'Layer_1_units': 101, 'Activation_1': 'sigmoid', 'n_layers': 7, 'Layer_2_units': 125, 'Activation_2': 'sigmoid', 'Layer_3_units': 128, 'Activation_3': 'relu', 'Layer_4_units': 56, 'Activation_4': 'relu', 'Layer_5_units': 50, 'Activation_5': 'relu', 'Layer_6_units': 128, 'Activation_6': 'relu', 'Layer_7_units': 123, 'Activation_7': 'relu', 'Layer_8_units': 128, 'Activation_8': 'sigmoid', 'learning_rate': 0.0068038854903899005, 'optimizer': 'rmsprop', 'batch_size': 50}. Best is trial 2 with value: 0.003322927176486701.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_020508-2vhirux2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/2vhirux2' target=\"_blank\">Trial_11</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/2vhirux2' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/2vhirux2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 7s 996us/step - loss: 0.1654 - accuracy: 0.9342 - val_loss: 0.1081 - val_accuracy: 0.9583\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 7s 953us/step - loss: 0.0707 - accuracy: 0.9797 - val_loss: 0.0418 - val_accuracy: 0.9900\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 7s 942us/step - loss: 0.0284 - accuracy: 0.9948 - val_loss: 0.0231 - val_accuracy: 0.9952\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0186 - accuracy: 0.9970 - val_loss: 0.0167 - val_accuracy: 0.9970\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 7s 953us/step - loss: 0.0151 - accuracy: 0.9975 - val_loss: 0.0143 - val_accuracy: 0.9974\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 7s 969us/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.0114 - val_accuracy: 0.9983\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 7s 941us/step - loss: 0.0113 - accuracy: 0.9978 - val_loss: 0.0100 - val_accuracy: 0.9984\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 7s 968us/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 0.0094 - val_accuracy: 0.9983\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 7s 963us/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.0085 - val_accuracy: 0.9981\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 7s 978us/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.0078 - val_accuracy: 0.9982\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 7s 951us/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.0092 - val_accuracy: 0.9973\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0080 - val_accuracy: 0.9977\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.0072 - val_accuracy: 0.9977\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 7s 943us/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0073 - val_accuracy: 0.9979\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 7s 971us/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0071 - val_accuracy: 0.9978\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 7s 952us/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0051 - val_accuracy: 0.9990\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 7s 972us/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0087 - val_accuracy: 0.9973\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 7s 987us/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0073 - val_accuracy: 0.9977\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 7s 950us/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0066 - val_accuracy: 0.9976\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 7s 958us/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0046 - val_accuracy: 0.9985\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 7s 956us/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0064 - val_accuracy: 0.9978\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 7s 950us/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0059 - val_accuracy: 0.9978\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 7s 956us/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 7s 969us/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0049 - val_accuracy: 0.9985\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 7s 955us/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0034 - val_accuracy: 0.9989\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0039 - val_accuracy: 0.9988\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 7s 981us/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0042 - val_accuracy: 0.9984\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 7s 970us/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0034 - val_accuracy: 0.9988\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 7s 941us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 7s 954us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0045 - val_accuracy: 0.9984\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0038 - val_accuracy: 0.9985\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 7s 977us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0057 - val_accuracy: 0.9980\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 7s 951us/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0044 - val_accuracy: 0.9984\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 7s 980us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0034 - val_accuracy: 0.9989\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 7s 970us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9980\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 7s 967us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0032 - val_accuracy: 0.9990\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 7s 942us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 0.9986\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 7s 972us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 7s 978us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 7s 940us/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 7s 983us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 0.9983\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 7s 970us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9985\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9984\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 7s 971us/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9984\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 7s 969us/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0039 - val_accuracy: 0.9984\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 7s 978us/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0049 - val_accuracy: 0.9981\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 7s 940us/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0031 - val_accuracy: 0.9990\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 7s 979us/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0038 - val_accuracy: 0.9988\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 7s 949us/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 7s 965us/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0036 - val_accuracy: 0.9986\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 7s 966us/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0031 - val_accuracy: 0.9988\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 7s 967us/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0027 - val_accuracy: 0.9991\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 7s 949us/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0034 - val_accuracy: 0.9985\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9984\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 7s 983us/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0062 - val_accuracy: 0.9979\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 7s 953us/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0035 - val_accuracy: 0.9984\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 7s 971us/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9982\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 7s 989us/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0053 - val_accuracy: 0.9980\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 7s 981us/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9985\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0037 - val_accuracy: 0.9986\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0030 - val_accuracy: 0.9986\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 7s 989us/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9985\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 7s 950us/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0027 - val_accuracy: 0.9990\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 7s 970us/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9985\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9984\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 7s 993us/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0027 - val_accuracy: 0.9989\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 7s 949us/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0045 - val_accuracy: 0.9984\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 6s 927us/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0032 - val_accuracy: 0.9988\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 7s 998us/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0031 - val_accuracy: 0.9988\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0051 - val_accuracy: 0.9981\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0032 - val_accuracy: 0.9988\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0114 - val_accuracy: 0.9969\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 7s 969us/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0059 - val_accuracy: 0.9983\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 7s 981us/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0043 - val_accuracy: 0.9985\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 7s 972us/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9985\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0031 - val_accuracy: 0.9986\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0028 - val_accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–â–„â–…â–…â–…â–†â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‚â–†â–…â–…â–„â–„â–ˆâ–‡â–‚â–ƒâ–ƒâ–†â–†â–„â–‡â–†â–†â–„â–ˆâ–‡â–‡â–‡â–‡â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–†â–‡â–ˆâ–‡â–†â–‡â–‡â–†</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99928</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.0002</td></tr><tr><td>batch/loss</td><td>0.00201</td></tr><tr><td>epoch/accuracy</td><td>0.99928</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.0002</td></tr><tr><td>epoch/loss</td><td>0.00201</td></tr><tr><td>epoch/val_accuracy</td><td>0.999</td></tr><tr><td>epoch/val_loss</td><td>0.00282</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_11</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/2vhirux2' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/2vhirux2</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_020508-2vhirux2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 02:16:24,876] Trial 11 finished with value: 0.002590348944067955 and parameters: {'Layer_1_units': 97, 'Activation_1': 'sigmoid', 'n_layers': 2, 'Layer_2_units': 101, 'Activation_2': 'relu', 'Layer_3_units': 90, 'Activation_3': 'relu', 'learning_rate': 0.00019581664147035253, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_021624-4qike0fa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4qike0fa' target=\"_blank\">Trial_12</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4qike0fa' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4qike0fa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2800/2800 [==============================] - 3s 954us/step - loss: 0.2390 - accuracy: 0.9015 - val_loss: 0.1496 - val_accuracy: 0.9410\n",
      "Epoch 2/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.1427 - accuracy: 0.9442 - val_loss: 0.1384 - val_accuracy: 0.9451\n",
      "Epoch 3/100\n",
      "2800/2800 [==============================] - 3s 977us/step - loss: 0.1356 - accuracy: 0.9459 - val_loss: 0.1295 - val_accuracy: 0.9475\n",
      "Epoch 4/100\n",
      "2800/2800 [==============================] - 3s 937us/step - loss: 0.1249 - accuracy: 0.9507 - val_loss: 0.1174 - val_accuracy: 0.9545\n",
      "Epoch 5/100\n",
      "2800/2800 [==============================] - 3s 922us/step - loss: 0.1089 - accuracy: 0.9596 - val_loss: 0.1033 - val_accuracy: 0.9616\n",
      "Epoch 6/100\n",
      "2800/2800 [==============================] - 3s 944us/step - loss: 0.0915 - accuracy: 0.9687 - val_loss: 0.0839 - val_accuracy: 0.9737\n",
      "Epoch 7/100\n",
      "2800/2800 [==============================] - 3s 917us/step - loss: 0.0777 - accuracy: 0.9764 - val_loss: 0.0734 - val_accuracy: 0.9786\n",
      "Epoch 8/100\n",
      "2800/2800 [==============================] - 3s 919us/step - loss: 0.0670 - accuracy: 0.9822 - val_loss: 0.0633 - val_accuracy: 0.9840\n",
      "Epoch 9/100\n",
      "2800/2800 [==============================] - 3s 919us/step - loss: 0.0570 - accuracy: 0.9861 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
      "Epoch 10/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0474 - accuracy: 0.9899 - val_loss: 0.0433 - val_accuracy: 0.9922\n",
      "Epoch 11/100\n",
      "2800/2800 [==============================] - 3s 943us/step - loss: 0.0390 - accuracy: 0.9927 - val_loss: 0.0390 - val_accuracy: 0.9911\n",
      "Epoch 12/100\n",
      "2800/2800 [==============================] - 3s 939us/step - loss: 0.0323 - accuracy: 0.9946 - val_loss: 0.0294 - val_accuracy: 0.9952\n",
      "Epoch 13/100\n",
      "2800/2800 [==============================] - 3s 951us/step - loss: 0.0270 - accuracy: 0.9960 - val_loss: 0.0254 - val_accuracy: 0.9963\n",
      "Epoch 14/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0232 - accuracy: 0.9966 - val_loss: 0.0219 - val_accuracy: 0.9969\n",
      "Epoch 15/100\n",
      "2800/2800 [==============================] - 3s 917us/step - loss: 0.0203 - accuracy: 0.9972 - val_loss: 0.0196 - val_accuracy: 0.9971\n",
      "Epoch 16/100\n",
      "2800/2800 [==============================] - 3s 980us/step - loss: 0.0182 - accuracy: 0.9974 - val_loss: 0.0177 - val_accuracy: 0.9973\n",
      "Epoch 17/100\n",
      "2800/2800 [==============================] - 3s 964us/step - loss: 0.0165 - accuracy: 0.9975 - val_loss: 0.0169 - val_accuracy: 0.9972\n",
      "Epoch 18/100\n",
      "2800/2800 [==============================] - 3s 929us/step - loss: 0.0152 - accuracy: 0.9978 - val_loss: 0.0156 - val_accuracy: 0.9973\n",
      "Epoch 19/100\n",
      "2800/2800 [==============================] - 3s 933us/step - loss: 0.0142 - accuracy: 0.9979 - val_loss: 0.0142 - val_accuracy: 0.9979\n",
      "Epoch 20/100\n",
      "2800/2800 [==============================] - 3s 917us/step - loss: 0.0132 - accuracy: 0.9980 - val_loss: 0.0140 - val_accuracy: 0.9976\n",
      "Epoch 21/100\n",
      "2800/2800 [==============================] - 3s 990us/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 0.0139 - val_accuracy: 0.9973\n",
      "Epoch 22/100\n",
      "2800/2800 [==============================] - 3s 966us/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 0.0127 - val_accuracy: 0.9976\n",
      "Epoch 23/100\n",
      "2800/2800 [==============================] - 3s 918us/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.0120 - val_accuracy: 0.9975\n",
      "Epoch 24/100\n",
      "2800/2800 [==============================] - 3s 918us/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.0116 - val_accuracy: 0.9979\n",
      "Epoch 25/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.0115 - val_accuracy: 0.9978\n",
      "Epoch 26/100\n",
      "2800/2800 [==============================] - 3s 953us/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.0105 - val_accuracy: 0.9979\n",
      "Epoch 27/100\n",
      "2800/2800 [==============================] - 3s 932us/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
      "Epoch 28/100\n",
      "2800/2800 [==============================] - 3s 936us/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
      "Epoch 29/100\n",
      "2800/2800 [==============================] - 3s 940us/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.0095 - val_accuracy: 0.9985\n",
      "Epoch 30/100\n",
      "2800/2800 [==============================] - 3s 920us/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.0093 - val_accuracy: 0.9983\n",
      "Epoch 31/100\n",
      "2800/2800 [==============================] - 3s 931us/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.0098 - val_accuracy: 0.9978\n",
      "Epoch 32/100\n",
      "2800/2800 [==============================] - 3s 965us/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0103 - val_accuracy: 0.9974\n",
      "Epoch 33/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.0089 - val_accuracy: 0.9980\n",
      "Epoch 34/100\n",
      "2800/2800 [==============================] - 3s 919us/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
      "Epoch 35/100\n",
      "2800/2800 [==============================] - 3s 919us/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 0.0085 - val_accuracy: 0.9982\n",
      "Epoch 36/100\n",
      "2800/2800 [==============================] - 3s 964us/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.0082 - val_accuracy: 0.9984\n",
      "Epoch 37/100\n",
      "2800/2800 [==============================] - 3s 998us/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.0083 - val_accuracy: 0.9980\n",
      "Epoch 38/100\n",
      "2800/2800 [==============================] - 3s 917us/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.0079 - val_accuracy: 0.9983\n",
      "Epoch 39/100\n",
      "2800/2800 [==============================] - 3s 974us/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.0078 - val_accuracy: 0.9983\n",
      "Epoch 40/100\n",
      "2800/2800 [==============================] - 3s 962us/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.0080 - val_accuracy: 0.9980\n",
      "Epoch 41/100\n",
      "2800/2800 [==============================] - 3s 929us/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.0076 - val_accuracy: 0.9984\n",
      "Epoch 42/100\n",
      "2800/2800 [==============================] - 3s 935us/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.0083 - val_accuracy: 0.9982\n",
      "Epoch 43/100\n",
      "2800/2800 [==============================] - 3s 917us/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0069 - val_accuracy: 0.9987\n",
      "Epoch 44/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0071 - val_accuracy: 0.9984\n",
      "Epoch 45/100\n",
      "2800/2800 [==============================] - 3s 950us/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0070 - val_accuracy: 0.9985\n",
      "Epoch 46/100\n",
      "2800/2800 [==============================] - 3s 921us/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
      "Epoch 47/100\n",
      "2800/2800 [==============================] - 3s 938us/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 0.9988\n",
      "Epoch 48/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
      "Epoch 49/100\n",
      "2800/2800 [==============================] - 3s 939us/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0068 - val_accuracy: 0.9983\n",
      "Epoch 50/100\n",
      "2800/2800 [==============================] - 3s 933us/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0066 - val_accuracy: 0.9984\n",
      "Epoch 51/100\n",
      "2800/2800 [==============================] - 3s 959us/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 52/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0098 - val_accuracy: 0.9969\n",
      "Epoch 53/100\n",
      "2800/2800 [==============================] - 3s 920us/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.0064 - val_accuracy: 0.9983\n",
      "Epoch 54/100\n",
      "2800/2800 [==============================] - 3s 940us/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.0065 - val_accuracy: 0.9984\n",
      "Epoch 55/100\n",
      "2800/2800 [==============================] - 3s 957us/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
      "Epoch 56/100\n",
      "2800/2800 [==============================] - 3s 928us/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0064 - val_accuracy: 0.9984\n",
      "Epoch 57/100\n",
      "2800/2800 [==============================] - 3s 922us/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0064 - val_accuracy: 0.9983\n",
      "Epoch 58/100\n",
      "2800/2800 [==============================] - 3s 923us/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0068 - val_accuracy: 0.9981\n",
      "Epoch 59/100\n",
      "2800/2800 [==============================] - 3s 988us/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 60/100\n",
      "2800/2800 [==============================] - 3s 977us/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 61/100\n",
      "2800/2800 [==============================] - 3s 922us/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "Epoch 62/100\n",
      "2800/2800 [==============================] - 3s 983us/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
      "Epoch 63/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "Epoch 64/100\n",
      "2800/2800 [==============================] - 3s 944us/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "Epoch 65/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0060 - val_accuracy: 0.9981\n",
      "Epoch 66/100\n",
      "2800/2800 [==============================] - 3s 932us/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 67/100\n",
      "2800/2800 [==============================] - 3s 920us/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
      "Epoch 68/100\n",
      "2800/2800 [==============================] - 3s 923us/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
      "Epoch 69/100\n",
      "2800/2800 [==============================] - 3s 918us/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0064 - val_accuracy: 0.9980\n",
      "Epoch 70/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0053 - val_accuracy: 0.9991\n",
      "Epoch 71/100\n",
      "2800/2800 [==============================] - 3s 995us/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0059 - val_accuracy: 0.9981\n",
      "Epoch 72/100\n",
      "2800/2800 [==============================] - 3s 928us/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0067 - val_accuracy: 0.9977\n",
      "Epoch 73/100\n",
      "2800/2800 [==============================] - 3s 936us/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0061 - val_accuracy: 0.9981\n",
      "Epoch 74/100\n",
      "2800/2800 [==============================] - 3s 999us/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0057 - val_accuracy: 0.9985\n",
      "Epoch 75/100\n",
      "2800/2800 [==============================] - 3s 964us/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0060 - val_accuracy: 0.9981\n",
      "Epoch 76/100\n",
      "2800/2800 [==============================] - 3s 926us/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0059 - val_accuracy: 0.9981\n",
      "Epoch 77/100\n",
      "2800/2800 [==============================] - 3s 939us/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 78/100\n",
      "2800/2800 [==============================] - 3s 949us/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
      "Epoch 79/100\n",
      "2800/2800 [==============================] - 3s 926us/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0056 - val_accuracy: 0.9981\n",
      "Epoch 80/100\n",
      "2800/2800 [==============================] - 3s 927us/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0052 - val_accuracy: 0.9985\n",
      "Epoch 81/100\n",
      "2800/2800 [==============================] - 3s 935us/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
      "Epoch 82/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0067 - val_accuracy: 0.9976\n",
      "Epoch 83/100\n",
      "2800/2800 [==============================] - 3s 932us/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 84/100\n",
      "2800/2800 [==============================] - 3s 932us/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0054 - val_accuracy: 0.9983\n",
      "Epoch 85/100\n",
      "2800/2800 [==============================] - 3s 987us/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0052 - val_accuracy: 0.9985\n",
      "Epoch 86/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 87/100\n",
      "2800/2800 [==============================] - 3s 927us/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9984\n",
      "Epoch 88/100\n",
      "2800/2800 [==============================] - 3s 937us/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 89/100\n",
      "2800/2800 [==============================] - 3s 934us/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0058 - val_accuracy: 0.9980\n",
      "Epoch 90/100\n",
      "2800/2800 [==============================] - 3s 926us/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0065 - val_accuracy: 0.9977\n",
      "Epoch 91/100\n",
      "2800/2800 [==============================] - 3s 925us/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0071 - val_accuracy: 0.9973\n",
      "Epoch 92/100\n",
      "2800/2800 [==============================] - 3s 920us/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
      "Epoch 93/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
      "Epoch 94/100\n",
      "2800/2800 [==============================] - 3s 969us/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 95/100\n",
      "2800/2800 [==============================] - 3s 923us/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 0.9973\n",
      "Epoch 96/100\n",
      "2800/2800 [==============================] - 3s 947us/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 97/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 0.9984\n",
      "Epoch 98/100\n",
      "2800/2800 [==============================] - 3s 942us/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 99/100\n",
      "2800/2800 [==============================] - 3s 926us/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0058 - val_accuracy: 0.9980\n",
      "Epoch 100/100\n",
      "2800/2800 [==============================] - 3s 969us/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0072 - val_accuracy: 0.9973\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ˆâ–ˆâ–‡â–‡â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–ƒâ–„â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‚â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–†â–…â–…â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99923</td></tr><tr><td>batch/batch_step</td><td>279995</td></tr><tr><td>batch/learning_rate</td><td>0.00026</td></tr><tr><td>batch/loss</td><td>0.00367</td></tr><tr><td>epoch/accuracy</td><td>0.99924</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00026</td></tr><tr><td>epoch/loss</td><td>0.00367</td></tr><tr><td>epoch/val_accuracy</td><td>0.99735</td></tr><tr><td>epoch/val_loss</td><td>0.00723</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_12</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4qike0fa' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4qike0fa</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_021624-4qike0fa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 02:20:54,423] Trial 12 finished with value: 0.004526339028961957 and parameters: {'Layer_1_units': 105, 'Activation_1': 'sigmoid', 'n_layers': 1, 'Layer_2_units': 115, 'Activation_2': 'sigmoid', 'learning_rate': 0.000255903583970744, 'optimizer': 'rmsprop', 'batch_size': 50}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_022054-oweg8kuh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/oweg8kuh' target=\"_blank\">Trial_13</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/oweg8kuh' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/oweg8kuh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/7000 [..............................] - ETA: 42:32 - loss: 1.0789 - accuracy: 0.3000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0006s). Check your callbacks.\n",
      "7000/7000 [==============================] - 6s 869us/step - loss: 0.0970 - accuracy: 0.9621 - val_loss: 0.0270 - val_accuracy: 0.9923\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.0162 - accuracy: 0.9958 - val_loss: 0.0175 - val_accuracy: 0.9945\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 6s 882us/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.0091 - val_accuracy: 0.9970\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 6s 878us/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.0095 - val_accuracy: 0.9967\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 6s 880us/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0076 - val_accuracy: 0.9977\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0060 - val_accuracy: 0.9977\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 6s 907us/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.0071 - val_accuracy: 0.9977\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 6s 868us/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0085 - val_accuracy: 0.9970\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 6s 876us/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 6s 868us/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0129 - val_accuracy: 0.9967\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0068 - val_accuracy: 0.9980\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0070 - val_accuracy: 0.9979\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 6s 882us/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0080 - val_accuracy: 0.9976\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 6s 872us/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0100 - val_accuracy: 0.9969\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 6s 876us/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0117 - val_accuracy: 0.9966\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0053 - val_accuracy: 0.9979\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 6s 907us/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0063 - val_accuracy: 0.9980\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 6s 876us/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.0169 - val_accuracy: 0.9956\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 6s 863us/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.0083 - val_accuracy: 0.9975\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 6s 863us/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0121 - val_accuracy: 0.9969\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0073 - val_accuracy: 0.9973\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 6s 897us/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0181 - val_accuracy: 0.9959\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 6s 888us/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0064 - val_accuracy: 0.9978\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 6s 864us/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0070 - val_accuracy: 0.9980\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 6s 878us/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0060 - val_accuracy: 0.9977\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 6s 885us/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.0128 - val_accuracy: 0.9967\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 6s 905us/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0040 - val_accuracy: 0.9984\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 6s 907us/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0087 - val_accuracy: 0.9976\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 6s 847us/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0104 - val_accuracy: 0.9974\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 6s 890us/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0101 - val_accuracy: 0.9973\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 6s 867us/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0050 - val_accuracy: 0.9981\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 6s 883us/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0053 - val_accuracy: 0.9983\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9983\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 6s 846us/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9984\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0103 - val_accuracy: 0.9974\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 6s 875us/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0081 - val_accuracy: 0.9974\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 6s 881us/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0104 - val_accuracy: 0.9967\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0143 - val_accuracy: 0.9966\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 6s 847us/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0041 - val_accuracy: 0.9985\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 6s 886us/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0212 - val_accuracy: 0.9952\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 6s 919us/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0042 - val_accuracy: 0.9984\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 6s 874us/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0165 - val_accuracy: 0.9961\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0049 - val_accuracy: 0.9981\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0091 - val_accuracy: 0.9973\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 6s 887us/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0100 - val_accuracy: 0.9973\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 6s 863us/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0086 - val_accuracy: 0.9972\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0081 - val_accuracy: 0.9978\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 6s 869us/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0083 - val_accuracy: 0.9973\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 6s 884us/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0100 - val_accuracy: 0.9973\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0048 - val_accuracy: 0.9983\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 7s 937us/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0050 - val_accuracy: 0.9983\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 6s 909us/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0070 - val_accuracy: 0.9981\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 6s 870us/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0057 - val_accuracy: 0.9979\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 6s 879us/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0071 - val_accuracy: 0.9977\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0088 - val_accuracy: 0.9976\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0039 - val_accuracy: 0.9983\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 6s 883us/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0063 - val_accuracy: 0.9983\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 6s 865us/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0046 - val_accuracy: 0.9984\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 6s 854us/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0087 - val_accuracy: 0.9977\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 6s 857us/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0132 - val_accuracy: 0.9969\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 6s 909us/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0068 - val_accuracy: 0.9976\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 6s 884us/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0072 - val_accuracy: 0.9979\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 6s 868us/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0047 - val_accuracy: 0.9983\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 6s 879us/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0055 - val_accuracy: 0.9980\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0045 - val_accuracy: 0.9981\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 6s 887us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0042 - val_accuracy: 0.9981\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 6s 919us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0052 - val_accuracy: 0.9981\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0062 - val_accuracy: 0.9982\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 6s 854us/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0041 - val_accuracy: 0.9985\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 6s 865us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0059 - val_accuracy: 0.9981\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0050 - val_accuracy: 0.9980\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0074 - val_accuracy: 0.9976\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 6s 861us/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0070 - val_accuracy: 0.9980\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 6s 873us/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0082 - val_accuracy: 0.9980\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 6s 880us/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0056 - val_accuracy: 0.9980\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0056 - val_accuracy: 0.9979\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 6s 888us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 6s 872us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0252 - val_accuracy: 0.9953\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0205 - val_accuracy: 0.9958\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 6s 854us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9984\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0058 - val_accuracy: 0.9980\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 6s 881us/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0053 - val_accuracy: 0.9983\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 6s 868us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0069 - val_accuracy: 0.9975\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 7s 930us/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0070 - val_accuracy: 0.9978\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0059 - val_accuracy: 0.9980\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 6s 849us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0088 - val_accuracy: 0.9974\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 6s 922us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0067 - val_accuracy: 0.9979\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0065 - val_accuracy: 0.9979\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 6s 905us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0126 - val_accuracy: 0.9969\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 6s 869us/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0158 - val_accuracy: 0.9971\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 6s 854us/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0103 - val_accuracy: 0.9973\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 6s 895us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0052 - val_accuracy: 0.9978\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 6s 846us/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0055 - val_accuracy: 0.9982\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 6s 912us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0088 - val_accuracy: 0.9975\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0078 - val_accuracy: 0.9977\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ˆâ–…â–†â–…â–„â–„â–„â–„â–„â–…â–…â–„â–„â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‚â–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–†â–…â–…â–…â–…â–…â–†â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–…â–†â–†â–„â–†â–„â–†â–‚â–…â–†â–†â–‡â–…â–‡â–‡â–ˆâ–†â–…â–‡â–…â–†â–‡â–‡â–†â–„â–†â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–â–†â–…â–…â–†â–†</td></tr><tr><td>epoch/val_loss</td><td>â–‡â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‡â–ƒâ–‡â–â–„â–„â–‚â–ƒâ–†â–ƒâ–ƒâ–ƒâ–‚â–â–ƒâ–â–‚â–ƒâ–â–‚â–â–‚â–‚â–ƒâ–ƒâ–ˆâ–‚â–‚â–ƒâ–‚â–…â–†â–ƒ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99911</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00101</td></tr><tr><td>batch/loss</td><td>0.00283</td></tr><tr><td>epoch/accuracy</td><td>0.99911</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00101</td></tr><tr><td>epoch/loss</td><td>0.00284</td></tr><tr><td>epoch/val_accuracy</td><td>0.99765</td></tr><tr><td>epoch/val_loss</td><td>0.00785</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_13</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/oweg8kuh' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/oweg8kuh</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_022054-oweg8kuh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 02:31:11,831] Trial 13 finished with value: 0.0035038277273997664 and parameters: {'Layer_1_units': 90, 'Activation_1': 'sigmoid', 'n_layers': 1, 'Layer_2_units': 101, 'Activation_2': 'relu', 'learning_rate': 0.0010127847737197659, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_023111-wjiah24f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/wjiah24f' target=\"_blank\">Trial_14</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/wjiah24f' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/wjiah24f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.1560 - accuracy: 0.9437 - val_loss: 0.0685 - val_accuracy: 0.9829\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0448 - accuracy: 0.9914 - val_loss: 0.0333 - val_accuracy: 0.9951\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0313 - accuracy: 0.9956 - val_loss: 0.0266 - val_accuracy: 0.9965\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0261 - accuracy: 0.9963 - val_loss: 0.0261 - val_accuracy: 0.9957\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0227 - accuracy: 0.9967 - val_loss: 0.0231 - val_accuracy: 0.9960\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0204 - accuracy: 0.9969 - val_loss: 0.0188 - val_accuracy: 0.9967\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0182 - accuracy: 0.9971 - val_loss: 0.0155 - val_accuracy: 0.9975\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0162 - accuracy: 0.9976 - val_loss: 0.0225 - val_accuracy: 0.9959\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0149 - accuracy: 0.9976 - val_loss: 0.0136 - val_accuracy: 0.9976\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0141 - accuracy: 0.9977 - val_loss: 0.0196 - val_accuracy: 0.9962\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0130 - accuracy: 0.9978 - val_loss: 0.0111 - val_accuracy: 0.9984\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0124 - accuracy: 0.9978 - val_loss: 0.0143 - val_accuracy: 0.9971\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 0.0116 - val_accuracy: 0.9977\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0110 - accuracy: 0.9980 - val_loss: 0.0162 - val_accuracy: 0.9966\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: 0.0089 - val_accuracy: 0.9981\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 0.0097 - val_accuracy: 0.9981\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.0086 - val_accuracy: 0.9984\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.0107 - val_accuracy: 0.9976\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.0190 - val_accuracy: 0.9959\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.0144 - val_accuracy: 0.9972\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.0079 - val_accuracy: 0.9983\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.0246 - val_accuracy: 0.9951\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.0188 - val_accuracy: 0.9959\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.0121 - val_accuracy: 0.9970\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.0066 - val_accuracy: 0.9985\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0069 - val_accuracy: 0.9985\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.0092 - val_accuracy: 0.9974\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.0068 - val_accuracy: 0.9981\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.0105 - val_accuracy: 0.9973\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0085 - val_accuracy: 0.9979\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.0113 - val_accuracy: 0.9974\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0124 - val_accuracy: 0.9970\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0090 - val_accuracy: 0.9981\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0121 - val_accuracy: 0.9969\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0088 - val_accuracy: 0.9979\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0079 - val_accuracy: 0.9978\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0101 - val_accuracy: 0.9974\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0045 - val_accuracy: 0.9988\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0062 - val_accuracy: 0.9983\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0045 - val_accuracy: 0.9988\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0139 - val_accuracy: 0.9969\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0070 - val_accuracy: 0.9984\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0055 - val_accuracy: 0.9990\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 0.9982\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0100 - val_accuracy: 0.9973\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0071 - val_accuracy: 0.9983\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0071 - val_accuracy: 0.9980\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0055 - val_accuracy: 0.9985\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0264 - val_accuracy: 0.9948\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0114 - val_accuracy: 0.9970\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0057 - val_accuracy: 0.9985\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0056 - val_accuracy: 0.9986\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0204 - val_accuracy: 0.9956\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0064 - val_accuracy: 0.9986\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0048 - val_accuracy: 0.9988\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9990\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0036 - val_accuracy: 0.9990\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0159 - val_accuracy: 0.9966\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0046 - val_accuracy: 0.9986\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0043 - val_accuracy: 0.9990\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0094 - val_accuracy: 0.9979\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0071 - val_accuracy: 0.9980\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0041 - val_accuracy: 0.9990\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0060 - val_accuracy: 0.9983\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0066 - val_accuracy: 0.9983\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9988\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0112 - val_accuracy: 0.9974\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0113 - val_accuracy: 0.9974\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0124 - val_accuracy: 0.9970\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9992\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0039 - val_accuracy: 0.9989\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0115 - val_accuracy: 0.9974\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0216 - val_accuracy: 0.9956\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0039 - val_accuracy: 0.9988\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0062 - val_accuracy: 0.9981\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0048 - val_accuracy: 0.9985\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ƒâ–…â–„â–…â–…â–…â–…â–…â–ˆâ–†â–‡â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–…â–‚â–…â–‡â–…â–…â–â–‚â–„â–‡â–†â–…â–„â–†â–„â–‡â–†â–…â–‡â–„â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–…â–‡â–ˆâ–‡â–‡â–…â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–â–ƒâ–â–â–â–â–â–â–â–â–â–‚â–â–â–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99921</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00018</td></tr><tr><td>batch/loss</td><td>0.00356</td></tr><tr><td>epoch/accuracy</td><td>0.99921</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00018</td></tr><tr><td>epoch/loss</td><td>0.00356</td></tr><tr><td>epoch/val_accuracy</td><td>0.9988</td></tr><tr><td>epoch/val_loss</td><td>0.00473</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_14</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/wjiah24f' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/wjiah24f</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_023111-wjiah24f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 02:44:44,648] Trial 14 finished with value: 0.003252321179024875 and parameters: {'Layer_1_units': 116, 'Activation_1': 'sigmoid', 'n_layers': 6, 'Layer_2_units': 79, 'Activation_2': 'relu', 'Layer_3_units': 90, 'Activation_3': 'relu', 'Layer_4_units': 60, 'Activation_4': 'relu', 'Layer_5_units': 65, 'Activation_5': 'relu', 'Layer_6_units': 92, 'Activation_6': 'relu', 'Layer_7_units': 32, 'Activation_7': 'relu', 'learning_rate': 0.0001772970674943899, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_024444-96bzn22j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/96bzn22j' target=\"_blank\">Trial_15</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/96bzn22j' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/96bzn22j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.1555 - accuracy: 0.9417 - val_loss: 0.0594 - val_accuracy: 0.9863\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0411 - accuracy: 0.9918 - val_loss: 0.0260 - val_accuracy: 0.9972\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0285 - accuracy: 0.9958 - val_loss: 0.0256 - val_accuracy: 0.9958\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0236 - accuracy: 0.9964 - val_loss: 0.0195 - val_accuracy: 0.9972\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0203 - accuracy: 0.9971 - val_loss: 0.0174 - val_accuracy: 0.9974\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0185 - accuracy: 0.9971 - val_loss: 0.0195 - val_accuracy: 0.9961\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0165 - accuracy: 0.9974 - val_loss: 0.0144 - val_accuracy: 0.9975\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 0.0137 - val_accuracy: 0.9977\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.0104 - val_accuracy: 0.9986\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0121 - accuracy: 0.9978 - val_loss: 0.0130 - val_accuracy: 0.9976\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.0098 - val_accuracy: 0.9981\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0107 - accuracy: 0.9980 - val_loss: 0.0102 - val_accuracy: 0.9979\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 0.0176 - val_accuracy: 0.9965\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.0104 - val_accuracy: 0.9980\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.0092 - val_accuracy: 0.9979\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0087 - accuracy: 0.9984 - val_loss: 0.0092 - val_accuracy: 0.9980\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 0.0084 - val_accuracy: 0.9981\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.0066 - val_accuracy: 0.9985\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.0073 - val_accuracy: 0.9984\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0088 - val_accuracy: 0.9976\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.0094 - val_accuracy: 0.9978\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.0060 - val_accuracy: 0.9983\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0065 - val_accuracy: 0.9986\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0166 - val_accuracy: 0.9963\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0112 - val_accuracy: 0.9974\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0082 - val_accuracy: 0.9980\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.0088 - val_accuracy: 0.9978\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0064 - val_accuracy: 0.9984\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0049 - val_accuracy: 0.9986\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0065 - val_accuracy: 0.9982\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0102 - val_accuracy: 0.9976\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0069 - val_accuracy: 0.9982\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0074 - val_accuracy: 0.9984\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0078 - val_accuracy: 0.9980\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0057 - val_accuracy: 0.9985\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0248 - val_accuracy: 0.9956\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0061 - val_accuracy: 0.9983\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0057 - val_accuracy: 0.9986\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9982\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0060 - val_accuracy: 0.9984\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0037 - val_accuracy: 0.9990\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0064 - val_accuracy: 0.9984\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0046 - val_accuracy: 0.9986\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0100 - val_accuracy: 0.9976\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0043 - val_accuracy: 0.9990\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0038 - val_accuracy: 0.9991\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0072 - val_accuracy: 0.9983\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0057 - val_accuracy: 0.9981\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0083 - val_accuracy: 0.9977\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0067 - val_accuracy: 0.9980\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0041 - val_accuracy: 0.9990\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0085 - val_accuracy: 0.9978\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0087 - val_accuracy: 0.9976\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9989\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0042 - val_accuracy: 0.9990\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0048 - val_accuracy: 0.9984\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0077 - val_accuracy: 0.9979\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0091 - val_accuracy: 0.9979\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0117 - val_accuracy: 0.9971\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0094 - val_accuracy: 0.9973\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0039 - val_accuracy: 0.9990\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 0.9985\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 0.9985\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0051 - val_accuracy: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ƒâ–„â–…â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–‚â–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99908</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00018</td></tr><tr><td>batch/loss</td><td>0.00345</td></tr><tr><td>epoch/accuracy</td><td>0.99908</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00018</td></tr><tr><td>epoch/loss</td><td>0.00345</td></tr><tr><td>epoch/val_accuracy</td><td>0.99855</td></tr><tr><td>epoch/val_loss</td><td>0.00507</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_15</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/96bzn22j' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/96bzn22j</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_024444-96bzn22j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 02:58:03,904] Trial 15 finished with value: 0.00367390438914299 and parameters: {'Layer_1_units': 119, 'Activation_1': 'sigmoid', 'n_layers': 6, 'Layer_2_units': 77, 'Activation_2': 'relu', 'Layer_3_units': 95, 'Activation_3': 'relu', 'Layer_4_units': 61, 'Activation_4': 'relu', 'Layer_5_units': 61, 'Activation_5': 'relu', 'Layer_6_units': 90, 'Activation_6': 'relu', 'Layer_7_units': 34, 'Activation_7': 'relu', 'learning_rate': 0.00017700567992758964, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_025804-kksjk01o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/kksjk01o' target=\"_blank\">Trial_16</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/kksjk01o' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/kksjk01o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.2707 - accuracy: 0.8932 - val_loss: 0.1607 - val_accuracy: 0.9416\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.1482 - accuracy: 0.9461 - val_loss: 0.1452 - val_accuracy: 0.9471\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.1151 - accuracy: 0.9627 - val_loss: 0.0926 - val_accuracy: 0.9741\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0839 - accuracy: 0.9776 - val_loss: 0.0724 - val_accuracy: 0.9826\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0687 - accuracy: 0.9838 - val_loss: 0.0624 - val_accuracy: 0.9867\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0551 - accuracy: 0.9889 - val_loss: 0.0487 - val_accuracy: 0.9911\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0432 - accuracy: 0.9931 - val_loss: 0.0369 - val_accuracy: 0.9948\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0373 - accuracy: 0.9952 - val_loss: 0.0386 - val_accuracy: 0.9943\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0343 - accuracy: 0.9962 - val_loss: 0.0319 - val_accuracy: 0.9972\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0329 - accuracy: 0.9967 - val_loss: 0.0321 - val_accuracy: 0.9963\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0317 - accuracy: 0.9969 - val_loss: 0.0309 - val_accuracy: 0.9974\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0304 - accuracy: 0.9972 - val_loss: 0.0387 - val_accuracy: 0.9946\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0299 - accuracy: 0.9972 - val_loss: 0.0341 - val_accuracy: 0.9955\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0293 - accuracy: 0.9972 - val_loss: 0.0286 - val_accuracy: 0.9972\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0284 - accuracy: 0.9975 - val_loss: 0.0285 - val_accuracy: 0.9972\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0277 - accuracy: 0.9975 - val_loss: 0.0254 - val_accuracy: 0.9981\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0271 - accuracy: 0.9976 - val_loss: 0.0250 - val_accuracy: 0.9981\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0263 - accuracy: 0.9977 - val_loss: 0.0246 - val_accuracy: 0.9980\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0259 - accuracy: 0.9978 - val_loss: 0.0242 - val_accuracy: 0.9983\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0254 - accuracy: 0.9978 - val_loss: 0.0288 - val_accuracy: 0.9967\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0251 - accuracy: 0.9977 - val_loss: 0.0247 - val_accuracy: 0.9974\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0245 - accuracy: 0.9979 - val_loss: 0.0234 - val_accuracy: 0.9980\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0241 - accuracy: 0.9979 - val_loss: 0.0233 - val_accuracy: 0.9977\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0235 - accuracy: 0.9979 - val_loss: 0.0231 - val_accuracy: 0.9979\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0230 - accuracy: 0.9981 - val_loss: 0.0292 - val_accuracy: 0.9962\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0227 - accuracy: 0.9979 - val_loss: 0.0263 - val_accuracy: 0.9965\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0222 - accuracy: 0.9980 - val_loss: 0.0482 - val_accuracy: 0.9905\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0222 - accuracy: 0.9979 - val_loss: 0.0359 - val_accuracy: 0.9952\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0216 - accuracy: 0.9980 - val_loss: 0.0213 - val_accuracy: 0.9975\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0210 - accuracy: 0.9981 - val_loss: 0.0232 - val_accuracy: 0.9972\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0206 - accuracy: 0.9981 - val_loss: 0.0215 - val_accuracy: 0.9979\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0201 - accuracy: 0.9980 - val_loss: 0.0212 - val_accuracy: 0.9980\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0200 - accuracy: 0.9981 - val_loss: 0.0217 - val_accuracy: 0.9977\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0198 - accuracy: 0.9982 - val_loss: 0.0194 - val_accuracy: 0.9984\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0196 - accuracy: 0.9982 - val_loss: 0.0176 - val_accuracy: 0.9987\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0190 - accuracy: 0.9983 - val_loss: 0.0196 - val_accuracy: 0.9983\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0185 - accuracy: 0.9983 - val_loss: 0.0241 - val_accuracy: 0.9966\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0185 - accuracy: 0.9983 - val_loss: 0.0167 - val_accuracy: 0.9987\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0182 - accuracy: 0.9982 - val_loss: 0.0198 - val_accuracy: 0.9980\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0181 - accuracy: 0.9983 - val_loss: 0.0171 - val_accuracy: 0.9984\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0179 - accuracy: 0.9982 - val_loss: 0.0177 - val_accuracy: 0.9979\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0175 - accuracy: 0.9983 - val_loss: 0.0215 - val_accuracy: 0.9967\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0174 - accuracy: 0.9983 - val_loss: 0.0154 - val_accuracy: 0.9987\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0171 - accuracy: 0.9982 - val_loss: 0.0155 - val_accuracy: 0.9987\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0170 - accuracy: 0.9983 - val_loss: 0.0151 - val_accuracy: 0.9987\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0167 - accuracy: 0.9984 - val_loss: 0.0273 - val_accuracy: 0.9957\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0162 - accuracy: 0.9984 - val_loss: 0.0206 - val_accuracy: 0.9973\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0162 - accuracy: 0.9984 - val_loss: 0.0151 - val_accuracy: 0.9984\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0159 - accuracy: 0.9984 - val_loss: 0.0156 - val_accuracy: 0.9982\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0157 - accuracy: 0.9984 - val_loss: 0.0194 - val_accuracy: 0.9973\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0159 - accuracy: 0.9983 - val_loss: 0.0156 - val_accuracy: 0.9982\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0155 - accuracy: 0.9985 - val_loss: 0.0136 - val_accuracy: 0.9991\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0155 - accuracy: 0.9982 - val_loss: 0.0212 - val_accuracy: 0.9967\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0153 - accuracy: 0.9985 - val_loss: 0.0142 - val_accuracy: 0.9988\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0152 - accuracy: 0.9984 - val_loss: 0.0133 - val_accuracy: 0.9990\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0151 - accuracy: 0.9984 - val_loss: 0.0146 - val_accuracy: 0.9982\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0146 - accuracy: 0.9984 - val_loss: 0.0196 - val_accuracy: 0.9969\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0147 - accuracy: 0.9984 - val_loss: 0.0178 - val_accuracy: 0.9975\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0145 - accuracy: 0.9984 - val_loss: 0.0137 - val_accuracy: 0.9984\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0139 - accuracy: 0.9985 - val_loss: 0.0124 - val_accuracy: 0.9991\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0139 - accuracy: 0.9986 - val_loss: 0.0234 - val_accuracy: 0.9961\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0139 - accuracy: 0.9985 - val_loss: 0.0135 - val_accuracy: 0.9985\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0137 - accuracy: 0.9986 - val_loss: 0.0130 - val_accuracy: 0.9985\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0135 - accuracy: 0.9985 - val_loss: 0.0128 - val_accuracy: 0.9984\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0137 - accuracy: 0.9984 - val_loss: 0.0130 - val_accuracy: 0.9987\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0137 - accuracy: 0.9984 - val_loss: 0.0119 - val_accuracy: 0.9990\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0133 - accuracy: 0.9984 - val_loss: 0.0122 - val_accuracy: 0.9988\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0132 - accuracy: 0.9986 - val_loss: 0.0143 - val_accuracy: 0.9980\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0131 - accuracy: 0.9985 - val_loss: 0.0115 - val_accuracy: 0.9987\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0129 - accuracy: 0.9985 - val_loss: 0.0197 - val_accuracy: 0.9967\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0130 - accuracy: 0.9985 - val_loss: 0.0110 - val_accuracy: 0.9989\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0126 - accuracy: 0.9986 - val_loss: 0.0117 - val_accuracy: 0.9985\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0126 - accuracy: 0.9985 - val_loss: 0.0114 - val_accuracy: 0.9986\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0126 - accuracy: 0.9986 - val_loss: 0.0139 - val_accuracy: 0.9979\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0127 - accuracy: 0.9985 - val_loss: 0.0139 - val_accuracy: 0.9982\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0125 - accuracy: 0.9984 - val_loss: 0.0111 - val_accuracy: 0.9988\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0122 - accuracy: 0.9985 - val_loss: 0.0117 - val_accuracy: 0.9983\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0120 - accuracy: 0.9986 - val_loss: 0.0122 - val_accuracy: 0.9984\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0122 - accuracy: 0.9984 - val_loss: 0.0105 - val_accuracy: 0.9988\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0121 - accuracy: 0.9985 - val_loss: 0.0108 - val_accuracy: 0.9988\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0120 - accuracy: 0.9985 - val_loss: 0.0114 - val_accuracy: 0.9987\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0119 - accuracy: 0.9985 - val_loss: 0.0115 - val_accuracy: 0.9984\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0116 - accuracy: 0.9986 - val_loss: 0.0150 - val_accuracy: 0.9976\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0117 - accuracy: 0.9986 - val_loss: 0.0118 - val_accuracy: 0.9983\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0114 - accuracy: 0.9986 - val_loss: 0.0285 - val_accuracy: 0.9947\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0118 - accuracy: 0.9985 - val_loss: 0.0126 - val_accuracy: 0.9980\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0112 - accuracy: 0.9986 - val_loss: 0.0151 - val_accuracy: 0.9974\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0110 - accuracy: 0.9986 - val_loss: 0.0111 - val_accuracy: 0.9986\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0112 - accuracy: 0.9986 - val_loss: 0.0232 - val_accuracy: 0.9959\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.0167 - val_accuracy: 0.9970\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0107 - accuracy: 0.9986 - val_loss: 0.0151 - val_accuracy: 0.9973\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0107 - accuracy: 0.9987 - val_loss: 0.0096 - val_accuracy: 0.9987\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0110 - accuracy: 0.9985 - val_loss: 0.0100 - val_accuracy: 0.9989\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0105 - accuracy: 0.9987 - val_loss: 0.0093 - val_accuracy: 0.9989\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0108 - accuracy: 0.9986 - val_loss: 0.0121 - val_accuracy: 0.9984\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 0.0130 - val_accuracy: 0.9979\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.0135 - val_accuracy: 0.9977\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0103 - accuracy: 0.9986 - val_loss: 0.0174 - val_accuracy: 0.9970\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 0.0133 - val_accuracy: 0.9979\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.0220 - val_accuracy: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–…â–…â–…â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ˆâ–†â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‡â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99866</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>4e-05</td></tr><tr><td>batch/loss</td><td>0.01035</td></tr><tr><td>epoch/accuracy</td><td>0.99866</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>4e-05</td></tr><tr><td>epoch/loss</td><td>0.01036</td></tr><tr><td>epoch/val_accuracy</td><td>0.99625</td></tr><tr><td>epoch/val_loss</td><td>0.02201</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_16</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/kksjk01o' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/kksjk01o</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_025804-kksjk01o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 03:15:43,328] Trial 16 finished with value: 0.009420822747051716 and parameters: {'Layer_1_units': 115, 'Activation_1': 'sigmoid', 'n_layers': 8, 'Layer_2_units': 76, 'Activation_2': 'relu', 'Layer_3_units': 90, 'Activation_3': 'relu', 'Layer_4_units': 60, 'Activation_4': 'relu', 'Layer_5_units': 69, 'Activation_5': 'relu', 'Layer_6_units': 89, 'Activation_6': 'relu', 'Layer_7_units': 33, 'Activation_7': 'relu', 'Layer_8_units': 34, 'Activation_8': 'relu', 'Layer_9_units': 126, 'Activation_9': 'relu', 'learning_rate': 3.686962364869608e-05, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_031543-kfehsdpl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/kfehsdpl' target=\"_blank\">Trial_17</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/kfehsdpl' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/kfehsdpl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.1624 - accuracy: 0.9397 - val_loss: 0.0805 - val_accuracy: 0.9768\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0584 - accuracy: 0.9849 - val_loss: 0.0393 - val_accuracy: 0.9922\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0319 - accuracy: 0.9944 - val_loss: 0.0244 - val_accuracy: 0.9966\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0253 - accuracy: 0.9961 - val_loss: 0.0278 - val_accuracy: 0.9944\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0214 - accuracy: 0.9967 - val_loss: 0.0206 - val_accuracy: 0.9963\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0191 - accuracy: 0.9969 - val_loss: 0.0200 - val_accuracy: 0.9965\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0172 - accuracy: 0.9973 - val_loss: 0.0139 - val_accuracy: 0.9977\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0164 - accuracy: 0.9974 - val_loss: 0.0178 - val_accuracy: 0.9964\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0147 - accuracy: 0.9977 - val_loss: 0.0222 - val_accuracy: 0.9956\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 0.0124 - val_accuracy: 0.9980\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0128 - accuracy: 0.9978 - val_loss: 0.0187 - val_accuracy: 0.9959\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.0153 - val_accuracy: 0.9972\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0116 - accuracy: 0.9981 - val_loss: 0.0158 - val_accuracy: 0.9969\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0108 - accuracy: 0.9980 - val_loss: 0.0099 - val_accuracy: 0.9982\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 0.0152 - val_accuracy: 0.9970\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 0.0095 - val_accuracy: 0.9980\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.0086 - val_accuracy: 0.9984\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.0080 - val_accuracy: 0.9985\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.0085 - val_accuracy: 0.9983\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.0099 - val_accuracy: 0.9977\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.0112 - val_accuracy: 0.9974\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0092 - val_accuracy: 0.9984\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0087 - val_accuracy: 0.9980\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.0071 - val_accuracy: 0.9984\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.0068 - val_accuracy: 0.9984\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0061 - val_accuracy: 0.9983\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0076 - val_accuracy: 0.9985\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0053 - val_accuracy: 0.9989\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0069 - val_accuracy: 0.9985\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0050 - val_accuracy: 0.9986\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.0075 - val_accuracy: 0.9984\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0095 - val_accuracy: 0.9977\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0055 - val_accuracy: 0.9985\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0063 - val_accuracy: 0.9984\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0072 - val_accuracy: 0.9982\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0050 - val_accuracy: 0.9988\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0063 - val_accuracy: 0.9983\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0047 - val_accuracy: 0.9989\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0060 - val_accuracy: 0.9988\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9983\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0068 - val_accuracy: 0.9984\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0045 - val_accuracy: 0.9988\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0045 - val_accuracy: 0.9990\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0044 - val_accuracy: 0.9990\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0041 - val_accuracy: 0.9990\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0196 - val_accuracy: 0.9961\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0042 - val_accuracy: 0.9990\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0078 - val_accuracy: 0.9981\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0065 - val_accuracy: 0.9980\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0050 - val_accuracy: 0.9986\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0115 - val_accuracy: 0.9969\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9988\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0074 - val_accuracy: 0.9983\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9990\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0040 - val_accuracy: 0.9990\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0049 - val_accuracy: 0.9985\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0055 - val_accuracy: 0.9986\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0055 - val_accuracy: 0.9985\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0064 - val_accuracy: 0.9981\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9989\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 0.9985\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9989\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 0.9986\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 0.9983\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0106 - val_accuracy: 0.9973\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0076 - val_accuracy: 0.9982\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0065 - val_accuracy: 0.9984\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0087 - val_accuracy: 0.9977\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0083 - val_accuracy: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–â–„â–…â–…â–…â–†â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ƒâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99922</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00015</td></tr><tr><td>batch/loss</td><td>0.00291</td></tr><tr><td>epoch/accuracy</td><td>0.99922</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00015</td></tr><tr><td>epoch/loss</td><td>0.00291</td></tr><tr><td>epoch/val_accuracy</td><td>0.99785</td></tr><tr><td>epoch/val_loss</td><td>0.00826</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_17</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/kfehsdpl' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/kfehsdpl</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_031543-kfehsdpl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 03:29:43,343] Trial 17 finished with value: 0.003756333701312542 and parameters: {'Layer_1_units': 111, 'Activation_1': 'sigmoid', 'n_layers': 6, 'Layer_2_units': 64, 'Activation_2': 'relu', 'Layer_3_units': 112, 'Activation_3': 'relu', 'Layer_4_units': 126, 'Activation_4': 'relu', 'Layer_5_units': 78, 'Activation_5': 'relu', 'Layer_6_units': 65, 'Activation_6': 'relu', 'Layer_7_units': 106, 'Activation_7': 'relu', 'learning_rate': 0.00015471619692254853, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_032943-ovx4b88k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/ovx4b88k' target=\"_blank\">Trial_18</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/ovx4b88k' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/ovx4b88k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.5464 - accuracy: 0.7692 - val_loss: 0.5424 - val_accuracy: 0.7689\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5426 - accuracy: 0.7692 - val_loss: 0.5443 - val_accuracy: 0.7689\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5417 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5413 - accuracy: 0.7692 - val_loss: 0.5418 - val_accuracy: 0.7689\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5412 - accuracy: 0.7692 - val_loss: 0.5417 - val_accuracy: 0.7689\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5413 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5411 - accuracy: 0.7692 - val_loss: 0.5412 - val_accuracy: 0.7689\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5411 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5413 - val_accuracy: 0.7689\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5434 - val_accuracy: 0.7689\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5423 - val_accuracy: 0.7689\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5420 - val_accuracy: 0.7689\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5421 - val_accuracy: 0.7689\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5410 - val_accuracy: 0.7689\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5417 - val_accuracy: 0.7689\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5420 - val_accuracy: 0.7689\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5420 - val_accuracy: 0.7689\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5411 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5423 - val_accuracy: 0.7689\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5422 - val_accuracy: 0.7689\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5419 - val_accuracy: 0.7689\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5413 - val_accuracy: 0.7689\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5418 - val_accuracy: 0.7689\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5410 - val_accuracy: 0.7689\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5435 - val_accuracy: 0.7689\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5410 - val_accuracy: 0.7689\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5413 - val_accuracy: 0.7689\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5419 - val_accuracy: 0.7689\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5410 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5414 - val_accuracy: 0.7689\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5411 - val_accuracy: 0.7689\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5410 - val_accuracy: 0.7689\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5412 - val_accuracy: 0.7689\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5428 - val_accuracy: 0.7689\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5415 - val_accuracy: 0.7689\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5416 - val_accuracy: 0.7689\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5412 - val_accuracy: 0.7689\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5410 - val_accuracy: 0.7689\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5411 - val_accuracy: 0.7689\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5421 - val_accuracy: 0.7689\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5420 - val_accuracy: 0.7689\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5410 - val_accuracy: 0.7689\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5407 - val_accuracy: 0.7689\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5409 - val_accuracy: 0.7689\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5408 - val_accuracy: 0.7689\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5409 - accuracy: 0.7692 - val_loss: 0.5413 - val_accuracy: 0.7689\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.5408 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7689\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–â–‚</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–…â–„â–…â–…â–…â–‡â–â–†â–…â–„â–…â–‡â–…â–†â–…â–…â–…â–†â–‡â–„â–…â–…â–„â–„â–…â–„â–„â–…â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…</td></tr><tr><td>epoch/accuracy</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_loss</td><td>â–‚â–‚â–â–‚â–‚â–‡â–‡â–‡â–â–ˆâ–ƒâ–‚â–‚â–â–â–‚â–‚â–â–â–„â–â–‡â–â–â–â–â–â–‚â–â–â–‚â–‚â–‚â–â–ƒâ–ˆâ–â–‚â–‡â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.76922</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00053</td></tr><tr><td>batch/loss</td><td>0.54079</td></tr><tr><td>epoch/accuracy</td><td>0.76921</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00053</td></tr><tr><td>epoch/loss</td><td>0.54081</td></tr><tr><td>epoch/val_accuracy</td><td>0.7689</td></tr><tr><td>epoch/val_loss</td><td>0.5406</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_18</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/ovx4b88k' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/ovx4b88k</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_032943-ovx4b88k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 03:44:48,880] Trial 18 finished with value: 0.54061439037323 and parameters: {'Layer_1_units': 128, 'Activation_1': 'relu', 'n_layers': 10, 'Layer_2_units': 88, 'Activation_2': 'relu', 'Layer_3_units': 81, 'Activation_3': 'relu', 'Layer_4_units': 49, 'Activation_4': 'relu', 'Layer_5_units': 39, 'Activation_5': 'sigmoid', 'Layer_6_units': 106, 'Activation_6': 'relu', 'Layer_7_units': 55, 'Activation_7': 'relu', 'Layer_8_units': 33, 'Activation_8': 'sigmoid', 'Layer_9_units': 52, 'Activation_9': 'relu', 'Layer_10_units': 44, 'Activation_10': 'sigmoid', 'Layer_11_units': 127, 'Activation_11': 'sigmoid', 'learning_rate': 0.0005269148710603641, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_034448-4c1ibjkh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4c1ibjkh' target=\"_blank\">Trial_19</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4c1ibjkh' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4c1ibjkh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1400/1400 [==============================] - 3s 2ms/step - loss: 0.1111 - accuracy: 0.9607 - val_loss: 0.0331 - val_accuracy: 0.9948\n",
      "Epoch 2/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0248 - accuracy: 0.9956 - val_loss: 0.0190 - val_accuracy: 0.9967\n",
      "Epoch 3/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0194 - accuracy: 0.9964 - val_loss: 0.0177 - val_accuracy: 0.9963\n",
      "Epoch 4/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0176 - accuracy: 0.9963 - val_loss: 0.0135 - val_accuracy: 0.9973\n",
      "Epoch 5/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.0153 - val_accuracy: 0.9961\n",
      "Epoch 6/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0120 - accuracy: 0.9976 - val_loss: 0.0114 - val_accuracy: 0.9975\n",
      "Epoch 7/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.0113 - val_accuracy: 0.9969\n",
      "Epoch 8/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0180 - val_accuracy: 0.9954\n",
      "Epoch 9/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.0156 - val_accuracy: 0.9957\n",
      "Epoch 10/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.0083 - val_accuracy: 0.9979\n",
      "Epoch 11/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.0108 - val_accuracy: 0.9973\n",
      "Epoch 12/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0101 - val_accuracy: 0.9972\n",
      "Epoch 13/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0072 - val_accuracy: 0.9984\n",
      "Epoch 14/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.0265 - val_accuracy: 0.9907\n",
      "Epoch 15/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0068 - val_accuracy: 0.9980\n",
      "Epoch 16/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0083 - val_accuracy: 0.9977\n",
      "Epoch 17/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0069 - val_accuracy: 0.9979\n",
      "Epoch 18/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0074 - val_accuracy: 0.9978\n",
      "Epoch 19/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.0085 - val_accuracy: 0.9979\n",
      "Epoch 20/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0074 - val_accuracy: 0.9980\n",
      "Epoch 21/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0069 - val_accuracy: 0.9983\n",
      "Epoch 22/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0074 - val_accuracy: 0.9979\n",
      "Epoch 23/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0079 - val_accuracy: 0.9977\n",
      "Epoch 24/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
      "Epoch 25/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0104 - val_accuracy: 0.9969\n",
      "Epoch 26/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0087 - val_accuracy: 0.9977\n",
      "Epoch 27/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0062 - val_accuracy: 0.9984\n",
      "Epoch 28/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0080 - val_accuracy: 0.9980\n",
      "Epoch 29/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0090 - val_accuracy: 0.9975\n",
      "Epoch 30/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0097 - val_accuracy: 0.9977\n",
      "Epoch 31/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0080 - val_accuracy: 0.9979\n",
      "Epoch 32/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 33/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0086 - val_accuracy: 0.9979\n",
      "Epoch 34/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0090 - val_accuracy: 0.9978\n",
      "Epoch 35/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0077 - val_accuracy: 0.9983\n",
      "Epoch 36/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0095 - val_accuracy: 0.9977\n",
      "Epoch 37/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0129 - val_accuracy: 0.9972\n",
      "Epoch 38/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0078 - val_accuracy: 0.9977\n",
      "Epoch 39/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0110 - val_accuracy: 0.9976\n",
      "Epoch 40/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0072 - val_accuracy: 0.9980\n",
      "Epoch 41/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0103 - val_accuracy: 0.9977\n",
      "Epoch 42/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0092 - val_accuracy: 0.9976\n",
      "Epoch 43/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0089 - val_accuracy: 0.9977\n",
      "Epoch 44/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0386 - val_accuracy: 0.9936\n",
      "Epoch 45/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0142 - val_accuracy: 0.9969\n",
      "Epoch 46/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0093 - val_accuracy: 0.9977\n",
      "Epoch 47/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0086 - val_accuracy: 0.9979\n",
      "Epoch 48/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0116 - val_accuracy: 0.9976\n",
      "Epoch 49/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0089 - val_accuracy: 0.9979\n",
      "Epoch 50/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0090 - val_accuracy: 0.9973\n",
      "Epoch 51/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0122 - val_accuracy: 0.9973\n",
      "Epoch 52/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9977\n",
      "Epoch 53/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0077 - val_accuracy: 0.9977\n",
      "Epoch 54/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0115 - val_accuracy: 0.9971\n",
      "Epoch 55/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0110 - val_accuracy: 0.9977\n",
      "Epoch 56/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0124 - val_accuracy: 0.9973\n",
      "Epoch 57/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0124 - val_accuracy: 0.9975\n",
      "Epoch 58/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0126 - val_accuracy: 0.9973\n",
      "Epoch 59/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0094 - val_accuracy: 0.9978\n",
      "Epoch 60/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0106 - val_accuracy: 0.9977\n",
      "Epoch 61/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0138 - val_accuracy: 0.9972\n",
      "Epoch 62/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0076 - val_accuracy: 0.9978\n",
      "Epoch 63/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9974\n",
      "Epoch 64/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0094 - val_accuracy: 0.9977\n",
      "Epoch 65/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9980\n",
      "Epoch 66/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9976\n",
      "Epoch 67/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0099 - val_accuracy: 0.9973\n",
      "Epoch 68/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9975\n",
      "Epoch 69/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0150 - val_accuracy: 0.9968\n",
      "Epoch 70/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0123 - val_accuracy: 0.9973\n",
      "Epoch 71/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9976\n",
      "Epoch 72/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0090 - val_accuracy: 0.9976\n",
      "Epoch 73/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0120 - val_accuracy: 0.9973\n",
      "Epoch 74/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0112 - val_accuracy: 0.9974\n",
      "Epoch 75/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0111 - val_accuracy: 0.9977\n",
      "Epoch 76/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0097 - val_accuracy: 0.9974\n",
      "Epoch 77/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0099 - val_accuracy: 0.9977\n",
      "Epoch 78/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0096 - val_accuracy: 0.9977\n",
      "Epoch 79/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0170 - val_accuracy: 0.9967\n",
      "Epoch 80/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0172 - val_accuracy: 0.9970\n",
      "Epoch 81/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0128 - val_accuracy: 0.9974\n",
      "Epoch 82/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0095 - val_accuracy: 0.9977\n",
      "Epoch 83/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0105 - val_accuracy: 0.9975\n",
      "Epoch 84/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0098 - val_accuracy: 0.9975\n",
      "Epoch 85/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0091 - val_accuracy: 0.9977\n",
      "Epoch 86/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0093 - val_accuracy: 0.9973\n",
      "Epoch 87/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0084 - val_accuracy: 0.9976\n",
      "Epoch 88/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9977\n",
      "Epoch 89/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0121 - val_accuracy: 0.9970\n",
      "Epoch 90/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9979\n",
      "Epoch 91/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 9.9279e-04 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9976\n",
      "Epoch 92/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0116 - val_accuracy: 0.9972\n",
      "Epoch 93/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 9.6915e-04 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9972\n",
      "Epoch 94/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0096 - val_accuracy: 0.9977\n",
      "Epoch 95/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0119 - val_accuracy: 0.9973\n",
      "Epoch 96/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 9.6928e-04 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9977\n",
      "Epoch 97/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 8.8627e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9973\n",
      "Epoch 98/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0115 - val_accuracy: 0.9974\n",
      "Epoch 99/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9977\n",
      "Epoch 100/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0103 - val_accuracy: 0.9974\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–†â–„â–†â–†â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–…â–‡â–‡â–‡â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–…â–†â–†â–†â–†â–†â–‡â–†</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ƒâ–‚â–ƒâ–‚â–†â–â–â–â–â–‚â–‚â–â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99979</td></tr><tr><td>batch/batch_step</td><td>139995</td></tr><tr><td>batch/learning_rate</td><td>0.00142</td></tr><tr><td>batch/loss</td><td>0.00158</td></tr><tr><td>epoch/accuracy</td><td>0.99979</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00142</td></tr><tr><td>epoch/loss</td><td>0.00158</td></tr><tr><td>epoch/val_accuracy</td><td>0.9974</td></tr><tr><td>epoch/val_loss</td><td>0.01033</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_19</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4c1ibjkh' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4c1ibjkh</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_034448-4c1ibjkh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 03:48:09,206] Trial 19 finished with value: 0.005688469618326053 and parameters: {'Layer_1_units': 72, 'Activation_1': 'sigmoid', 'n_layers': 5, 'Layer_2_units': 114, 'Activation_2': 'relu', 'Layer_3_units': 108, 'Activation_3': 'relu', 'Layer_4_units': 70, 'Activation_4': 'relu', 'Layer_5_units': 57, 'Activation_5': 'relu', 'Layer_6_units': 51, 'Activation_6': 'relu', 'learning_rate': 0.001423036599740097, 'optimizer': 'adam', 'batch_size': 100}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_034809-3ubal1xz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/3ubal1xz' target=\"_blank\">Trial_20</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/3ubal1xz' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/3ubal1xz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3500/3500 [==============================] - 6s 2ms/step - loss: 0.2123 - accuracy: 0.9225 - val_loss: 0.1324 - val_accuracy: 0.9551\n",
      "Epoch 2/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0883 - accuracy: 0.9759 - val_loss: 0.0670 - val_accuracy: 0.9827\n",
      "Epoch 3/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0448 - accuracy: 0.9917 - val_loss: 0.0347 - val_accuracy: 0.9947\n",
      "Epoch 4/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0304 - accuracy: 0.9957 - val_loss: 0.0239 - val_accuracy: 0.9973\n",
      "Epoch 5/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0253 - accuracy: 0.9963 - val_loss: 0.0200 - val_accuracy: 0.9979\n",
      "Epoch 6/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0219 - accuracy: 0.9969 - val_loss: 0.0205 - val_accuracy: 0.9970\n",
      "Epoch 7/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0196 - accuracy: 0.9972 - val_loss: 0.0170 - val_accuracy: 0.9976\n",
      "Epoch 8/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0185 - accuracy: 0.9973 - val_loss: 0.0185 - val_accuracy: 0.9969\n",
      "Epoch 9/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0168 - accuracy: 0.9975 - val_loss: 0.0144 - val_accuracy: 0.9978\n",
      "Epoch 10/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0155 - accuracy: 0.9977 - val_loss: 0.0173 - val_accuracy: 0.9969\n",
      "Epoch 11/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0156 - accuracy: 0.9975 - val_loss: 0.0179 - val_accuracy: 0.9963\n",
      "Epoch 12/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0144 - accuracy: 0.9977 - val_loss: 0.0129 - val_accuracy: 0.9980\n",
      "Epoch 13/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 0.0180 - val_accuracy: 0.9969\n",
      "Epoch 14/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0133 - accuracy: 0.9979 - val_loss: 0.0278 - val_accuracy: 0.9946\n",
      "Epoch 15/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0129 - accuracy: 0.9980 - val_loss: 0.0338 - val_accuracy: 0.9939\n",
      "Epoch 16/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.0109 - val_accuracy: 0.9984\n",
      "Epoch 17/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0120 - accuracy: 0.9981 - val_loss: 0.0102 - val_accuracy: 0.9983\n",
      "Epoch 18/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0115 - accuracy: 0.9981 - val_loss: 0.0277 - val_accuracy: 0.9949\n",
      "Epoch 19/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0112 - accuracy: 0.9981 - val_loss: 0.0109 - val_accuracy: 0.9984\n",
      "Epoch 20/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 0.0118 - val_accuracy: 0.9982\n",
      "Epoch 21/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.0109 - val_accuracy: 0.9981\n",
      "Epoch 22/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.0158 - val_accuracy: 0.9965\n",
      "Epoch 23/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0112 - val_accuracy: 0.9978\n",
      "Epoch 24/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0090 - val_accuracy: 0.9984\n",
      "Epoch 25/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0093 - val_accuracy: 0.9987\n",
      "Epoch 26/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0091 - accuracy: 0.9986 - val_loss: 0.0082 - val_accuracy: 0.9986\n",
      "Epoch 27/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.0147 - val_accuracy: 0.9977\n",
      "Epoch 28/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.0096 - val_accuracy: 0.9984\n",
      "Epoch 29/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0084 - accuracy: 0.9987 - val_loss: 0.0282 - val_accuracy: 0.9952\n",
      "Epoch 30/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0082 - accuracy: 0.9987 - val_loss: 0.0096 - val_accuracy: 0.9984\n",
      "Epoch 31/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.0190 - val_accuracy: 0.9964\n",
      "Epoch 32/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.0121 - val_accuracy: 0.9979\n",
      "Epoch 33/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0079 - val_accuracy: 0.9987\n",
      "Epoch 34/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0075 - val_accuracy: 0.9987\n",
      "Epoch 35/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.0068 - val_accuracy: 0.9988\n",
      "Epoch 36/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.0120 - val_accuracy: 0.9977\n",
      "Epoch 37/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.0087 - val_accuracy: 0.9984\n",
      "Epoch 38/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.0091 - val_accuracy: 0.9984\n",
      "Epoch 39/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.0092 - val_accuracy: 0.9983\n",
      "Epoch 40/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0091 - val_accuracy: 0.9984\n",
      "Epoch 41/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.0078 - val_accuracy: 0.9987\n",
      "Epoch 42/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0071 - accuracy: 0.9990 - val_loss: 0.0069 - val_accuracy: 0.9988\n",
      "Epoch 43/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0067 - accuracy: 0.9990 - val_loss: 0.0125 - val_accuracy: 0.9978\n",
      "Epoch 44/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
      "Epoch 45/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
      "Epoch 46/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.0094 - val_accuracy: 0.9981\n",
      "Epoch 47/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0067 - accuracy: 0.9990 - val_loss: 0.0081 - val_accuracy: 0.9984\n",
      "Epoch 48/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.0082 - val_accuracy: 0.9984\n",
      "Epoch 49/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0070 - val_accuracy: 0.9990\n",
      "Epoch 50/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.0085 - val_accuracy: 0.9987\n",
      "Epoch 51/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.0115 - val_accuracy: 0.9980\n",
      "Epoch 52/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 0.0075 - val_accuracy: 0.9985\n",
      "Epoch 53/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
      "Epoch 54/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
      "Epoch 55/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.0080 - val_accuracy: 0.9987\n",
      "Epoch 56/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.0153 - val_accuracy: 0.9969\n",
      "Epoch 57/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.0097 - val_accuracy: 0.9981\n",
      "Epoch 58/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.0118 - val_accuracy: 0.9977\n",
      "Epoch 59/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
      "Epoch 60/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 0.0073 - val_accuracy: 0.9987\n",
      "Epoch 61/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0147 - val_accuracy: 0.9971\n",
      "Epoch 62/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.0057 - val_accuracy: 0.9989\n",
      "Epoch 63/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.0058 - val_accuracy: 0.9988\n",
      "Epoch 64/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.0069 - val_accuracy: 0.9985\n",
      "Epoch 65/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0060 - val_accuracy: 0.9988\n",
      "Epoch 66/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.0071 - val_accuracy: 0.9985\n",
      "Epoch 67/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.0088 - val_accuracy: 0.9981\n",
      "Epoch 68/100\n",
      "3500/3500 [==============================] - 6s 2ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0074 - val_accuracy: 0.9986\n",
      "Epoch 69/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.0085 - val_accuracy: 0.9985\n",
      "Epoch 70/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0084 - val_accuracy: 0.9984\n",
      "Epoch 71/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0154 - val_accuracy: 0.9970\n",
      "Epoch 72/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0108 - val_accuracy: 0.9978\n",
      "Epoch 73/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
      "Epoch 74/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.0069 - val_accuracy: 0.9985\n",
      "Epoch 75/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.0060 - val_accuracy: 0.9988\n",
      "Epoch 76/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
      "Epoch 77/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0076 - val_accuracy: 0.9983\n",
      "Epoch 78/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.0072 - val_accuracy: 0.9987\n",
      "Epoch 79/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0115 - val_accuracy: 0.9980\n",
      "Epoch 80/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0087 - val_accuracy: 0.9981\n",
      "Epoch 81/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0059 - val_accuracy: 0.9989\n",
      "Epoch 82/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.0187 - val_accuracy: 0.9966\n",
      "Epoch 83/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.0066 - val_accuracy: 0.9988\n",
      "Epoch 84/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.0077 - val_accuracy: 0.9983\n",
      "Epoch 85/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
      "Epoch 86/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
      "Epoch 87/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.0105 - val_accuracy: 0.9979\n",
      "Epoch 88/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.0067 - val_accuracy: 0.9986\n",
      "Epoch 89/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.0090 - val_accuracy: 0.9981\n",
      "Epoch 90/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.0097 - val_accuracy: 0.9979\n",
      "Epoch 91/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0203 - val_accuracy: 0.9958\n",
      "Epoch 92/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0077 - val_accuracy: 0.9984\n",
      "Epoch 93/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0054 - val_accuracy: 0.9988\n",
      "Epoch 94/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 0.9984\n",
      "Epoch 95/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0057 - val_accuracy: 0.9988\n",
      "Epoch 96/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0059 - val_accuracy: 0.9990\n",
      "Epoch 97/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0110 - val_accuracy: 0.9979\n",
      "Epoch 98/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0065 - val_accuracy: 0.9986\n",
      "Epoch 99/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.0083 - val_accuracy: 0.9982\n",
      "Epoch 100/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 0.0057 - val_accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–„â–„â–„â–ƒâ–ˆâ–‚â–‚â–ƒâ–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–ƒâ–â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–‚â–â–â–â–‚â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99933</td></tr><tr><td>batch/batch_step</td><td>349995</td></tr><tr><td>batch/learning_rate</td><td>0.00027</td></tr><tr><td>batch/loss</td><td>0.00455</td></tr><tr><td>epoch/accuracy</td><td>0.99934</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00027</td></tr><tr><td>epoch/loss</td><td>0.00455</td></tr><tr><td>epoch/val_accuracy</td><td>0.99885</td></tr><tr><td>epoch/val_loss</td><td>0.00568</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_20</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/3ubal1xz' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/3ubal1xz</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_034809-3ubal1xz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 03:56:43,237] Trial 20 finished with value: 0.0053366049192845825 and parameters: {'Layer_1_units': 92, 'Activation_1': 'sigmoid', 'n_layers': 8, 'Layer_2_units': 68, 'Activation_2': 'relu', 'Layer_3_units': 82, 'Activation_3': 'relu', 'Layer_4_units': 73, 'Activation_4': 'relu', 'Layer_5_units': 128, 'Activation_5': 'relu', 'Layer_6_units': 106, 'Activation_6': 'sigmoid', 'Layer_7_units': 94, 'Activation_7': 'sigmoid', 'Layer_8_units': 128, 'Activation_8': 'relu', 'Layer_9_units': 67, 'Activation_9': 'relu', 'learning_rate': 0.00026897941434709654, 'optimizer': 'rmsprop', 'batch_size': 40}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_035643-qwdaqku4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/qwdaqku4' target=\"_blank\">Trial_21</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/qwdaqku4' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/qwdaqku4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2800/2800 [==============================] - 4s 1ms/step - loss: 0.0858 - accuracy: 0.9684 - val_loss: 0.0248 - val_accuracy: 0.9941\n",
      "Epoch 2/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0206 - accuracy: 0.9947 - val_loss: 0.0152 - val_accuracy: 0.9960\n",
      "Epoch 3/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.0098 - val_accuracy: 0.9973\n",
      "Epoch 4/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.0125 - val_accuracy: 0.9972\n",
      "Epoch 5/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0270 - val_accuracy: 0.9950\n",
      "Epoch 6/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.0226 - val_accuracy: 0.9948\n",
      "Epoch 7/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.0090 - val_accuracy: 0.9979\n",
      "Epoch 8/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.0082 - val_accuracy: 0.9973\n",
      "Epoch 9/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0379 - val_accuracy: 0.9939\n",
      "Epoch 10/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0105 - val_accuracy: 0.9974\n",
      "Epoch 11/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0079 - val_accuracy: 0.9980\n",
      "Epoch 12/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.0093 - val_accuracy: 0.9973\n",
      "Epoch 13/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.0162 - val_accuracy: 0.9970\n",
      "Epoch 14/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0246 - val_accuracy: 0.9954\n",
      "Epoch 15/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 16/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0089 - val_accuracy: 0.9972\n",
      "Epoch 17/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0089 - val_accuracy: 0.9980\n",
      "Epoch 18/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0063 - val_accuracy: 0.9980\n",
      "Epoch 19/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0070 - val_accuracy: 0.9977\n",
      "Epoch 20/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0069 - val_accuracy: 0.9983\n",
      "Epoch 21/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.0065 - val_accuracy: 0.9985\n",
      "Epoch 22/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0078 - val_accuracy: 0.9983\n",
      "Epoch 23/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0083 - val_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0079 - val_accuracy: 0.9983\n",
      "Epoch 25/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0096 - val_accuracy: 0.9972\n",
      "Epoch 26/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0083 - val_accuracy: 0.9981\n",
      "Epoch 27/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9981\n",
      "Epoch 28/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0177 - val_accuracy: 0.9969\n",
      "Epoch 29/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0080 - val_accuracy: 0.9981\n",
      "Epoch 30/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0153 - val_accuracy: 0.9958\n",
      "Epoch 31/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0098 - val_accuracy: 0.9983\n",
      "Epoch 32/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0082 - val_accuracy: 0.9981\n",
      "Epoch 33/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0063 - val_accuracy: 0.9980\n",
      "Epoch 34/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0067 - val_accuracy: 0.9983\n",
      "Epoch 35/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0141 - val_accuracy: 0.9974\n",
      "Epoch 36/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0079 - val_accuracy: 0.9981\n",
      "Epoch 37/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "Epoch 38/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 39/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0094 - val_accuracy: 0.9977\n",
      "Epoch 40/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0148 - val_accuracy: 0.9974\n",
      "Epoch 41/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0078 - val_accuracy: 0.9986\n",
      "Epoch 42/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0045 - val_accuracy: 0.9986\n",
      "Epoch 43/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0095 - val_accuracy: 0.9981\n",
      "Epoch 44/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0078 - val_accuracy: 0.9986\n",
      "Epoch 45/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0064 - val_accuracy: 0.9978\n",
      "Epoch 46/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0074 - val_accuracy: 0.9970\n",
      "Epoch 47/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0068 - val_accuracy: 0.9986\n",
      "Epoch 48/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0103 - val_accuracy: 0.9979\n",
      "Epoch 49/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0088 - val_accuracy: 0.9984\n",
      "Epoch 50/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
      "Epoch 51/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0088 - val_accuracy: 0.9983\n",
      "Epoch 52/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0141 - val_accuracy: 0.9973\n",
      "Epoch 53/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0080 - val_accuracy: 0.9983\n",
      "Epoch 54/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0081 - val_accuracy: 0.9984\n",
      "Epoch 55/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0070 - val_accuracy: 0.9981\n",
      "Epoch 56/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0081 - val_accuracy: 0.9983\n",
      "Epoch 57/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0087 - val_accuracy: 0.9984\n",
      "Epoch 58/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0117 - val_accuracy: 0.9981\n",
      "Epoch 59/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0068 - val_accuracy: 0.9985\n",
      "Epoch 60/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9984\n",
      "Epoch 61/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0094 - val_accuracy: 0.9981\n",
      "Epoch 62/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 63/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
      "Epoch 64/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0085 - val_accuracy: 0.9984\n",
      "Epoch 65/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Epoch 66/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0078 - val_accuracy: 0.9984\n",
      "Epoch 67/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0050 - val_accuracy: 0.9988\n",
      "Epoch 68/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 69/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0057 - val_accuracy: 0.9988\n",
      "Epoch 70/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0171 - val_accuracy: 0.9973\n",
      "Epoch 71/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9988\n",
      "Epoch 72/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
      "Epoch 73/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0089 - val_accuracy: 0.9985\n",
      "Epoch 74/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
      "Epoch 75/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 0.9984\n",
      "Epoch 76/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0166 - val_accuracy: 0.9976\n",
      "Epoch 77/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
      "Epoch 78/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0085 - val_accuracy: 0.9984\n",
      "Epoch 79/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0110 - val_accuracy: 0.9984\n",
      "Epoch 80/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0088 - val_accuracy: 0.9983\n",
      "Epoch 81/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0052 - val_accuracy: 0.9988\n",
      "Epoch 82/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0057 - val_accuracy: 0.9986\n",
      "Epoch 83/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0144 - val_accuracy: 0.9973\n",
      "Epoch 84/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0063 - val_accuracy: 0.9986\n",
      "Epoch 85/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9990\n",
      "Epoch 86/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9988\n",
      "Epoch 87/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0063 - val_accuracy: 0.9986\n",
      "Epoch 88/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "Epoch 89/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
      "Epoch 90/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9989\n",
      "Epoch 91/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 92/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "Epoch 93/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0162 - val_accuracy: 0.9979\n",
      "Epoch 94/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 95/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0130 - val_accuracy: 0.9978\n",
      "Epoch 96/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
      "Epoch 97/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0052 - val_accuracy: 0.9985\n",
      "Epoch 98/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
      "Epoch 99/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
      "Epoch 100/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0049 - val_accuracy: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–„â–‚â–â–†â–†â–ƒâ–‡â–‡â–†â–‡â–‡â–„â–‡â–‡â–‡â–†â–‡â–ˆâ–…â–‡â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–ˆâ–ˆâ–ˆâ–‡â–†â–†â–‡â–‡â–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–‡â–‚â–…â–ˆâ–‚â–‚â–†â–‚â–…â–‚â–„â–‚â–â–…â–ƒâ–‚â–ƒâ–‚â–‚â–„â–‚â–‚â–â–â–ƒâ–‚â–ƒâ–ƒâ–â–â–â–‚â–‚â–â–…â–„â–‚â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99936</td></tr><tr><td>batch/batch_step</td><td>279995</td></tr><tr><td>batch/learning_rate</td><td>0.00845</td></tr><tr><td>batch/loss</td><td>0.00283</td></tr><tr><td>epoch/accuracy</td><td>0.99936</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00845</td></tr><tr><td>epoch/loss</td><td>0.00283</td></tr><tr><td>epoch/val_accuracy</td><td>0.99865</td></tr><tr><td>epoch/val_loss</td><td>0.00494</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_21</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/qwdaqku4' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/qwdaqku4</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_035643-qwdaqku4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 04:01:39,586] Trial 21 finished with value: 0.0035785966319963336 and parameters: {'Layer_1_units': 88, 'Activation_1': 'sigmoid', 'n_layers': 3, 'Layer_2_units': 105, 'Activation_2': 'sigmoid', 'Layer_3_units': 72, 'Activation_3': 'relu', 'Layer_4_units': 92, 'Activation_4': 'relu', 'learning_rate': 0.008447158077318823, 'optimizer': 'rmsprop', 'batch_size': 50}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_040139-8qyqpuoh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/8qyqpuoh' target=\"_blank\">Trial_22</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/8qyqpuoh' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/8qyqpuoh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.2853 - accuracy: 0.8799 - val_loss: 0.1519 - val_accuracy: 0.9422\n",
      "Epoch 2/100\n",
      "2800/2800 [==============================] - 3s 982us/step - loss: 0.1468 - accuracy: 0.9424 - val_loss: 0.1439 - val_accuracy: 0.9438\n",
      "Epoch 3/100\n",
      "2800/2800 [==============================] - 3s 975us/step - loss: 0.1436 - accuracy: 0.9432 - val_loss: 0.1427 - val_accuracy: 0.9433\n",
      "Epoch 4/100\n",
      "2800/2800 [==============================] - 3s 985us/step - loss: 0.1418 - accuracy: 0.9438 - val_loss: 0.1412 - val_accuracy: 0.9439\n",
      "Epoch 5/100\n",
      "2800/2800 [==============================] - 3s 982us/step - loss: 0.1395 - accuracy: 0.9447 - val_loss: 0.1365 - val_accuracy: 0.9457\n",
      "Epoch 6/100\n",
      "2800/2800 [==============================] - 3s 980us/step - loss: 0.1370 - accuracy: 0.9461 - val_loss: 0.1367 - val_accuracy: 0.9457\n",
      "Epoch 7/100\n",
      "2800/2800 [==============================] - 3s 981us/step - loss: 0.1332 - accuracy: 0.9479 - val_loss: 0.1293 - val_accuracy: 0.9493\n",
      "Epoch 8/100\n",
      "2800/2800 [==============================] - 3s 983us/step - loss: 0.1278 - accuracy: 0.9505 - val_loss: 0.1274 - val_accuracy: 0.9520\n",
      "Epoch 9/100\n",
      "2800/2800 [==============================] - 3s 982us/step - loss: 0.1202 - accuracy: 0.9543 - val_loss: 0.1155 - val_accuracy: 0.9574\n",
      "Epoch 10/100\n",
      "2800/2800 [==============================] - 3s 983us/step - loss: 0.1107 - accuracy: 0.9593 - val_loss: 0.1074 - val_accuracy: 0.9609\n",
      "Epoch 11/100\n",
      "2800/2800 [==============================] - 3s 980us/step - loss: 0.1001 - accuracy: 0.9652 - val_loss: 0.0945 - val_accuracy: 0.9681\n",
      "Epoch 12/100\n",
      "2800/2800 [==============================] - 3s 984us/step - loss: 0.0895 - accuracy: 0.9708 - val_loss: 0.0848 - val_accuracy: 0.9743\n",
      "Epoch 13/100\n",
      "2800/2800 [==============================] - 3s 976us/step - loss: 0.0801 - accuracy: 0.9758 - val_loss: 0.0772 - val_accuracy: 0.9781\n",
      "Epoch 14/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0723 - accuracy: 0.9797 - val_loss: 0.0694 - val_accuracy: 0.9811\n",
      "Epoch 15/100\n",
      "2800/2800 [==============================] - 3s 984us/step - loss: 0.0654 - accuracy: 0.9833 - val_loss: 0.0621 - val_accuracy: 0.9851\n",
      "Epoch 16/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0584 - accuracy: 0.9858 - val_loss: 0.0561 - val_accuracy: 0.9876\n",
      "Epoch 17/100\n",
      "2800/2800 [==============================] - 3s 986us/step - loss: 0.0517 - accuracy: 0.9881 - val_loss: 0.0512 - val_accuracy: 0.9884\n",
      "Epoch 18/100\n",
      "2800/2800 [==============================] - 3s 977us/step - loss: 0.0454 - accuracy: 0.9901 - val_loss: 0.0475 - val_accuracy: 0.9883\n",
      "Epoch 19/100\n",
      "2800/2800 [==============================] - 3s 983us/step - loss: 0.0392 - accuracy: 0.9923 - val_loss: 0.0370 - val_accuracy: 0.9931\n",
      "Epoch 20/100\n",
      "2800/2800 [==============================] - 3s 978us/step - loss: 0.0341 - accuracy: 0.9936 - val_loss: 0.0319 - val_accuracy: 0.9944\n",
      "Epoch 21/100\n",
      "2800/2800 [==============================] - 3s 977us/step - loss: 0.0301 - accuracy: 0.9947 - val_loss: 0.0293 - val_accuracy: 0.9947\n",
      "Epoch 22/100\n",
      "2800/2800 [==============================] - 3s 982us/step - loss: 0.0268 - accuracy: 0.9955 - val_loss: 0.0259 - val_accuracy: 0.9954\n",
      "Epoch 23/100\n",
      "2800/2800 [==============================] - 3s 985us/step - loss: 0.0244 - accuracy: 0.9961 - val_loss: 0.0256 - val_accuracy: 0.9948\n",
      "Epoch 24/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0225 - accuracy: 0.9967 - val_loss: 0.0249 - val_accuracy: 0.9959\n",
      "Epoch 25/100\n",
      "2800/2800 [==============================] - 3s 977us/step - loss: 0.0210 - accuracy: 0.9971 - val_loss: 0.0240 - val_accuracy: 0.9965\n",
      "Epoch 26/100\n",
      "2800/2800 [==============================] - 3s 982us/step - loss: 0.0198 - accuracy: 0.9974 - val_loss: 0.0199 - val_accuracy: 0.9970\n",
      "Epoch 27/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0189 - accuracy: 0.9974 - val_loss: 0.0287 - val_accuracy: 0.9942\n",
      "Epoch 28/100\n",
      "2800/2800 [==============================] - 3s 980us/step - loss: 0.0180 - accuracy: 0.9976 - val_loss: 0.0188 - val_accuracy: 0.9969\n",
      "Epoch 29/100\n",
      "2800/2800 [==============================] - 3s 973us/step - loss: 0.0175 - accuracy: 0.9975 - val_loss: 0.0188 - val_accuracy: 0.9967\n",
      "Epoch 30/100\n",
      "2800/2800 [==============================] - 3s 973us/step - loss: 0.0167 - accuracy: 0.9978 - val_loss: 0.0174 - val_accuracy: 0.9975\n",
      "Epoch 31/100\n",
      "2800/2800 [==============================] - 3s 970us/step - loss: 0.0160 - accuracy: 0.9979 - val_loss: 0.0161 - val_accuracy: 0.9977\n",
      "Epoch 32/100\n",
      "2800/2800 [==============================] - 3s 971us/step - loss: 0.0156 - accuracy: 0.9978 - val_loss: 0.0156 - val_accuracy: 0.9978\n",
      "Epoch 33/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0151 - accuracy: 0.9979 - val_loss: 0.0153 - val_accuracy: 0.9973\n",
      "Epoch 34/100\n",
      "2800/2800 [==============================] - 3s 978us/step - loss: 0.0147 - accuracy: 0.9979 - val_loss: 0.0146 - val_accuracy: 0.9979\n",
      "Epoch 35/100\n",
      "2800/2800 [==============================] - 3s 980us/step - loss: 0.0141 - accuracy: 0.9982 - val_loss: 0.0148 - val_accuracy: 0.9970\n",
      "Epoch 36/100\n",
      "2800/2800 [==============================] - 3s 978us/step - loss: 0.0138 - accuracy: 0.9981 - val_loss: 0.0214 - val_accuracy: 0.9953\n",
      "Epoch 37/100\n",
      "2800/2800 [==============================] - 3s 973us/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 0.0136 - val_accuracy: 0.9977\n",
      "Epoch 38/100\n",
      "2800/2800 [==============================] - 3s 974us/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 0.0141 - val_accuracy: 0.9977\n",
      "Epoch 39/100\n",
      "2800/2800 [==============================] - 3s 974us/step - loss: 0.0127 - accuracy: 0.9981 - val_loss: 0.0125 - val_accuracy: 0.9981\n",
      "Epoch 40/100\n",
      "2800/2800 [==============================] - 3s 975us/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 0.0161 - val_accuracy: 0.9969\n",
      "Epoch 41/100\n",
      "2800/2800 [==============================] - 3s 973us/step - loss: 0.0121 - accuracy: 0.9981 - val_loss: 0.0122 - val_accuracy: 0.9984\n",
      "Epoch 42/100\n",
      "2800/2800 [==============================] - 3s 975us/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.0118 - val_accuracy: 0.9980\n",
      "Epoch 43/100\n",
      "2800/2800 [==============================] - 3s 981us/step - loss: 0.0115 - accuracy: 0.9982 - val_loss: 0.0119 - val_accuracy: 0.9982\n",
      "Epoch 44/100\n",
      "2800/2800 [==============================] - 3s 978us/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.0123 - val_accuracy: 0.9977\n",
      "Epoch 45/100\n",
      "2800/2800 [==============================] - 3s 976us/step - loss: 0.0113 - accuracy: 0.9981 - val_loss: 0.0154 - val_accuracy: 0.9965\n",
      "Epoch 46/100\n",
      "2800/2800 [==============================] - 3s 972us/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.0119 - val_accuracy: 0.9974\n",
      "Epoch 47/100\n",
      "2800/2800 [==============================] - 3s 976us/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.0130 - val_accuracy: 0.9973\n",
      "Epoch 48/100\n",
      "2800/2800 [==============================] - 3s 975us/step - loss: 0.0106 - accuracy: 0.9984 - val_loss: 0.0142 - val_accuracy: 0.9963\n",
      "Epoch 49/100\n",
      "2800/2800 [==============================] - 3s 975us/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.0106 - val_accuracy: 0.9982\n",
      "Epoch 50/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 0.0103 - val_accuracy: 0.9982\n",
      "Epoch 51/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.0110 - val_accuracy: 0.9976\n",
      "Epoch 52/100\n",
      "2800/2800 [==============================] - 3s 980us/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 0.0110 - val_accuracy: 0.9976\n",
      "Epoch 53/100\n",
      "2800/2800 [==============================] - 3s 970us/step - loss: 0.0097 - accuracy: 0.9984 - val_loss: 0.0099 - val_accuracy: 0.9981\n",
      "Epoch 54/100\n",
      "2800/2800 [==============================] - 3s 976us/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.0097 - val_accuracy: 0.9983\n",
      "Epoch 55/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.0109 - val_accuracy: 0.9974\n",
      "Epoch 56/100\n",
      "2800/2800 [==============================] - 3s 980us/step - loss: 0.0094 - accuracy: 0.9984 - val_loss: 0.0093 - val_accuracy: 0.9984\n",
      "Epoch 57/100\n",
      "2800/2800 [==============================] - 3s 978us/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.0095 - val_accuracy: 0.9982\n",
      "Epoch 58/100\n",
      "2800/2800 [==============================] - 3s 972us/step - loss: 0.0090 - accuracy: 0.9984 - val_loss: 0.0128 - val_accuracy: 0.9967\n",
      "Epoch 59/100\n",
      "2800/2800 [==============================] - 3s 985us/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.0092 - val_accuracy: 0.9981\n",
      "Epoch 60/100\n",
      "2800/2800 [==============================] - 3s 984us/step - loss: 0.0090 - accuracy: 0.9984 - val_loss: 0.0098 - val_accuracy: 0.9977\n",
      "Epoch 61/100\n",
      "2800/2800 [==============================] - 3s 986us/step - loss: 0.0087 - accuracy: 0.9984 - val_loss: 0.0092 - val_accuracy: 0.9977\n",
      "Epoch 62/100\n",
      "2800/2800 [==============================] - 3s 980us/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
      "Epoch 63/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0086 - val_accuracy: 0.9983\n",
      "Epoch 64/100\n",
      "2800/2800 [==============================] - 3s 990us/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
      "Epoch 65/100\n",
      "2800/2800 [==============================] - 3s 971us/step - loss: 0.0084 - accuracy: 0.9984 - val_loss: 0.0089 - val_accuracy: 0.9980\n",
      "Epoch 66/100\n",
      "2800/2800 [==============================] - 3s 981us/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 0.0092 - val_accuracy: 0.9980\n",
      "Epoch 67/100\n",
      "2800/2800 [==============================] - 3s 977us/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.0110 - val_accuracy: 0.9973\n",
      "Epoch 68/100\n",
      "2800/2800 [==============================] - 3s 978us/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.0082 - val_accuracy: 0.9983\n",
      "Epoch 69/100\n",
      "2800/2800 [==============================] - 3s 970us/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.0097 - val_accuracy: 0.9978\n",
      "Epoch 70/100\n",
      "2800/2800 [==============================] - 3s 975us/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.0096 - val_accuracy: 0.9975\n",
      "Epoch 71/100\n",
      "2800/2800 [==============================] - 3s 977us/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.0101 - val_accuracy: 0.9977\n",
      "Epoch 72/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.0076 - val_accuracy: 0.9984\n",
      "Epoch 73/100\n",
      "2800/2800 [==============================] - 3s 976us/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.0087 - val_accuracy: 0.9978\n",
      "Epoch 74/100\n",
      "2800/2800 [==============================] - 3s 980us/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.0079 - val_accuracy: 0.9984\n",
      "Epoch 75/100\n",
      "2800/2800 [==============================] - 3s 978us/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.0095 - val_accuracy: 0.9976\n",
      "Epoch 76/100\n",
      "2800/2800 [==============================] - 3s 975us/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.0081 - val_accuracy: 0.9981\n",
      "Epoch 77/100\n",
      "2800/2800 [==============================] - 3s 975us/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.0076 - val_accuracy: 0.9984\n",
      "Epoch 78/100\n",
      "2800/2800 [==============================] - 3s 976us/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.0074 - val_accuracy: 0.9985\n",
      "Epoch 79/100\n",
      "2800/2800 [==============================] - 3s 972us/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.0082 - val_accuracy: 0.9980\n",
      "Epoch 80/100\n",
      "2800/2800 [==============================] - 3s 975us/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0091 - val_accuracy: 0.9979\n",
      "Epoch 81/100\n",
      "2800/2800 [==============================] - 3s 971us/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.0081 - val_accuracy: 0.9978\n",
      "Epoch 82/100\n",
      "2800/2800 [==============================] - 3s 980us/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0074 - val_accuracy: 0.9984\n",
      "Epoch 83/100\n",
      "2800/2800 [==============================] - 3s 977us/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.0074 - val_accuracy: 0.9984\n",
      "Epoch 84/100\n",
      "2800/2800 [==============================] - 3s 974us/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.0084 - val_accuracy: 0.9979\n",
      "Epoch 85/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.0100 - val_accuracy: 0.9973\n",
      "Epoch 86/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0075 - val_accuracy: 0.9981\n",
      "Epoch 87/100\n",
      "2800/2800 [==============================] - 3s 976us/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0084 - val_accuracy: 0.9979\n",
      "Epoch 88/100\n",
      "2800/2800 [==============================] - 3s 983us/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0072 - val_accuracy: 0.9985\n",
      "Epoch 89/100\n",
      "2800/2800 [==============================] - 3s 977us/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0094 - val_accuracy: 0.9972\n",
      "Epoch 90/100\n",
      "2800/2800 [==============================] - 3s 977us/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0084 - val_accuracy: 0.9977\n",
      "Epoch 91/100\n",
      "2800/2800 [==============================] - 3s 971us/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0085 - val_accuracy: 0.9979\n",
      "Epoch 92/100\n",
      "2800/2800 [==============================] - 3s 972us/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0071 - val_accuracy: 0.9980\n",
      "Epoch 93/100\n",
      "2800/2800 [==============================] - 3s 977us/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0088 - val_accuracy: 0.9978\n",
      "Epoch 94/100\n",
      "2800/2800 [==============================] - 3s 983us/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0090 - val_accuracy: 0.9976\n",
      "Epoch 95/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0070 - val_accuracy: 0.9981\n",
      "Epoch 96/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0080 - val_accuracy: 0.9979\n",
      "Epoch 97/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0086 - val_accuracy: 0.9978\n",
      "Epoch 98/100\n",
      "2800/2800 [==============================] - 3s 984us/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0086 - val_accuracy: 0.9977\n",
      "Epoch 99/100\n",
      "2800/2800 [==============================] - 3s 977us/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 0.9983\n",
      "Epoch 100/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–‚â–â–‚â–ƒâ–„â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–â–â–â–‚â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.9987</td></tr><tr><td>batch/batch_step</td><td>279995</td></tr><tr><td>batch/learning_rate</td><td>0.00013</td></tr><tr><td>batch/loss</td><td>0.00624</td></tr><tr><td>epoch/accuracy</td><td>0.9987</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00013</td></tr><tr><td>epoch/loss</td><td>0.00623</td></tr><tr><td>epoch/val_accuracy</td><td>0.99815</td></tr><tr><td>epoch/val_loss</td><td>0.00667</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_22</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/8qyqpuoh' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/8qyqpuoh</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_040139-8qyqpuoh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 04:06:15,843] Trial 22 finished with value: 0.0066224354784935715 and parameters: {'Layer_1_units': 106, 'Activation_1': 'sigmoid', 'n_layers': 2, 'Layer_2_units': 86, 'Activation_2': 'sigmoid', 'Layer_3_units': 86, 'Activation_3': 'relu', 'learning_rate': 0.00013447986599514605, 'optimizer': 'rmsprop', 'batch_size': 50}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_040615-j136gwh2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/j136gwh2' target=\"_blank\">Trial_23</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/j136gwh2' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/j136gwh2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.1261 - accuracy: 0.9544 - val_loss: 0.0453 - val_accuracy: 0.9898\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0365 - accuracy: 0.9920 - val_loss: 0.0234 - val_accuracy: 0.9965\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0263 - accuracy: 0.9946 - val_loss: 0.0211 - val_accuracy: 0.9954\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0222 - accuracy: 0.9956 - val_loss: 0.0159 - val_accuracy: 0.9971\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0195 - accuracy: 0.9959 - val_loss: 0.0161 - val_accuracy: 0.9966\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0181 - accuracy: 0.9963 - val_loss: 0.0215 - val_accuracy: 0.9946\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0162 - accuracy: 0.9966 - val_loss: 0.0122 - val_accuracy: 0.9977\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.0157 - val_accuracy: 0.9962\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0158 - val_accuracy: 0.9962\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0139 - accuracy: 0.9968 - val_loss: 0.0107 - val_accuracy: 0.9977\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0130 - accuracy: 0.9971 - val_loss: 0.0128 - val_accuracy: 0.9965\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.0127 - val_accuracy: 0.9966\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.0099 - val_accuracy: 0.9975\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.0159 - val_accuracy: 0.9957\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.0120 - val_accuracy: 0.9970\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.0090 - val_accuracy: 0.9979\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.0083 - val_accuracy: 0.9980\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0105 - val_accuracy: 0.9970\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0098 - val_accuracy: 0.9976\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 0.0120 - val_accuracy: 0.9967\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.0071 - val_accuracy: 0.9982\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.0126 - val_accuracy: 0.9964\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 0.0119 - val_accuracy: 0.9966\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.0078 - val_accuracy: 0.9980\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.0075 - val_accuracy: 0.9984\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.0211 - val_accuracy: 0.9943\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0076 - val_accuracy: 0.9979\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0068 - val_accuracy: 0.9984\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0069 - val_accuracy: 0.9984\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0064 - val_accuracy: 0.9987\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0061 - val_accuracy: 0.9986\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0167 - val_accuracy: 0.9955\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0084 - val_accuracy: 0.9980\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0100 - val_accuracy: 0.9972\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0088 - val_accuracy: 0.9976\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0091 - val_accuracy: 0.9977\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0063 - val_accuracy: 0.9984\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0069 - val_accuracy: 0.9983\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0106 - val_accuracy: 0.9970\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0067 - val_accuracy: 0.9980\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.0053 - val_accuracy: 0.9988\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0050 - val_accuracy: 0.9988\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0078 - val_accuracy: 0.9981\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0055 - val_accuracy: 0.9989\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0136 - val_accuracy: 0.9964\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0083 - val_accuracy: 0.9974\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0165 - val_accuracy: 0.9952\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0117 - val_accuracy: 0.9967\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0076 - val_accuracy: 0.9977\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0056 - val_accuracy: 0.9986\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0051 - val_accuracy: 0.9986\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0085 - val_accuracy: 0.9976\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0050 - val_accuracy: 0.9990\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0174 - val_accuracy: 0.9952\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0078 - val_accuracy: 0.9977\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0084 - val_accuracy: 0.9977\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0077 - val_accuracy: 0.9977\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0072 - val_accuracy: 0.9978\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0106 - val_accuracy: 0.9966\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0065 - val_accuracy: 0.9982\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0111 - val_accuracy: 0.9970\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0044 - val_accuracy: 0.9990\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0067 - val_accuracy: 0.9979\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0047 - val_accuracy: 0.9986\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0090 - val_accuracy: 0.9973\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9989\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0066 - val_accuracy: 0.9982\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0040 - val_accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–‚â–ƒâ–„â–„â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–†â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‡â–…â–†â–‡â–†â–†â–†â–ˆâ–„â–ˆâ–ˆâ–ˆâ–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–†â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–…â–‡â–ˆâ–ˆâ–‡â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–„â–â–â–ƒâ–‚â–â–â–â–â–â–â–â–â–‚â–ƒâ–â–â–â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99912</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00155</td></tr><tr><td>batch/loss</td><td>0.00408</td></tr><tr><td>epoch/accuracy</td><td>0.99912</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00155</td></tr><tr><td>epoch/loss</td><td>0.00408</td></tr><tr><td>epoch/val_accuracy</td><td>0.99895</td></tr><tr><td>epoch/val_loss</td><td>0.00405</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_23</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/j136gwh2' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/j136gwh2</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_040615-j136gwh2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 04:18:46,448] Trial 23 finished with value: 0.004052261728793383 and parameters: {'Layer_1_units': 87, 'Activation_1': 'sigmoid', 'n_layers': 4, 'Layer_2_units': 106, 'Activation_2': 'sigmoid', 'Layer_3_units': 100, 'Activation_3': 'relu', 'Layer_4_units': 45, 'Activation_4': 'sigmoid', 'Layer_5_units': 92, 'Activation_5': 'sigmoid', 'learning_rate': 0.0015531386776573982, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_041846-pmdf7idh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/pmdf7idh' target=\"_blank\">Trial_24</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/pmdf7idh' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/pmdf7idh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.1327 - accuracy: 0.9542 - val_loss: 0.0827 - val_accuracy: 0.9754\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0362 - accuracy: 0.9927 - val_loss: 0.0215 - val_accuracy: 0.9972\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0248 - accuracy: 0.9952 - val_loss: 0.0330 - val_accuracy: 0.9909\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0199 - accuracy: 0.9960 - val_loss: 0.0218 - val_accuracy: 0.9952\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0169 - accuracy: 0.9966 - val_loss: 0.0164 - val_accuracy: 0.9969\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0151 - accuracy: 0.9971 - val_loss: 0.0130 - val_accuracy: 0.9966\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.0150 - val_accuracy: 0.9967\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0127 - accuracy: 0.9975 - val_loss: 0.0111 - val_accuracy: 0.9976\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0123 - accuracy: 0.9975 - val_loss: 0.0207 - val_accuracy: 0.9954\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0101 - val_accuracy: 0.9982\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0259 - val_accuracy: 0.9924\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0093 - accuracy: 0.9981 - val_loss: 0.0095 - val_accuracy: 0.9980\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.0074 - val_accuracy: 0.9985\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.0092 - val_accuracy: 0.9981\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.0081 - val_accuracy: 0.9981\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.0093 - val_accuracy: 0.9977\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.0083 - val_accuracy: 0.9983\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.0148 - val_accuracy: 0.9964\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.0083 - val_accuracy: 0.9984\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0112 - val_accuracy: 0.9979\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.0072 - val_accuracy: 0.9985\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0085 - val_accuracy: 0.9980\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0078 - val_accuracy: 0.9981\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0251 - val_accuracy: 0.9951\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0140 - val_accuracy: 0.9969\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0077 - val_accuracy: 0.9983\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0061 - val_accuracy: 0.9986\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0102 - val_accuracy: 0.9974\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0063 - val_accuracy: 0.9984\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0074 - val_accuracy: 0.9984\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0112 - val_accuracy: 0.9976\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0085 - val_accuracy: 0.9976\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0069 - val_accuracy: 0.9981\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.0084 - val_accuracy: 0.9976\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0072 - val_accuracy: 0.9981\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0088 - val_accuracy: 0.9980\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0060 - val_accuracy: 0.9981\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0066 - val_accuracy: 0.9980\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0063 - val_accuracy: 0.9984\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0074 - val_accuracy: 0.9983\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0055 - val_accuracy: 0.9986\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0042 - val_accuracy: 0.9990\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0058 - val_accuracy: 0.9980\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0070 - val_accuracy: 0.9982\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0048 - val_accuracy: 0.9986\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0085 - val_accuracy: 0.9979\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0063 - val_accuracy: 0.9982\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0077 - val_accuracy: 0.9980\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0048 - val_accuracy: 0.9986\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0074 - val_accuracy: 0.9977\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0134 - val_accuracy: 0.9967\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0063 - val_accuracy: 0.9984\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0060 - val_accuracy: 0.9981\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9985\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0058 - val_accuracy: 0.9982\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 0.9985\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0061 - val_accuracy: 0.9980\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0060 - val_accuracy: 0.9983\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0083 - val_accuracy: 0.9979\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0115 - val_accuracy: 0.9969\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0073 - val_accuracy: 0.9982\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0086 - val_accuracy: 0.9978\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0062 - val_accuracy: 0.9981\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0061 - val_accuracy: 0.9982\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0053 - val_accuracy: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–†â–†â–‡â–†â–…â–…â–‡â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–…â–‡</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–ƒâ–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–†â–„â–†â–…â–†â–„â–‡â–â–‡â–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–†â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–…â–ˆâ–ƒâ–„â–ƒâ–†â–‚â–‚â–‚â–ƒâ–‚â–†â–ƒâ–â–â–â–â–‚â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–‚â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99928</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00041</td></tr><tr><td>batch/loss</td><td>0.0033</td></tr><tr><td>epoch/accuracy</td><td>0.99928</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00041</td></tr><tr><td>epoch/loss</td><td>0.0033</td></tr><tr><td>epoch/val_accuracy</td><td>0.99855</td></tr><tr><td>epoch/val_loss</td><td>0.0053</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_24</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/pmdf7idh' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/pmdf7idh</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_041846-pmdf7idh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 04:33:09,892] Trial 24 finished with value: 0.0040705229854211215 and parameters: {'Layer_1_units': 67, 'Activation_1': 'sigmoid', 'n_layers': 7, 'Layer_2_units': 126, 'Activation_2': 'relu', 'Layer_3_units': 62, 'Activation_3': 'relu', 'Layer_4_units': 71, 'Activation_4': 'relu', 'Layer_5_units': 76, 'Activation_5': 'relu', 'Layer_6_units': 104, 'Activation_6': 'relu', 'Layer_7_units': 51, 'Activation_7': 'relu', 'Layer_8_units': 83, 'Activation_8': 'sigmoid', 'learning_rate': 0.0004059619598063131, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_043309-zamlmh7h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/zamlmh7h' target=\"_blank\">Trial_25</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/zamlmh7h' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/zamlmh7h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2800/2800 [==============================] - 4s 1ms/step - loss: 0.4568 - accuracy: 0.7832 - val_loss: 0.3371 - val_accuracy: 0.8521\n",
      "Epoch 2/100\n",
      "2800/2800 [==============================] - 3s 983us/step - loss: 0.2407 - accuracy: 0.9169 - val_loss: 0.1766 - val_accuracy: 0.9353\n",
      "Epoch 3/100\n",
      "2800/2800 [==============================] - 3s 899us/step - loss: 0.1587 - accuracy: 0.9404 - val_loss: 0.1472 - val_accuracy: 0.9413\n",
      "Epoch 4/100\n",
      "2800/2800 [==============================] - 3s 917us/step - loss: 0.1437 - accuracy: 0.9423 - val_loss: 0.1400 - val_accuracy: 0.9431\n",
      "Epoch 5/100\n",
      "2800/2800 [==============================] - 3s 915us/step - loss: 0.1391 - accuracy: 0.9431 - val_loss: 0.1375 - val_accuracy: 0.9431\n",
      "Epoch 6/100\n",
      "2800/2800 [==============================] - 3s 913us/step - loss: 0.1368 - accuracy: 0.9440 - val_loss: 0.1352 - val_accuracy: 0.9450\n",
      "Epoch 7/100\n",
      "2800/2800 [==============================] - 3s 895us/step - loss: 0.1349 - accuracy: 0.9448 - val_loss: 0.1330 - val_accuracy: 0.9448\n",
      "Epoch 8/100\n",
      "2800/2800 [==============================] - 3s 917us/step - loss: 0.1333 - accuracy: 0.9450 - val_loss: 0.1329 - val_accuracy: 0.9469\n",
      "Epoch 9/100\n",
      "2800/2800 [==============================] - 3s 979us/step - loss: 0.1318 - accuracy: 0.9463 - val_loss: 0.1305 - val_accuracy: 0.9475\n",
      "Epoch 10/100\n",
      "2800/2800 [==============================] - 3s 948us/step - loss: 0.1301 - accuracy: 0.9466 - val_loss: 0.1281 - val_accuracy: 0.9470\n",
      "Epoch 11/100\n",
      "2800/2800 [==============================] - 2s 885us/step - loss: 0.1280 - accuracy: 0.9476 - val_loss: 0.1270 - val_accuracy: 0.9493\n",
      "Epoch 12/100\n",
      "2800/2800 [==============================] - 3s 893us/step - loss: 0.1255 - accuracy: 0.9485 - val_loss: 0.1232 - val_accuracy: 0.9493\n",
      "Epoch 13/100\n",
      "2800/2800 [==============================] - 3s 967us/step - loss: 0.1222 - accuracy: 0.9503 - val_loss: 0.1198 - val_accuracy: 0.9521\n",
      "Epoch 14/100\n",
      "2800/2800 [==============================] - 3s 951us/step - loss: 0.1181 - accuracy: 0.9522 - val_loss: 0.1167 - val_accuracy: 0.9542\n",
      "Epoch 15/100\n",
      "2800/2800 [==============================] - 2s 887us/step - loss: 0.1132 - accuracy: 0.9551 - val_loss: 0.1106 - val_accuracy: 0.9567\n",
      "Epoch 16/100\n",
      "2800/2800 [==============================] - 3s 963us/step - loss: 0.1076 - accuracy: 0.9584 - val_loss: 0.1051 - val_accuracy: 0.9601\n",
      "Epoch 17/100\n",
      "2800/2800 [==============================] - 3s 928us/step - loss: 0.1016 - accuracy: 0.9624 - val_loss: 0.0993 - val_accuracy: 0.9644\n",
      "Epoch 18/100\n",
      "2800/2800 [==============================] - 3s 902us/step - loss: 0.0954 - accuracy: 0.9662 - val_loss: 0.0933 - val_accuracy: 0.9696\n",
      "Epoch 19/100\n",
      "2800/2800 [==============================] - 2s 891us/step - loss: 0.0895 - accuracy: 0.9698 - val_loss: 0.0880 - val_accuracy: 0.9725\n",
      "Epoch 20/100\n",
      "2800/2800 [==============================] - 3s 912us/step - loss: 0.0841 - accuracy: 0.9728 - val_loss: 0.0835 - val_accuracy: 0.9733\n",
      "Epoch 21/100\n",
      "2800/2800 [==============================] - 3s 988us/step - loss: 0.0791 - accuracy: 0.9752 - val_loss: 0.0786 - val_accuracy: 0.9761\n",
      "Epoch 22/100\n",
      "2800/2800 [==============================] - 3s 921us/step - loss: 0.0746 - accuracy: 0.9769 - val_loss: 0.0745 - val_accuracy: 0.9771\n",
      "Epoch 23/100\n",
      "2800/2800 [==============================] - 3s 894us/step - loss: 0.0706 - accuracy: 0.9785 - val_loss: 0.0704 - val_accuracy: 0.9786\n",
      "Epoch 24/100\n",
      "2800/2800 [==============================] - 3s 903us/step - loss: 0.0669 - accuracy: 0.9800 - val_loss: 0.0673 - val_accuracy: 0.9799\n",
      "Epoch 25/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0636 - accuracy: 0.9813 - val_loss: 0.0638 - val_accuracy: 0.9808\n",
      "Epoch 26/100\n",
      "2800/2800 [==============================] - 3s 916us/step - loss: 0.0604 - accuracy: 0.9825 - val_loss: 0.0606 - val_accuracy: 0.9825\n",
      "Epoch 27/100\n",
      "2800/2800 [==============================] - 3s 903us/step - loss: 0.0575 - accuracy: 0.9835 - val_loss: 0.0574 - val_accuracy: 0.9833\n",
      "Epoch 28/100\n",
      "2800/2800 [==============================] - 3s 923us/step - loss: 0.0547 - accuracy: 0.9847 - val_loss: 0.0545 - val_accuracy: 0.9847\n",
      "Epoch 29/100\n",
      "2800/2800 [==============================] - 3s 893us/step - loss: 0.0522 - accuracy: 0.9858 - val_loss: 0.0521 - val_accuracy: 0.9855\n",
      "Epoch 30/100\n",
      "2800/2800 [==============================] - 3s 907us/step - loss: 0.0498 - accuracy: 0.9865 - val_loss: 0.0502 - val_accuracy: 0.9859\n",
      "Epoch 31/100\n",
      "2800/2800 [==============================] - 2s 889us/step - loss: 0.0478 - accuracy: 0.9872 - val_loss: 0.0482 - val_accuracy: 0.9869\n",
      "Epoch 32/100\n",
      "2800/2800 [==============================] - 3s 961us/step - loss: 0.0459 - accuracy: 0.9878 - val_loss: 0.0469 - val_accuracy: 0.9859\n",
      "Epoch 33/100\n",
      "2800/2800 [==============================] - 3s 982us/step - loss: 0.0441 - accuracy: 0.9882 - val_loss: 0.0447 - val_accuracy: 0.9876\n",
      "Epoch 34/100\n",
      "2800/2800 [==============================] - 3s 895us/step - loss: 0.0423 - accuracy: 0.9886 - val_loss: 0.0427 - val_accuracy: 0.9886\n",
      "Epoch 35/100\n",
      "2800/2800 [==============================] - 3s 895us/step - loss: 0.0405 - accuracy: 0.9892 - val_loss: 0.0416 - val_accuracy: 0.9879\n",
      "Epoch 36/100\n",
      "2800/2800 [==============================] - 3s 930us/step - loss: 0.0388 - accuracy: 0.9897 - val_loss: 0.0395 - val_accuracy: 0.9889\n",
      "Epoch 37/100\n",
      "2800/2800 [==============================] - 3s 974us/step - loss: 0.0370 - accuracy: 0.9902 - val_loss: 0.0370 - val_accuracy: 0.9904\n",
      "Epoch 38/100\n",
      "2800/2800 [==============================] - 3s 948us/step - loss: 0.0353 - accuracy: 0.9909 - val_loss: 0.0354 - val_accuracy: 0.9905\n",
      "Epoch 39/100\n",
      "2800/2800 [==============================] - 2s 890us/step - loss: 0.0335 - accuracy: 0.9914 - val_loss: 0.0338 - val_accuracy: 0.9911\n",
      "Epoch 40/100\n",
      "2800/2800 [==============================] - 3s 950us/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 0.0318 - val_accuracy: 0.9916\n",
      "Epoch 41/100\n",
      "2800/2800 [==============================] - 3s 980us/step - loss: 0.0301 - accuracy: 0.9925 - val_loss: 0.0301 - val_accuracy: 0.9922\n",
      "Epoch 42/100\n",
      "2800/2800 [==============================] - 3s 910us/step - loss: 0.0284 - accuracy: 0.9928 - val_loss: 0.0285 - val_accuracy: 0.9926\n",
      "Epoch 43/100\n",
      "2800/2800 [==============================] - 3s 897us/step - loss: 0.0267 - accuracy: 0.9934 - val_loss: 0.0269 - val_accuracy: 0.9928\n",
      "Epoch 44/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0250 - accuracy: 0.9940 - val_loss: 0.0252 - val_accuracy: 0.9936\n",
      "Epoch 45/100\n",
      "2800/2800 [==============================] - 3s 951us/step - loss: 0.0234 - accuracy: 0.9948 - val_loss: 0.0235 - val_accuracy: 0.9944\n",
      "Epoch 46/100\n",
      "2800/2800 [==============================] - 3s 897us/step - loss: 0.0219 - accuracy: 0.9952 - val_loss: 0.0220 - val_accuracy: 0.9947\n",
      "Epoch 47/100\n",
      "2800/2800 [==============================] - 3s 898us/step - loss: 0.0204 - accuracy: 0.9957 - val_loss: 0.0207 - val_accuracy: 0.9948\n",
      "Epoch 48/100\n",
      "2800/2800 [==============================] - 3s 995us/step - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.0194 - val_accuracy: 0.9954\n",
      "Epoch 49/100\n",
      "2800/2800 [==============================] - 3s 930us/step - loss: 0.0179 - accuracy: 0.9967 - val_loss: 0.0183 - val_accuracy: 0.9959\n",
      "Epoch 50/100\n",
      "2800/2800 [==============================] - 3s 901us/step - loss: 0.0168 - accuracy: 0.9970 - val_loss: 0.0178 - val_accuracy: 0.9961\n",
      "Epoch 51/100\n",
      "2800/2800 [==============================] - 2s 891us/step - loss: 0.0159 - accuracy: 0.9974 - val_loss: 0.0164 - val_accuracy: 0.9974\n",
      "Epoch 52/100\n",
      "2800/2800 [==============================] - 3s 928us/step - loss: 0.0151 - accuracy: 0.9978 - val_loss: 0.0156 - val_accuracy: 0.9977\n",
      "Epoch 53/100\n",
      "2800/2800 [==============================] - 2s 890us/step - loss: 0.0144 - accuracy: 0.9980 - val_loss: 0.0150 - val_accuracy: 0.9976\n",
      "Epoch 54/100\n",
      "2800/2800 [==============================] - 3s 899us/step - loss: 0.0138 - accuracy: 0.9982 - val_loss: 0.0144 - val_accuracy: 0.9981\n",
      "Epoch 55/100\n",
      "2800/2800 [==============================] - 3s 900us/step - loss: 0.0133 - accuracy: 0.9982 - val_loss: 0.0142 - val_accuracy: 0.9976\n",
      "Epoch 56/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0128 - accuracy: 0.9984 - val_loss: 0.0136 - val_accuracy: 0.9981\n",
      "Epoch 57/100\n",
      "2800/2800 [==============================] - 3s 920us/step - loss: 0.0124 - accuracy: 0.9984 - val_loss: 0.0132 - val_accuracy: 0.9982\n",
      "Epoch 58/100\n",
      "2800/2800 [==============================] - 2s 891us/step - loss: 0.0121 - accuracy: 0.9986 - val_loss: 0.0131 - val_accuracy: 0.9980\n",
      "Epoch 59/100\n",
      "2800/2800 [==============================] - 3s 905us/step - loss: 0.0118 - accuracy: 0.9987 - val_loss: 0.0126 - val_accuracy: 0.9983\n",
      "Epoch 60/100\n",
      "2800/2800 [==============================] - 3s 985us/step - loss: 0.0115 - accuracy: 0.9987 - val_loss: 0.0121 - val_accuracy: 0.9984\n",
      "Epoch 61/100\n",
      "2800/2800 [==============================] - 3s 905us/step - loss: 0.0112 - accuracy: 0.9987 - val_loss: 0.0119 - val_accuracy: 0.9984\n",
      "Epoch 62/100\n",
      "2800/2800 [==============================] - 3s 898us/step - loss: 0.0109 - accuracy: 0.9987 - val_loss: 0.0117 - val_accuracy: 0.9984\n",
      "Epoch 63/100\n",
      "2800/2800 [==============================] - 3s 926us/step - loss: 0.0107 - accuracy: 0.9988 - val_loss: 0.0116 - val_accuracy: 0.9983\n",
      "Epoch 64/100\n",
      "2800/2800 [==============================] - 3s 955us/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.0114 - val_accuracy: 0.9982\n",
      "Epoch 65/100\n",
      "2800/2800 [==============================] - 3s 895us/step - loss: 0.0102 - accuracy: 0.9988 - val_loss: 0.0110 - val_accuracy: 0.9987\n",
      "Epoch 66/100\n",
      "2800/2800 [==============================] - 3s 899us/step - loss: 0.0100 - accuracy: 0.9989 - val_loss: 0.0109 - val_accuracy: 0.9985\n",
      "Epoch 67/100\n",
      "2800/2800 [==============================] - 3s 995us/step - loss: 0.0098 - accuracy: 0.9989 - val_loss: 0.0107 - val_accuracy: 0.9984\n",
      "Epoch 68/100\n",
      "2800/2800 [==============================] - 3s 982us/step - loss: 0.0096 - accuracy: 0.9989 - val_loss: 0.0104 - val_accuracy: 0.9984\n",
      "Epoch 69/100\n",
      "2800/2800 [==============================] - 3s 897us/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.0105 - val_accuracy: 0.9983\n",
      "Epoch 70/100\n",
      "2800/2800 [==============================] - 3s 939us/step - loss: 0.0093 - accuracy: 0.9989 - val_loss: 0.0102 - val_accuracy: 0.9985\n",
      "Epoch 71/100\n",
      "2800/2800 [==============================] - 3s 967us/step - loss: 0.0091 - accuracy: 0.9988 - val_loss: 0.0098 - val_accuracy: 0.9986\n",
      "Epoch 72/100\n",
      "2800/2800 [==============================] - 3s 960us/step - loss: 0.0089 - accuracy: 0.9989 - val_loss: 0.0097 - val_accuracy: 0.9986\n",
      "Epoch 73/100\n",
      "2800/2800 [==============================] - 3s 966us/step - loss: 0.0087 - accuracy: 0.9990 - val_loss: 0.0098 - val_accuracy: 0.9984\n",
      "Epoch 74/100\n",
      "2800/2800 [==============================] - 3s 896us/step - loss: 0.0086 - accuracy: 0.9990 - val_loss: 0.0094 - val_accuracy: 0.9987\n",
      "Epoch 75/100\n",
      "2800/2800 [==============================] - 3s 933us/step - loss: 0.0084 - accuracy: 0.9990 - val_loss: 0.0095 - val_accuracy: 0.9985\n",
      "Epoch 76/100\n",
      "2800/2800 [==============================] - 2s 887us/step - loss: 0.0083 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9987\n",
      "Epoch 77/100\n",
      "2800/2800 [==============================] - 3s 945us/step - loss: 0.0082 - accuracy: 0.9990 - val_loss: 0.0090 - val_accuracy: 0.9987\n",
      "Epoch 78/100\n",
      "2800/2800 [==============================] - 2s 892us/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 0.0089 - val_accuracy: 0.9987\n",
      "Epoch 79/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0079 - accuracy: 0.9990 - val_loss: 0.0088 - val_accuracy: 0.9987\n",
      "Epoch 80/100\n",
      "2800/2800 [==============================] - 3s 934us/step - loss: 0.0078 - accuracy: 0.9991 - val_loss: 0.0087 - val_accuracy: 0.9985\n",
      "Epoch 81/100\n",
      "2800/2800 [==============================] - 3s 903us/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.0085 - val_accuracy: 0.9986\n",
      "Epoch 82/100\n",
      "2800/2800 [==============================] - 2s 889us/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 0.0087 - val_accuracy: 0.9985\n",
      "Epoch 83/100\n",
      "2800/2800 [==============================] - 3s 995us/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 0.0082 - val_accuracy: 0.9988\n",
      "Epoch 84/100\n",
      "2800/2800 [==============================] - 3s 926us/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.0082 - val_accuracy: 0.9987\n",
      "Epoch 85/100\n",
      "2800/2800 [==============================] - 3s 899us/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.0081 - val_accuracy: 0.9988\n",
      "Epoch 86/100\n",
      "2800/2800 [==============================] - 2s 887us/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 0.0079 - val_accuracy: 0.9989\n",
      "Epoch 87/100\n",
      "2800/2800 [==============================] - 3s 928us/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.0079 - val_accuracy: 0.9987\n",
      "Epoch 88/100\n",
      "2800/2800 [==============================] - 3s 892us/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 0.0079 - val_accuracy: 0.9988\n",
      "Epoch 89/100\n",
      "2800/2800 [==============================] - 3s 900us/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 0.0077 - val_accuracy: 0.9988\n",
      "Epoch 90/100\n",
      "2800/2800 [==============================] - 3s 896us/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.0076 - val_accuracy: 0.9988\n",
      "Epoch 91/100\n",
      "2800/2800 [==============================] - 3s 994us/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.0075 - val_accuracy: 0.9990\n",
      "Epoch 92/100\n",
      "2800/2800 [==============================] - 3s 896us/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.0077 - val_accuracy: 0.9987\n",
      "Epoch 93/100\n",
      "2800/2800 [==============================] - 3s 896us/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.0074 - val_accuracy: 0.9987\n",
      "Epoch 94/100\n",
      "2800/2800 [==============================] - 3s 903us/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.0074 - val_accuracy: 0.9987\n",
      "Epoch 95/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.0073 - val_accuracy: 0.9987\n",
      "Epoch 96/100\n",
      "2800/2800 [==============================] - 3s 904us/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.0072 - val_accuracy: 0.9988\n",
      "Epoch 97/100\n",
      "2800/2800 [==============================] - 2s 892us/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
      "Epoch 98/100\n",
      "2800/2800 [==============================] - 3s 911us/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
      "Epoch 99/100\n",
      "2800/2800 [==============================] - 3s 944us/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 0.9986\n",
      "Epoch 100/100\n",
      "2800/2800 [==============================] - 2s 888us/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.0068 - val_accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99917</td></tr><tr><td>batch/batch_step</td><td>279995</td></tr><tr><td>batch/learning_rate</td><td>4e-05</td></tr><tr><td>batch/loss</td><td>0.00602</td></tr><tr><td>epoch/accuracy</td><td>0.99917</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>4e-05</td></tr><tr><td>epoch/loss</td><td>0.00602</td></tr><tr><td>epoch/val_accuracy</td><td>0.99885</td></tr><tr><td>epoch/val_loss</td><td>0.0068</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_25</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/zamlmh7h' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/zamlmh7h</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_043309-zamlmh7h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 04:37:32,330] Trial 25 finished with value: 0.006717939535155893 and parameters: {'Layer_1_units': 83, 'Activation_1': 'sigmoid', 'n_layers': 1, 'Layer_2_units': 115, 'Activation_2': 'relu', 'learning_rate': 3.662816484440652e-05, 'optimizer': 'rmsprop', 'batch_size': 50}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_043732-93hda6pj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/93hda6pj' target=\"_blank\">Trial_26</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/93hda6pj' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/93hda6pj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.2553 - accuracy: 0.8981 - val_loss: 0.1673 - val_accuracy: 0.9384\n",
      "Epoch 2/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1588 - accuracy: 0.9413 - val_loss: 0.1495 - val_accuracy: 0.9451\n",
      "Epoch 3/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1388 - accuracy: 0.9503 - val_loss: 0.1258 - val_accuracy: 0.9566\n",
      "Epoch 4/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.1121 - accuracy: 0.9625 - val_loss: 0.1001 - val_accuracy: 0.9690\n",
      "Epoch 5/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0844 - accuracy: 0.9762 - val_loss: 0.0753 - val_accuracy: 0.9804\n",
      "Epoch 6/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0639 - accuracy: 0.9843 - val_loss: 0.0621 - val_accuracy: 0.9851\n",
      "Epoch 7/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0498 - accuracy: 0.9899 - val_loss: 0.0484 - val_accuracy: 0.9903\n",
      "Epoch 8/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0406 - accuracy: 0.9932 - val_loss: 0.0491 - val_accuracy: 0.9894\n",
      "Epoch 9/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0350 - accuracy: 0.9950 - val_loss: 0.0368 - val_accuracy: 0.9940\n",
      "Epoch 10/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0316 - accuracy: 0.9961 - val_loss: 0.0353 - val_accuracy: 0.9947\n",
      "Epoch 11/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0290 - accuracy: 0.9968 - val_loss: 0.0317 - val_accuracy: 0.9949\n",
      "Epoch 12/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0268 - accuracy: 0.9972 - val_loss: 0.0311 - val_accuracy: 0.9956\n",
      "Epoch 13/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0253 - accuracy: 0.9975 - val_loss: 0.0273 - val_accuracy: 0.9963\n",
      "Epoch 14/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0235 - accuracy: 0.9979 - val_loss: 0.0257 - val_accuracy: 0.9966\n",
      "Epoch 15/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0220 - accuracy: 0.9981 - val_loss: 0.0285 - val_accuracy: 0.9952\n",
      "Epoch 16/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0210 - accuracy: 0.9981 - val_loss: 0.0227 - val_accuracy: 0.9969\n",
      "Epoch 17/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0198 - accuracy: 0.9982 - val_loss: 0.0223 - val_accuracy: 0.9968\n",
      "Epoch 18/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0186 - accuracy: 0.9984 - val_loss: 0.0209 - val_accuracy: 0.9974\n",
      "Epoch 19/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0177 - accuracy: 0.9984 - val_loss: 0.0203 - val_accuracy: 0.9969\n",
      "Epoch 20/100\n",
      "3500/3500 [==============================] - 5s 1ms/step - loss: 0.0168 - accuracy: 0.9986 - val_loss: 0.0208 - val_accuracy: 0.9969\n",
      "Epoch 21/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0160 - accuracy: 0.9987 - val_loss: 0.0196 - val_accuracy: 0.9973\n",
      "Epoch 22/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0153 - accuracy: 0.9987 - val_loss: 0.0186 - val_accuracy: 0.9971\n",
      "Epoch 23/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0146 - accuracy: 0.9989 - val_loss: 0.0231 - val_accuracy: 0.9962\n",
      "Epoch 24/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0138 - accuracy: 0.9989 - val_loss: 0.0193 - val_accuracy: 0.9970\n",
      "Epoch 25/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0133 - accuracy: 0.9989 - val_loss: 0.0164 - val_accuracy: 0.9976\n",
      "Epoch 26/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0129 - accuracy: 0.9990 - val_loss: 0.0163 - val_accuracy: 0.9975\n",
      "Epoch 27/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0122 - accuracy: 0.9990 - val_loss: 0.0154 - val_accuracy: 0.9977\n",
      "Epoch 28/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0119 - accuracy: 0.9991 - val_loss: 0.0169 - val_accuracy: 0.9967\n",
      "Epoch 29/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0113 - accuracy: 0.9990 - val_loss: 0.0145 - val_accuracy: 0.9979\n",
      "Epoch 30/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0109 - accuracy: 0.9991 - val_loss: 0.0145 - val_accuracy: 0.9977\n",
      "Epoch 31/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0104 - accuracy: 0.9991 - val_loss: 0.0151 - val_accuracy: 0.9973\n",
      "Epoch 32/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 0.0151 - val_accuracy: 0.9976\n",
      "Epoch 33/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0099 - accuracy: 0.9991 - val_loss: 0.0139 - val_accuracy: 0.9977\n",
      "Epoch 34/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.0149 - val_accuracy: 0.9973\n",
      "Epoch 35/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0092 - accuracy: 0.9992 - val_loss: 0.0136 - val_accuracy: 0.9974\n",
      "Epoch 36/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0088 - accuracy: 0.9992 - val_loss: 0.0123 - val_accuracy: 0.9976\n",
      "Epoch 37/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0086 - accuracy: 0.9992 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
      "Epoch 38/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0082 - accuracy: 0.9993 - val_loss: 0.0171 - val_accuracy: 0.9967\n",
      "Epoch 39/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0080 - accuracy: 0.9993 - val_loss: 0.0127 - val_accuracy: 0.9975\n",
      "Epoch 40/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0110 - val_accuracy: 0.9980\n",
      "Epoch 41/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.0113 - val_accuracy: 0.9975\n",
      "Epoch 42/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0107 - val_accuracy: 0.9980\n",
      "Epoch 43/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.0126 - val_accuracy: 0.9973\n",
      "Epoch 44/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.0165 - val_accuracy: 0.9966\n",
      "Epoch 45/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.0114 - val_accuracy: 0.9975\n",
      "Epoch 46/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.0120 - val_accuracy: 0.9976\n",
      "Epoch 47/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.0115 - val_accuracy: 0.9973\n",
      "Epoch 48/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 0.0104 - val_accuracy: 0.9980\n",
      "Epoch 49/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.0099 - val_accuracy: 0.9977\n",
      "Epoch 50/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.0129 - val_accuracy: 0.9973\n",
      "Epoch 51/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.0098 - val_accuracy: 0.9977\n",
      "Epoch 52/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 0.0122 - val_accuracy: 0.9973\n",
      "Epoch 53/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.0116 - val_accuracy: 0.9977\n",
      "Epoch 54/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.0094 - val_accuracy: 0.9977\n",
      "Epoch 55/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.0094 - val_accuracy: 0.9977\n",
      "Epoch 56/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.0094 - val_accuracy: 0.9980\n",
      "Epoch 57/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.0108 - val_accuracy: 0.9973\n",
      "Epoch 58/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.0093 - val_accuracy: 0.9978\n",
      "Epoch 59/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.0133 - val_accuracy: 0.9968\n",
      "Epoch 60/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.0088 - val_accuracy: 0.9980\n",
      "Epoch 61/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.0087 - val_accuracy: 0.9981\n",
      "Epoch 62/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.0123 - val_accuracy: 0.9972\n",
      "Epoch 63/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.0095 - val_accuracy: 0.9978\n",
      "Epoch 64/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.0095 - val_accuracy: 0.9980\n",
      "Epoch 65/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.0097 - val_accuracy: 0.9977\n",
      "Epoch 66/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0128 - val_accuracy: 0.9967\n",
      "Epoch 67/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.0140 - val_accuracy: 0.9966\n",
      "Epoch 68/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.0100 - val_accuracy: 0.9975\n",
      "Epoch 69/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0102 - val_accuracy: 0.9976\n",
      "Epoch 70/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0130 - val_accuracy: 0.9967\n",
      "Epoch 71/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.0089 - val_accuracy: 0.9979\n",
      "Epoch 72/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.0149 - val_accuracy: 0.9965\n",
      "Epoch 73/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.0082 - val_accuracy: 0.9980\n",
      "Epoch 74/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.0100 - val_accuracy: 0.9974\n",
      "Epoch 75/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.0081 - val_accuracy: 0.9980\n",
      "Epoch 76/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.0087 - val_accuracy: 0.9979\n",
      "Epoch 77/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.0137 - val_accuracy: 0.9967\n",
      "Epoch 78/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.0154 - val_accuracy: 0.9966\n",
      "Epoch 79/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.0122 - val_accuracy: 0.9969\n",
      "Epoch 80/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.0085 - val_accuracy: 0.9977\n",
      "Epoch 81/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.0080 - val_accuracy: 0.9980\n",
      "Epoch 82/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0087 - val_accuracy: 0.9979\n",
      "Epoch 83/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0088 - val_accuracy: 0.9977\n",
      "Epoch 84/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.0105 - val_accuracy: 0.9972\n",
      "Epoch 85/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0082 - val_accuracy: 0.9980\n",
      "Epoch 86/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0088 - val_accuracy: 0.9979\n",
      "Epoch 87/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0103 - val_accuracy: 0.9974\n",
      "Epoch 88/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0076 - val_accuracy: 0.9983\n",
      "Epoch 89/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0086 - val_accuracy: 0.9979\n",
      "Epoch 90/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0108 - val_accuracy: 0.9973\n",
      "Epoch 91/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0081 - val_accuracy: 0.9981\n",
      "Epoch 92/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0090 - val_accuracy: 0.9977\n",
      "Epoch 93/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0081 - val_accuracy: 0.9976\n",
      "Epoch 94/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0079 - val_accuracy: 0.9980\n",
      "Epoch 95/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0152 - val_accuracy: 0.9965\n",
      "Epoch 96/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0124 - val_accuracy: 0.9970\n",
      "Epoch 97/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0085 - val_accuracy: 0.9977\n",
      "Epoch 98/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
      "Epoch 99/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0092 - val_accuracy: 0.9975\n",
      "Epoch 100/100\n",
      "3500/3500 [==============================] - 4s 1ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0086 - val_accuracy: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ƒâ–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ˆâ–„â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–…â–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‡â–†â–…â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99963</td></tr><tr><td>batch/batch_step</td><td>349995</td></tr><tr><td>batch/learning_rate</td><td>8e-05</td></tr><tr><td>batch/loss</td><td>0.00297</td></tr><tr><td>epoch/accuracy</td><td>0.99963</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>8e-05</td></tr><tr><td>epoch/loss</td><td>0.00297</td></tr><tr><td>epoch/val_accuracy</td><td>0.9978</td></tr><tr><td>epoch/val_loss</td><td>0.00863</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_26</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/93hda6pj' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/93hda6pj</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_043732-93hda6pj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 04:44:34,733] Trial 26 finished with value: 0.007150525646284223 and parameters: {'Layer_1_units': 96, 'Activation_1': 'relu', 'n_layers': 5, 'Layer_2_units': 99, 'Activation_2': 'sigmoid', 'Layer_3_units': 110, 'Activation_3': 'relu', 'Layer_4_units': 111, 'Activation_4': 'relu', 'Layer_5_units': 45, 'Activation_5': 'relu', 'Layer_6_units': 32, 'Activation_6': 'relu', 'learning_rate': 8.169906126654005e-05, 'optimizer': 'rmsprop', 'batch_size': 40}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_044434-e9l1tw6u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/e9l1tw6u' target=\"_blank\">Trial_27</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/e9l1tw6u' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/e9l1tw6u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0857 - accuracy: 0.9660 - val_loss: 0.0231 - val_accuracy: 0.9928\n",
      "Epoch 2/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0140 - val_accuracy: 0.9955\n",
      "Epoch 3/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.0095 - val_accuracy: 0.9973\n",
      "Epoch 4/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.0094 - val_accuracy: 0.9967\n",
      "Epoch 5/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0112 - val_accuracy: 0.9963\n",
      "Epoch 6/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0072 - val_accuracy: 0.9979\n",
      "Epoch 7/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0100 - val_accuracy: 0.9970\n",
      "Epoch 8/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0136 - val_accuracy: 0.9952\n",
      "Epoch 9/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0090 - val_accuracy: 0.9969\n",
      "Epoch 10/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0060 - val_accuracy: 0.9979\n",
      "Epoch 11/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0078 - val_accuracy: 0.9970\n",
      "Epoch 12/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0116 - val_accuracy: 0.9963\n",
      "Epoch 13/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0059 - val_accuracy: 0.9980\n",
      "Epoch 14/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0057 - val_accuracy: 0.9979\n",
      "Epoch 15/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0062 - val_accuracy: 0.9979\n",
      "Epoch 16/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0065 - val_accuracy: 0.9981\n",
      "Epoch 17/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0082 - val_accuracy: 0.9974\n",
      "Epoch 18/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0098 - val_accuracy: 0.9968\n",
      "Epoch 19/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0137 - val_accuracy: 0.9963\n",
      "Epoch 20/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9980\n",
      "Epoch 21/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0051 - val_accuracy: 0.9983\n",
      "Epoch 22/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0083 - val_accuracy: 0.9977\n",
      "Epoch 23/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0059 - val_accuracy: 0.9981\n",
      "Epoch 24/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0094 - val_accuracy: 0.9971\n",
      "Epoch 25/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0061 - val_accuracy: 0.9981\n",
      "Epoch 26/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0113 - val_accuracy: 0.9977\n",
      "Epoch 27/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0145 - val_accuracy: 0.9971\n",
      "Epoch 28/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0126 - val_accuracy: 0.9978\n",
      "Epoch 29/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0075 - val_accuracy: 0.9977\n",
      "Epoch 30/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0084 - val_accuracy: 0.9977\n",
      "Epoch 31/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0115 - val_accuracy: 0.9969\n",
      "Epoch 32/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0123 - val_accuracy: 0.9972\n",
      "Epoch 33/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0095 - val_accuracy: 0.9979\n",
      "Epoch 34/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0115 - val_accuracy: 0.9977\n",
      "Epoch 35/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0097 - val_accuracy: 0.9975\n",
      "Epoch 36/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0126 - val_accuracy: 0.9977\n",
      "Epoch 37/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0151 - val_accuracy: 0.9973\n",
      "Epoch 38/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0091 - val_accuracy: 0.9976\n",
      "Epoch 39/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0147 - val_accuracy: 0.9974\n",
      "Epoch 40/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0154 - val_accuracy: 0.9970\n",
      "Epoch 41/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0133 - val_accuracy: 0.9966\n",
      "Epoch 42/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0083 - val_accuracy: 0.9980\n",
      "Epoch 43/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0192 - val_accuracy: 0.9969\n",
      "Epoch 44/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0088 - val_accuracy: 0.9981\n",
      "Epoch 45/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0183 - val_accuracy: 0.9966\n",
      "Epoch 46/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 47/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0096 - val_accuracy: 0.9974\n",
      "Epoch 48/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0192 - val_accuracy: 0.9969\n",
      "Epoch 49/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0068 - val_accuracy: 0.9981\n",
      "Epoch 50/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0092 - val_accuracy: 0.9978\n",
      "Epoch 51/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0115 - val_accuracy: 0.9973\n",
      "Epoch 52/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0099 - val_accuracy: 0.9978\n",
      "Epoch 53/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0105 - val_accuracy: 0.9979\n",
      "Epoch 54/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0116 - val_accuracy: 0.9976\n",
      "Epoch 55/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0174 - val_accuracy: 0.9972\n",
      "Epoch 56/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0082 - val_accuracy: 0.9980\n",
      "Epoch 57/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0088 - val_accuracy: 0.9980\n",
      "Epoch 58/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0093 - val_accuracy: 0.9980\n",
      "Epoch 59/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0133 - val_accuracy: 0.9977\n",
      "Epoch 60/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0120 - val_accuracy: 0.9977\n",
      "Epoch 61/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 62/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0096 - val_accuracy: 0.9979\n",
      "Epoch 63/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0087 - val_accuracy: 0.9977\n",
      "Epoch 64/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0179 - val_accuracy: 0.9969\n",
      "Epoch 65/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0189 - val_accuracy: 0.9968\n",
      "Epoch 66/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0078 - val_accuracy: 0.9980\n",
      "Epoch 67/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0088 - val_accuracy: 0.9980\n",
      "Epoch 68/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0081 - val_accuracy: 0.9978\n",
      "Epoch 69/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0208 - val_accuracy: 0.9965\n",
      "Epoch 70/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0183 - val_accuracy: 0.9966\n",
      "Epoch 71/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0077 - val_accuracy: 0.9980\n",
      "Epoch 72/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0083 - val_accuracy: 0.9980\n",
      "Epoch 73/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0077 - val_accuracy: 0.9981\n",
      "Epoch 74/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0102 - val_accuracy: 0.9979\n",
      "Epoch 75/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0150 - val_accuracy: 0.9970\n",
      "Epoch 76/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0122 - val_accuracy: 0.9974\n",
      "Epoch 77/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0091 - val_accuracy: 0.9980\n",
      "Epoch 78/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0141 - val_accuracy: 0.9973\n",
      "Epoch 79/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0084 - val_accuracy: 0.9980\n",
      "Epoch 80/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0139 - val_accuracy: 0.9973\n",
      "Epoch 81/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0084 - val_accuracy: 0.9981\n",
      "Epoch 82/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0128 - val_accuracy: 0.9975\n",
      "Epoch 83/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0091 - val_accuracy: 0.9980\n",
      "Epoch 84/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0104 - val_accuracy: 0.9976\n",
      "Epoch 85/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0103 - val_accuracy: 0.9981\n",
      "Epoch 86/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0124 - val_accuracy: 0.9976\n",
      "Epoch 87/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0109 - val_accuracy: 0.9980\n",
      "Epoch 88/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0211 - val_accuracy: 0.9969\n",
      "Epoch 89/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0092 - val_accuracy: 0.9981\n",
      "Epoch 90/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0092 - val_accuracy: 0.9981\n",
      "Epoch 91/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0131 - val_accuracy: 0.9977\n",
      "Epoch 92/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0092 - val_accuracy: 0.9983\n",
      "Epoch 93/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0101 - val_accuracy: 0.9980\n",
      "Epoch 94/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0203 - val_accuracy: 0.9966\n",
      "Epoch 95/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0092 - val_accuracy: 0.9981\n",
      "Epoch 96/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0123 - val_accuracy: 0.9975\n",
      "Epoch 97/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0121 - val_accuracy: 0.9978\n",
      "Epoch 98/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0142 - val_accuracy: 0.9974\n",
      "Epoch 99/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0083 - val_accuracy: 0.9980\n",
      "Epoch 100/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0087 - val_accuracy: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ƒâ–ƒâ–…â–…â–†â–…â–‡â–‡â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–†â–‡â–„â–†â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–‚â–‚â–â–‚</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–„â–‡â–†â–‡â–‡â–ˆâ–‡â–†â–…â–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–ˆâ–‡â–ˆâ–†â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–†â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–„â–ƒâ–‚â–ƒâ–â–â–ƒâ–â–ƒâ–‚â–„â–…â–„â–‚â–†â–‚â–ƒâ–ƒâ–†â–‚â–‚â–‚â–†â–‚â–‡â–‚â–‚â–„â–„â–ƒâ–ƒâ–‡â–‚â–„â–ƒâ–‡â–„â–„â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99953</td></tr><tr><td>batch/batch_step</td><td>139995</td></tr><tr><td>batch/learning_rate</td><td>0.00379</td></tr><tr><td>batch/loss</td><td>0.00174</td></tr><tr><td>epoch/accuracy</td><td>0.99954</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00379</td></tr><tr><td>epoch/loss</td><td>0.00174</td></tr><tr><td>epoch/val_accuracy</td><td>0.9984</td></tr><tr><td>epoch/val_loss</td><td>0.00867</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_27</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/e9l1tw6u' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/e9l1tw6u</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_044434-e9l1tw6u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 04:47:09,416] Trial 27 finished with value: 0.004741540236864239 and parameters: {'Layer_1_units': 110, 'Activation_1': 'sigmoid', 'n_layers': 2, 'Layer_2_units': 85, 'Activation_2': 'relu', 'Layer_3_units': 76, 'Activation_3': 'relu', 'learning_rate': 0.0037932200946693396, 'optimizer': 'rmsprop', 'batch_size': 100}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_044709-645okj2a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/645okj2a' target=\"_blank\">Trial_28</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/645okj2a' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/645okj2a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.1492 - accuracy: 0.9434 - val_loss: 0.0894 - val_accuracy: 0.9704\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0592 - accuracy: 0.9833 - val_loss: 0.0467 - val_accuracy: 0.9869\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0321 - accuracy: 0.9935 - val_loss: 0.0232 - val_accuracy: 0.9958\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0216 - accuracy: 0.9965 - val_loss: 0.0206 - val_accuracy: 0.9963\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0190 - accuracy: 0.9968 - val_loss: 0.0168 - val_accuracy: 0.9971\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0165 - accuracy: 0.9972 - val_loss: 0.0143 - val_accuracy: 0.9980\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0151 - accuracy: 0.9973 - val_loss: 0.0197 - val_accuracy: 0.9944\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.0239 - val_accuracy: 0.9924\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0127 - accuracy: 0.9977 - val_loss: 0.0140 - val_accuracy: 0.9964\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0117 - accuracy: 0.9979 - val_loss: 0.0125 - val_accuracy: 0.9974\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: 0.0107 - val_accuracy: 0.9979\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 0.0151 - val_accuracy: 0.9959\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.0096 - val_accuracy: 0.9981\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0089 - accuracy: 0.9984 - val_loss: 0.0109 - val_accuracy: 0.9972\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0088 - val_accuracy: 0.9983\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.0103 - val_accuracy: 0.9969\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0082 - val_accuracy: 0.9985\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.0083 - val_accuracy: 0.9979\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.0080 - val_accuracy: 0.9983\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0106 - val_accuracy: 0.9975\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.0080 - val_accuracy: 0.9982\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.0076 - val_accuracy: 0.9980\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 0.0079 - val_accuracy: 0.9984\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.0076 - val_accuracy: 0.9987\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0080 - val_accuracy: 0.9980\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.0071 - val_accuracy: 0.9983\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.0093 - val_accuracy: 0.9973\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.0104 - val_accuracy: 0.9972\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.0082 - val_accuracy: 0.9977\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.0074 - val_accuracy: 0.9983\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.0076 - val_accuracy: 0.9982\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.0066 - val_accuracy: 0.9983\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0089 - val_accuracy: 0.9977\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0041 - accuracy: 0.9997 - val_loss: 0.0079 - val_accuracy: 0.9978\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 0.0082 - val_accuracy: 0.9977\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.0071 - val_accuracy: 0.9982\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.0133 - val_accuracy: 0.9967\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.0063 - val_accuracy: 0.9984\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9982\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.0074 - val_accuracy: 0.9980\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.0064 - val_accuracy: 0.9981\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0061 - val_accuracy: 0.9983\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0067 - val_accuracy: 0.9977\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0070 - val_accuracy: 0.9974\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.0064 - val_accuracy: 0.9977\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0060 - val_accuracy: 0.9982\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0061 - val_accuracy: 0.9981\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0065 - val_accuracy: 0.9981\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0065 - val_accuracy: 0.9980\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0082 - val_accuracy: 0.9973\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0061 - val_accuracy: 0.9981\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0064 - val_accuracy: 0.9978\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0067 - val_accuracy: 0.9977\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0064 - val_accuracy: 0.9979\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0084 - val_accuracy: 0.9972\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0088 - val_accuracy: 0.9973\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9980\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0059 - val_accuracy: 0.9978\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9979\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0059 - val_accuracy: 0.9979\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0065 - val_accuracy: 0.9978\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9981\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0077 - val_accuracy: 0.9973\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9979\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0061 - val_accuracy: 0.9977\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0055 - val_accuracy: 0.9979\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9977\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9978\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9982\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9980\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9981\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9977\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9979\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9980\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9980\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9982\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9980\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9980\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9983\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9973\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9981\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9980\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9976\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9980\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9985\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9982\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9980\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9984\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9984\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9973\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–„â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‡â–…â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‡â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99998</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00061</td></tr><tr><td>batch/loss</td><td>0.00134</td></tr><tr><td>epoch/accuracy</td><td>0.99998</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00061</td></tr><tr><td>epoch/loss</td><td>0.00134</td></tr><tr><td>epoch/val_accuracy</td><td>0.99815</td></tr><tr><td>epoch/val_loss</td><td>0.00505</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_28</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/645okj2a' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/645okj2a</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_044709-645okj2a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 04:59:10,235] Trial 28 finished with value: 0.004207076213788241 and parameters: {'Layer_1_units': 121, 'Activation_1': 'sigmoid', 'n_layers': 3, 'Layer_2_units': 68, 'Activation_2': 'sigmoid', 'Layer_3_units': 121, 'Activation_3': 'relu', 'Layer_4_units': 53, 'Activation_4': 'sigmoid', 'learning_rate': 0.000609869400034101, 'optimizer': 'adam', 'batch_size': 20}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_045910-oi648zo4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/oi648zo4' target=\"_blank\">Trial_29</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/oi648zo4' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/oi648zo4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1400/1400 [==============================] - 3s 2ms/step - loss: 0.6250 - accuracy: 0.7692 - val_loss: 0.6105 - val_accuracy: 0.7689\n",
      "Epoch 2/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.6035 - accuracy: 0.7692 - val_loss: 0.5991 - val_accuracy: 0.7689\n",
      "Epoch 3/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5964 - accuracy: 0.7692 - val_loss: 0.5951 - val_accuracy: 0.7689\n",
      "Epoch 4/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5939 - accuracy: 0.7692 - val_loss: 0.5936 - val_accuracy: 0.7689\n",
      "Epoch 5/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5929 - accuracy: 0.7692 - val_loss: 0.5930 - val_accuracy: 0.7689\n",
      "Epoch 6/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5925 - accuracy: 0.7692 - val_loss: 0.5928 - val_accuracy: 0.7689\n",
      "Epoch 7/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5924 - accuracy: 0.7692 - val_loss: 0.5927 - val_accuracy: 0.7689\n",
      "Epoch 8/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5927 - val_accuracy: 0.7689\n",
      "Epoch 9/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5927 - val_accuracy: 0.7689\n",
      "Epoch 10/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 11/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 12/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 13/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 14/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 15/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 16/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 17/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 18/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 19/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 20/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 21/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 22/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 23/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 24/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 25/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 26/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 27/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 28/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 29/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 30/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 31/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 32/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 33/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 34/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 35/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 36/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 37/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 38/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 39/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 40/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 41/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 42/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 43/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 44/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 45/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 46/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 47/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 48/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 49/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 50/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 51/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 52/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 53/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 54/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 55/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 56/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 57/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 58/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 59/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 60/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 61/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 62/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 63/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 64/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 65/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 66/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 67/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 68/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 69/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 70/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 71/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 72/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 73/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 74/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 75/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 76/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 77/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 78/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 79/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 80/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 81/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 82/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 83/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 84/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 85/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 86/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 87/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 88/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 89/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 90/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 91/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 92/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 93/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 94/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 95/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 96/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 97/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 98/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 99/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n",
      "Epoch 100/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7692 - val_loss: 0.5926 - val_accuracy: 0.7689\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–…â–…â–„â–…â–„â–„â–ˆâ–„â–â–„â–ƒâ–‚â–…â–…â–„â–†â–„â–…â–„â–…â–„â–„â–„â–…â–…â–„â–…â–†â–„â–ƒâ–…â–ƒâ–…â–„â–…â–…â–…â–†â–…â–„</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ˆâ–„â–„â–…â–„â–„â–„â–ƒâ–„â–ƒâ–„â–ƒâ–„â–…â–„â–„â–„â–…â–„â–ƒâ–„â–„â–‡â–â–„â–…â–†â–…â–„â–ƒâ–„â–ƒâ–ƒâ–†â–„â–„â–„â–‚â–„</td></tr><tr><td>epoch/accuracy</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.76926</td></tr><tr><td>batch/batch_step</td><td>139995</td></tr><tr><td>batch/learning_rate</td><td>6e-05</td></tr><tr><td>batch/loss</td><td>0.59216</td></tr><tr><td>epoch/accuracy</td><td>0.76921</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>6e-05</td></tr><tr><td>epoch/loss</td><td>0.59222</td></tr><tr><td>epoch/val_accuracy</td><td>0.7689</td></tr><tr><td>epoch/val_loss</td><td>0.59259</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_29</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/oi648zo4' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/oi648zo4</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_045910-oi648zo4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 05:02:31,995] Trial 29 finished with value: 0.5925535917282104 and parameters: {'Layer_1_units': 122, 'Activation_1': 'relu', 'n_layers': 7, 'Layer_2_units': 95, 'Activation_2': 'sigmoid', 'Layer_3_units': 91, 'Activation_3': 'relu', 'Layer_4_units': 33, 'Activation_4': 'relu', 'Layer_5_units': 68, 'Activation_5': 'sigmoid', 'Layer_6_units': 81, 'Activation_6': 'sigmoid', 'Layer_7_units': 86, 'Activation_7': 'sigmoid', 'Layer_8_units': 58, 'Activation_8': 'relu', 'learning_rate': 6.055350170766679e-05, 'optimizer': 'sgd', 'batch_size': 100}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_050232-31jffuh1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/31jffuh1' target=\"_blank\">Trial_30</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/31jffuh1' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/31jffuh1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2800/2800 [==============================] - 4s 1ms/step - loss: 0.1992 - accuracy: 0.9206 - val_loss: 0.1266 - val_accuracy: 0.9520\n",
      "Epoch 2/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0863 - accuracy: 0.9740 - val_loss: 0.0617 - val_accuracy: 0.9837\n",
      "Epoch 3/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0489 - accuracy: 0.9893 - val_loss: 0.0348 - val_accuracy: 0.9937\n",
      "Epoch 4/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0271 - accuracy: 0.9967 - val_loss: 0.0247 - val_accuracy: 0.9970\n",
      "Epoch 5/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0218 - accuracy: 0.9976 - val_loss: 0.0241 - val_accuracy: 0.9955\n",
      "Epoch 6/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0188 - accuracy: 0.9978 - val_loss: 0.0253 - val_accuracy: 0.9944\n",
      "Epoch 7/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0171 - accuracy: 0.9978 - val_loss: 0.0162 - val_accuracy: 0.9980\n",
      "Epoch 8/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0150 - accuracy: 0.9983 - val_loss: 0.0154 - val_accuracy: 0.9976\n",
      "Epoch 9/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0138 - accuracy: 0.9983 - val_loss: 0.0144 - val_accuracy: 0.9981\n",
      "Epoch 10/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0129 - accuracy: 0.9983 - val_loss: 0.0149 - val_accuracy: 0.9972\n",
      "Epoch 11/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0120 - accuracy: 0.9984 - val_loss: 0.0115 - val_accuracy: 0.9987\n",
      "Epoch 12/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0112 - accuracy: 0.9986 - val_loss: 0.0116 - val_accuracy: 0.9979\n",
      "Epoch 13/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0106 - accuracy: 0.9987 - val_loss: 0.0107 - val_accuracy: 0.9986\n",
      "Epoch 14/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0098 - accuracy: 0.9988 - val_loss: 0.0112 - val_accuracy: 0.9979\n",
      "Epoch 15/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0094 - accuracy: 0.9987 - val_loss: 0.0115 - val_accuracy: 0.9974\n",
      "Epoch 16/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0091 - accuracy: 0.9987 - val_loss: 0.0098 - val_accuracy: 0.9982\n",
      "Epoch 17/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.0097 - val_accuracy: 0.9983\n",
      "Epoch 18/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0081 - accuracy: 0.9990 - val_loss: 0.0087 - val_accuracy: 0.9986\n",
      "Epoch 19/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0078 - accuracy: 0.9990 - val_loss: 0.0085 - val_accuracy: 0.9984\n",
      "Epoch 20/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.0089 - val_accuracy: 0.9984\n",
      "Epoch 21/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.0088 - val_accuracy: 0.9982\n",
      "Epoch 22/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.0080 - val_accuracy: 0.9984\n",
      "Epoch 23/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.0090 - val_accuracy: 0.9982\n",
      "Epoch 24/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0065 - accuracy: 0.9993 - val_loss: 0.0075 - val_accuracy: 0.9986\n",
      "Epoch 25/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0064 - accuracy: 0.9993 - val_loss: 0.0076 - val_accuracy: 0.9984\n",
      "Epoch 26/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.0074 - val_accuracy: 0.9985\n",
      "Epoch 27/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.0078 - val_accuracy: 0.9981\n",
      "Epoch 28/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.0079 - val_accuracy: 0.9983\n",
      "Epoch 29/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 0.0082 - val_accuracy: 0.9982\n",
      "Epoch 30/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.0067 - val_accuracy: 0.9989\n",
      "Epoch 31/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.0071 - val_accuracy: 0.9985\n",
      "Epoch 32/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.0067 - val_accuracy: 0.9988\n",
      "Epoch 33/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.0100 - val_accuracy: 0.9977\n",
      "Epoch 34/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9988\n",
      "Epoch 35/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.0070 - val_accuracy: 0.9984\n",
      "Epoch 36/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.0064 - val_accuracy: 0.9985\n",
      "Epoch 37/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.0075 - val_accuracy: 0.9981\n",
      "Epoch 38/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.0066 - val_accuracy: 0.9985\n",
      "Epoch 39/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
      "Epoch 40/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 0.9984\n",
      "Epoch 41/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0041 - accuracy: 0.9997 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 42/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
      "Epoch 43/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.0063 - val_accuracy: 0.9988\n",
      "Epoch 44/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 0.0064 - val_accuracy: 0.9983\n",
      "Epoch 45/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0063 - val_accuracy: 0.9984\n",
      "Epoch 46/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 47/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.0062 - val_accuracy: 0.9984\n",
      "Epoch 48/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.0076 - val_accuracy: 0.9979\n",
      "Epoch 49/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
      "Epoch 50/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.0058 - val_accuracy: 0.9986\n",
      "Epoch 51/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9986\n",
      "Epoch 52/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 0.9981\n",
      "Epoch 53/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.0064 - val_accuracy: 0.9986\n",
      "Epoch 54/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.0066 - val_accuracy: 0.9985\n",
      "Epoch 55/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.0067 - val_accuracy: 0.9986\n",
      "Epoch 56/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
      "Epoch 57/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 58/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
      "Epoch 59/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0058 - val_accuracy: 0.9986\n",
      "Epoch 60/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0076 - val_accuracy: 0.9977\n",
      "Epoch 61/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.0061 - val_accuracy: 0.9986\n",
      "Epoch 62/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0063 - val_accuracy: 0.9983\n",
      "Epoch 63/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0060 - val_accuracy: 0.9982\n",
      "Epoch 64/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0063 - val_accuracy: 0.9984\n",
      "Epoch 65/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
      "Epoch 66/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0069 - val_accuracy: 0.9983\n",
      "Epoch 67/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
      "Epoch 68/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0069 - val_accuracy: 0.9982\n",
      "Epoch 69/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9976\n",
      "Epoch 70/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0071 - val_accuracy: 0.9980\n",
      "Epoch 71/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.0071 - val_accuracy: 0.9982\n",
      "Epoch 72/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0063 - val_accuracy: 0.9984\n",
      "Epoch 73/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0064 - val_accuracy: 0.9981\n",
      "Epoch 74/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
      "Epoch 75/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
      "Epoch 76/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9981\n",
      "Epoch 77/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9984\n",
      "Epoch 78/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
      "Epoch 79/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0062 - val_accuracy: 0.9979\n",
      "Epoch 80/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9986\n",
      "Epoch 81/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0070 - val_accuracy: 0.9980\n",
      "Epoch 82/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0062 - val_accuracy: 0.9981\n",
      "Epoch 83/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0062 - val_accuracy: 0.9983\n",
      "Epoch 84/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0074 - val_accuracy: 0.9981\n",
      "Epoch 85/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9980\n",
      "Epoch 86/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
      "Epoch 87/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 88/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9982\n",
      "Epoch 89/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
      "Epoch 90/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9981\n",
      "Epoch 91/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
      "Epoch 92/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9984\n",
      "Epoch 93/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "Epoch 94/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9984\n",
      "Epoch 95/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0067 - val_accuracy: 0.9980\n",
      "Epoch 96/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9980\n",
      "Epoch 97/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 98/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 99/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 100/100\n",
      "2800/2800 [==============================] - 3s 1ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9986\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ƒâ–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–†â–‚â–†â–‡â–ˆâ–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–†â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ˆâ–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–â–â–‚â–â–ƒâ–â–â–â–â–â–â–â–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99996</td></tr><tr><td>batch/batch_step</td><td>279995</td></tr><tr><td>batch/learning_rate</td><td>0.00027</td></tr><tr><td>batch/loss</td><td>0.00184</td></tr><tr><td>epoch/accuracy</td><td>0.99996</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00027</td></tr><tr><td>epoch/loss</td><td>0.00184</td></tr><tr><td>epoch/val_accuracy</td><td>0.9986</td></tr><tr><td>epoch/val_loss</td><td>0.00523</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_30</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/31jffuh1' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/31jffuh1</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_050232-31jffuh1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 05:07:42,212] Trial 30 finished with value: 0.0048903499497100714 and parameters: {'Layer_1_units': 101, 'Activation_1': 'sigmoid', 'n_layers': 3, 'Layer_2_units': 110, 'Activation_2': 'relu', 'Layer_3_units': 64, 'Activation_3': 'relu', 'Layer_4_units': 65, 'Activation_4': 'sigmoid', 'learning_rate': 0.0002684327240803952, 'optimizer': 'adam', 'batch_size': 50}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_050742-rcn7dcd3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/rcn7dcd3' target=\"_blank\">Trial_31</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/rcn7dcd3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/rcn7dcd3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/7000 [..............................] - ETA: 44:04 - loss: 0.7330 - accuracy: 0.4500WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0006s). Check your callbacks.\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0936 - accuracy: 0.9636 - val_loss: 0.0291 - val_accuracy: 0.9915\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.0145 - val_accuracy: 0.9955\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0228 - val_accuracy: 0.9927\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0078 - val_accuracy: 0.9976\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0061 - val_accuracy: 0.9980\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0172 - val_accuracy: 0.9953\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.0062 - val_accuracy: 0.9979\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 6s 834us/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0088 - val_accuracy: 0.9970\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 6s 831us/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0064 - val_accuracy: 0.9979\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0057 - val_accuracy: 0.9979\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0185 - val_accuracy: 0.9952\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0167 - val_accuracy: 0.9961\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0045 - val_accuracy: 0.9985\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 6s 833us/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0117 - val_accuracy: 0.9969\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0060 - val_accuracy: 0.9974\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0099 - val_accuracy: 0.9969\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 6s 831us/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0130 - val_accuracy: 0.9963\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0067 - val_accuracy: 0.9976\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 6s 864us/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0143 - val_accuracy: 0.9962\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0097 - val_accuracy: 0.9969\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0088 - val_accuracy: 0.9970\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0044 - val_accuracy: 0.9985\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 6s 834us/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0060 - val_accuracy: 0.9977\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0037 - val_accuracy: 0.9990\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.0061 - val_accuracy: 0.9979\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0126 - val_accuracy: 0.9962\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0088 - val_accuracy: 0.9972\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0046 - val_accuracy: 0.9984\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0074 - val_accuracy: 0.9979\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 6s 834us/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0119 - val_accuracy: 0.9969\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 6s 832us/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0074 - val_accuracy: 0.9977\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 6s 833us/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0090 - val_accuracy: 0.9973\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0127 - val_accuracy: 0.9966\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 6s 832us/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0112 - val_accuracy: 0.9967\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0068 - val_accuracy: 0.9976\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0127 - val_accuracy: 0.9969\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 6s 842us/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0086 - val_accuracy: 0.9973\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0050 - val_accuracy: 0.9984\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0059 - val_accuracy: 0.9980\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0126 - val_accuracy: 0.9973\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0096 - val_accuracy: 0.9973\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9981\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0191 - val_accuracy: 0.9959\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0050 - val_accuracy: 0.9981\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0079 - val_accuracy: 0.9979\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 6s 832us/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0192 - val_accuracy: 0.9962\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0088 - val_accuracy: 0.9973\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 6s 834us/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0074 - val_accuracy: 0.9976\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 6s 833us/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0152 - val_accuracy: 0.9970\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 6s 832us/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0110 - val_accuracy: 0.9969\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0081 - val_accuracy: 0.9980\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0076 - val_accuracy: 0.9977\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0050 - val_accuracy: 0.9981\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0123 - val_accuracy: 0.9973\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0065 - val_accuracy: 0.9977\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0175 - val_accuracy: 0.9960\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9980\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0042 - val_accuracy: 0.9984\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0081 - val_accuracy: 0.9978\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0068 - val_accuracy: 0.9981\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0093 - val_accuracy: 0.9975\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 6s 834us/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0066 - val_accuracy: 0.9979\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 6s 833us/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0055 - val_accuracy: 0.9980\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0057 - val_accuracy: 0.9982\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0062 - val_accuracy: 0.9981\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0050 - val_accuracy: 0.9984\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0166 - val_accuracy: 0.9965\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 6s 834us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 6s 832us/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0127 - val_accuracy: 0.9972\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0063 - val_accuracy: 0.9979\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 6s 833us/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0081 - val_accuracy: 0.9973\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0055 - val_accuracy: 0.9982\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 6s 833us/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0064 - val_accuracy: 0.9980\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0078 - val_accuracy: 0.9981\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0087 - val_accuracy: 0.9975\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0075 - val_accuracy: 0.9982\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 6s 834us/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0409 - val_accuracy: 0.9941\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0151 - val_accuracy: 0.9970\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0089 - val_accuracy: 0.9979\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0089 - val_accuracy: 0.9977\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0039 - val_accuracy: 0.9985\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0057 - val_accuracy: 0.9981\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0254 - val_accuracy: 0.9952\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0298 - val_accuracy: 0.9954\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 6s 833us/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0065 - val_accuracy: 0.9984\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0091 - val_accuracy: 0.9975\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 6s 834us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0047 - val_accuracy: 0.9983\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 6s 833us/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0060 - val_accuracy: 0.9982\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 6s 833us/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 6s 833us/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0102 - val_accuracy: 0.9974\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0077 - val_accuracy: 0.9980\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0151 - val_accuracy: 0.9967\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0069 - val_accuracy: 0.9981\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0076 - val_accuracy: 0.9979\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0228 - val_accuracy: 0.9959\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0133 - val_accuracy: 0.9970\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 6s 834us/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0106 - val_accuracy: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ƒâ–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–‡â–…â–†â–…â–†â–†â–„â–…â–†â–ˆâ–ˆâ–†â–†â–†â–‡â–†â–†â–‡â–†â–†â–†â–‡â–†â–„â–‡â–‡â–‡â–‡â–…â–†â–†â–‡â–â–†â–†â–ƒâ–ƒâ–†â–‡â–…</td></tr><tr><td>epoch/val_loss</td><td>â–‚â–‚â–‚â–‚â–†â–‚â–ƒâ–ƒâ–â–‚â–ƒâ–‚â–ƒâ–„â–â–â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ˆâ–â–â–‚â–‚â–ƒ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99892</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00107</td></tr><tr><td>batch/loss</td><td>0.00379</td></tr><tr><td>epoch/accuracy</td><td>0.99892</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00107</td></tr><tr><td>epoch/loss</td><td>0.00378</td></tr><tr><td>epoch/val_accuracy</td><td>0.9978</td></tr><tr><td>epoch/val_loss</td><td>0.01062</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_31</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/rcn7dcd3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/rcn7dcd3</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_050742-rcn7dcd3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 05:17:30,348] Trial 31 finished with value: 0.003667945810593665 and parameters: {'Layer_1_units': 91, 'Activation_1': 'sigmoid', 'n_layers': 1, 'Layer_2_units': 102, 'Activation_2': 'relu', 'learning_rate': 0.001067436098625053, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 11 with value: 0.002590348944067955.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_051730-2w58su36</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/2w58su36' target=\"_blank\">Trial_32</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/2w58su36' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/2w58su36</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 6s 863us/step - loss: 0.0662 - accuracy: 0.9749 - val_loss: 0.0150 - val_accuracy: 0.9957\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0171 - val_accuracy: 0.9942\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0119 - val_accuracy: 0.9965\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0240 - val_accuracy: 0.9927\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.0067 - val_accuracy: 0.9979\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0068 - val_accuracy: 0.9976\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 6s 847us/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0802 - val_accuracy: 0.9780\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0099 - val_accuracy: 0.9968\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0177 - val_accuracy: 0.9951\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.0259 - val_accuracy: 0.9947\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 6s 847us/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.0083 - val_accuracy: 0.9979\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.0079 - val_accuracy: 0.9974\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0071 - val_accuracy: 0.9976\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 6s 843us/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0055 - val_accuracy: 0.9981\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 6s 844us/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0082 - val_accuracy: 0.9977\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 6s 846us/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0050 - val_accuracy: 0.9981\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 6s 844us/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0068 - val_accuracy: 0.9977\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 6s 849us/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0064 - val_accuracy: 0.9977\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 6s 847us/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0061 - val_accuracy: 0.9980\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 6s 868us/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0151 - val_accuracy: 0.9964\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0053 - val_accuracy: 0.9983\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 6s 845us/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0087 - val_accuracy: 0.9973\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 6s 849us/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0152 - val_accuracy: 0.9964\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 6s 849us/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0077 - val_accuracy: 0.9977\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9984\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0055 - val_accuracy: 0.9983\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 6s 847us/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 6s 849us/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0127 - val_accuracy: 0.9971\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 6s 854us/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0061 - val_accuracy: 0.9980\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0080 - val_accuracy: 0.9977\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 6s 847us/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0057 - val_accuracy: 0.9979\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0054 - val_accuracy: 0.9982\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 6s 849us/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 6s 849us/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0059 - val_accuracy: 0.9980\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0052 - val_accuracy: 0.9984\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 7s 974us/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0082 - val_accuracy: 0.9979\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0106 - val_accuracy: 0.9973\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 7s 983us/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0103 - val_accuracy: 0.9977\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 6s 912us/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0097 - val_accuracy: 0.9973\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 6s 894us/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0044 - val_accuracy: 0.9984\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 6s 891us/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0092 - val_accuracy: 0.9981\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 6s 889us/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0053 - val_accuracy: 0.9983\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 6s 891us/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0075 - val_accuracy: 0.9981\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 6s 897us/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0101 - val_accuracy: 0.9973\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 6s 892us/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 6s 892us/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0099 - val_accuracy: 0.9977\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 6s 890us/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0050 - val_accuracy: 0.9982\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 6s 918us/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0099 - val_accuracy: 0.9977\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 6s 889us/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 6s 890us/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0147 - val_accuracy: 0.9969\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 6s 891us/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0075 - val_accuracy: 0.9981\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 6s 883us/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 6s 886us/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0088 - val_accuracy: 0.9976\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 6s 881us/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0052 - val_accuracy: 0.9985\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 6s 886us/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0064 - val_accuracy: 0.9984\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 6s 885us/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0064 - val_accuracy: 0.9979\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 6s 880us/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0117 - val_accuracy: 0.9972\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 6s 881us/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0073 - val_accuracy: 0.9986\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 6s 887us/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0089 - val_accuracy: 0.9973\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 6s 880us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 6s 879us/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 7s 928us/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0094 - val_accuracy: 0.9980\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 6s 881us/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0072 - val_accuracy: 0.9981\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 6s 882us/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0063 - val_accuracy: 0.9981\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 6s 883us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9986\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 6s 883us/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 6s 886us/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 6s 887us/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0044 - val_accuracy: 0.9983\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 6s 883us/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 6s 887us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9984\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 7s 957us/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0081 - val_accuracy: 0.9974\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0070 - val_accuracy: 0.9981\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0060 - val_accuracy: 0.9984\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 7s 975us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0038 - val_accuracy: 0.9986\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 6s 845us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9985\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 6s 912us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0052 - val_accuracy: 0.9984\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 6s 890us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9984\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 6s 877us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0046 - val_accuracy: 0.9984\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 6s 869us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0045 - val_accuracy: 0.9986\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 6s 845us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0045 - val_accuracy: 0.9983\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0120 - val_accuracy: 0.9976\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 6s 893us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0024 - val_accuracy: 0.9991\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 6s 862us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0131 - val_accuracy: 0.9975\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 6s 874us/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0286 - val_accuracy: 0.9956\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 6s 866us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0087 - val_accuracy: 0.9979\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 6s 886us/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0164 - val_accuracy: 0.9967\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0036 - val_accuracy: 0.9985\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 6s 906us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0101 - val_accuracy: 0.9977\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 6s 870us/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0180 - val_accuracy: 0.9967\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 6s 846us/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0073 - val_accuracy: 0.9979\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0113 - val_accuracy: 0.9977\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0071 - val_accuracy: 0.9977\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0135 - val_accuracy: 0.9968\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 6s 865us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0075 - val_accuracy: 0.9981\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 6s 847us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9986\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–‡â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–†â–ƒâ–…â–„â–„â–…â–„â–„â–…â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–â–‚</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–…â–†â–‚â–‚â–‡â–†â–‡â–‡â–ˆâ–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–†â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–†â–‡â–‡â–…â–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–â–ˆâ–ƒâ–â–ƒâ–„</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99916</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00208</td></tr><tr><td>batch/loss</td><td>0.00269</td></tr><tr><td>epoch/accuracy</td><td>0.99916</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00208</td></tr><tr><td>epoch/loss</td><td>0.00269</td></tr><tr><td>epoch/val_accuracy</td><td>0.9986</td></tr><tr><td>epoch/val_loss</td><td>0.00419</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_32</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/2w58su36' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/2w58su36</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_051730-2w58su36/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 05:27:50,656] Trial 32 finished with value: 0.0024291265988722445 and parameters: {'Layer_1_units': 84, 'Activation_1': 'sigmoid', 'n_layers': 1, 'Layer_2_units': 121, 'Activation_2': 'relu', 'learning_rate': 0.002080184510503494, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 32 with value: 0.0024291265988722445.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_052750-v6w3861a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/v6w3861a' target=\"_blank\">Trial_33</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/v6w3861a' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/v6w3861a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0558 - accuracy: 0.9795 - val_loss: 0.0151 - val_accuracy: 0.9952\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.0118 - val_accuracy: 0.9959\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 6s 911us/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 7s 992us/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.0268 - val_accuracy: 0.9942\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 7s 968us/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.0095 - val_accuracy: 0.9958\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 6s 921us/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0243 - val_accuracy: 0.9930\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 7s 930us/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.0094 - val_accuracy: 0.9971\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.0113 - val_accuracy: 0.9966\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.0105 - val_accuracy: 0.9967\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 7s 969us/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.0057 - val_accuracy: 0.9978\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.0225 - val_accuracy: 0.9952\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 7s 951us/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.0165 - val_accuracy: 0.9960\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0170 - val_accuracy: 0.9962\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 7s 966us/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.0102 - val_accuracy: 0.9970\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 7s 941us/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.0089 - val_accuracy: 0.9977\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 6s 927us/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.0100 - val_accuracy: 0.9977\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 7s 956us/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.0115 - val_accuracy: 0.9970\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 6s 928us/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 0.0073 - val_accuracy: 0.9977\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 7s 970us/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.0069 - val_accuracy: 0.9969\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.0077 - val_accuracy: 0.9980\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 6s 909us/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.0061 - val_accuracy: 0.9982\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 7s 973us/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.0085 - val_accuracy: 0.9965\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.0116 - val_accuracy: 0.9973\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.0083 - val_accuracy: 0.9975\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.0070 - val_accuracy: 0.9976\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.0088 - val_accuracy: 0.9979\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 7s 951us/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0121 - val_accuracy: 0.9972\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 7s 976us/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0148 - val_accuracy: 0.9967\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0082 - val_accuracy: 0.9973\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 6s 907us/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.0065 - val_accuracy: 0.9980\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 7s 993us/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.0077 - val_accuracy: 0.9975\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.0086 - val_accuracy: 0.9978\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0066 - val_accuracy: 0.9983\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0127 - val_accuracy: 0.9976\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 6s 919us/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.0077 - val_accuracy: 0.9973\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 7s 972us/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0255 - val_accuracy: 0.9952\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 7s 963us/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0101 - val_accuracy: 0.9980\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 6s 909us/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0221 - val_accuracy: 0.9966\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0043 - val_accuracy: 0.9985\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 6s 917us/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0091 - val_accuracy: 0.9977\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 7s 981us/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0159 - val_accuracy: 0.9973\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 6s 909us/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.0131 - val_accuracy: 0.9980\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 7s 967us/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0160 - val_accuracy: 0.9972\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 7s 957us/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.0080 - val_accuracy: 0.9976\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 6s 922us/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.0328 - val_accuracy: 0.9945\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 7s 937us/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.0133 - val_accuracy: 0.9974\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 7s 941us/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0105 - val_accuracy: 0.9973\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 7s 942us/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0060 - val_accuracy: 0.9984\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 7s 972us/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0068 - val_accuracy: 0.9986\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 6s 912us/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0148 - val_accuracy: 0.9975\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 7s 967us/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.0136 - val_accuracy: 0.9981\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 7s 953us/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0108 - val_accuracy: 0.9980\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0178 - val_accuracy: 0.9973\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.0186 - val_accuracy: 0.9969\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 6s 914us/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0110 - val_accuracy: 0.9982\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 7s 966us/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.0143 - val_accuracy: 0.9974\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0201 - val_accuracy: 0.9967\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 6s 928us/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0217 - val_accuracy: 0.9968\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0066 - val_accuracy: 0.9977\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0189 - val_accuracy: 0.9969\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 7s 977us/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0045 - val_accuracy: 0.9981\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 7s 956us/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0070 - val_accuracy: 0.9982\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0082 - val_accuracy: 0.9979\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0049 - val_accuracy: 0.9980\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9986\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0073 - val_accuracy: 0.9985\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 7s 965us/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0080 - val_accuracy: 0.9981\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 6s 926us/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0090 - val_accuracy: 0.9983\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 7s 973us/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0117 - val_accuracy: 0.9981\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0039 - val_accuracy: 0.9985\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 7s 930us/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0140 - val_accuracy: 0.9977\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0056 - val_accuracy: 0.9986\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.0183 - val_accuracy: 0.9970\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 7s 970us/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0070 - val_accuracy: 0.9985\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0171 - val_accuracy: 0.9974\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0095 - val_accuracy: 0.9983\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 7s 972us/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0111 - val_accuracy: 0.9980\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 6s 928us/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0051 - val_accuracy: 0.9986\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 7s 975us/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0095 - val_accuracy: 0.9984\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 7s 929us/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0128 - val_accuracy: 0.9978\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 6s 907us/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0244 - val_accuracy: 0.9962\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 7s 974us/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 7s 971us/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0127 - val_accuracy: 0.9980\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 6s 912us/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0096 - val_accuracy: 0.9982\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 6s 919us/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0064 - val_accuracy: 0.9981\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 7s 979us/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0072 - val_accuracy: 0.9980\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 6s 922us/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0140 - val_accuracy: 0.9973\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 7s 966us/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 7s 939us/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0167 - val_accuracy: 0.9973\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 6s 908us/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 7s 972us/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0133 - val_accuracy: 0.9975\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 7s 976us/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0159 - val_accuracy: 0.9977\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0074 - val_accuracy: 0.9985\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 6s 922us/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–‚â–ˆâ–‚â–ƒâ–ƒâ–‚â–„â–â–ƒâ–…â–…â–†â–„â–„â–„â–ƒâ–‡â–†â–†â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–†â–‡</td></tr><tr><td>batch/batch_step</td><td>â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–‡â–‡â–†â–†â–†â–‡â–†â–†â–‡â–‡â–…â–…â–†â–…â–…â–†â–ƒâ–…â–ˆâ–…â–†â–…â–†â–…â–…â–…â–„â–…â–…â–„â–…â–…â–…â–…â–„â–„â–…â–â–…â–„</td></tr><tr><td>epoch/accuracy</td><td>â–â–ƒâ–„â–…â–…â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–â–‚</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–…â–…â–†â–‚â–…â–‡â–†â–†â–…â–‡â–†â–†â–‚â–‡â–ˆâ–‡â–…â–†â–â–‡â–ˆâ–‡â–‡â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–†â–‡â–‡â–ˆâ–„â–‡â–†â–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–„â–ƒâ–ˆâ–ƒâ–‡â–‡â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–„â–…â–„â–…â–‚â–ƒâ–‚â–†â–„â–‚â–†â–â–â–„â–…â–‚â–ƒâ–‡â–‚â–ƒâ–‚â–„â–‚â–…â–„â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99854</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00455</td></tr><tr><td>batch/loss</td><td>0.00652</td></tr><tr><td>epoch/accuracy</td><td>0.99854</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00455</td></tr><tr><td>epoch/loss</td><td>0.00651</td></tr><tr><td>epoch/val_accuracy</td><td>0.99885</td></tr><tr><td>epoch/val_loss</td><td>0.0048</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_33</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/v6w3861a' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/v6w3861a</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_052750-v6w3861a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 05:38:55,634] Trial 33 finished with value: 0.0038401335943490265 and parameters: {'Layer_1_units': 83, 'Activation_1': 'sigmoid', 'n_layers': 2, 'Layer_2_units': 119, 'Activation_2': 'relu', 'Layer_3_units': 51, 'Activation_3': 'relu', 'learning_rate': 0.004545281195492035, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 32 with value: 0.0024291265988722445.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_053855-209pfc65</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/209pfc65' target=\"_blank\">Trial_34</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/209pfc65' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/209pfc65</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0560 - accuracy: 0.9798 - val_loss: 0.0189 - val_accuracy: 0.9948\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 7s 943us/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0101 - val_accuracy: 0.9967\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 6s 922us/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.0104 - val_accuracy: 0.9962\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0132 - val_accuracy: 0.9963\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 7s 951us/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0084 - val_accuracy: 0.9973\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 7s 963us/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0081 - val_accuracy: 0.9977\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.0082 - val_accuracy: 0.9973\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0079 - val_accuracy: 0.9974\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 7s 954us/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0065 - val_accuracy: 0.9977\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 7s 980us/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0099 - val_accuracy: 0.9973\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 7s 937us/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0080 - val_accuracy: 0.9977\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 6s 928us/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0068 - val_accuracy: 0.9977\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 7s 989us/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0199 - val_accuracy: 0.9948\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 6s 927us/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0057 - val_accuracy: 0.9979\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0077 - val_accuracy: 0.9972\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0069 - val_accuracy: 0.9976\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0069 - val_accuracy: 0.9978\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 7s 981us/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0048 - val_accuracy: 0.9981\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0036 - val_accuracy: 0.9986\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0048 - val_accuracy: 0.9983\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0091 - val_accuracy: 0.9973\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 7s 989us/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0066 - val_accuracy: 0.9979\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0046 - val_accuracy: 0.9984\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0070 - val_accuracy: 0.9980\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 7s 966us/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 7s 978us/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0047 - val_accuracy: 0.9985\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0096 - val_accuracy: 0.9973\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 6s 926us/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0050 - val_accuracy: 0.9983\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0046 - val_accuracy: 0.9983\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 7s 970us/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0091 - val_accuracy: 0.9971\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0070 - val_accuracy: 0.9979\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0073 - val_accuracy: 0.9979\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 7s 956us/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0050 - val_accuracy: 0.9984\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0064 - val_accuracy: 0.9980\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0045 - val_accuracy: 0.9985\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0059 - val_accuracy: 0.9983\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0030 - val_accuracy: 0.9988\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0050 - val_accuracy: 0.9984\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 7s 967us/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 7s 979us/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0093 - val_accuracy: 0.9972\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 7s 954us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0055 - val_accuracy: 0.9983\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 7s 989us/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0038 - val_accuracy: 0.9985\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 6s 927us/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 7s 971us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0055 - val_accuracy: 0.9982\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 7s 952us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0106 - val_accuracy: 0.9972\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0032 - val_accuracy: 0.9990\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 7s 995us/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0026 - val_accuracy: 0.9991\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 7s 978us/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9986\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 7s 943us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0113 - val_accuracy: 0.9965\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0045 - val_accuracy: 0.9985\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 7s 996us/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0049 - val_accuracy: 0.9983\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 6s 926us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0048 - val_accuracy: 0.9988\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 7s 981us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0059 - val_accuracy: 0.9981\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9979\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0084 - val_accuracy: 0.9979\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0029 - val_accuracy: 0.9989\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0045 - val_accuracy: 0.9986\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 7s 940us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9988\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 7s 975us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 7s 937us/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 7s 940us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 7s 992us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 7s 973us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0045 - val_accuracy: 0.9986\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0027 - val_accuracy: 0.9990\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 7s 939us/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 6s 922us/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0072 - val_accuracy: 0.9983\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0100 - val_accuracy: 0.9973\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 7s 975us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0029 - val_accuracy: 0.9990\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0080 - val_accuracy: 0.9981\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0087 - val_accuracy: 0.9979\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 6s 921us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9985\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 7s 978us/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 7s 995us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9989\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 7s 940us/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 7s 939us/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 7s 976us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0026 - val_accuracy: 0.9992\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 7s 977us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0069 - val_accuracy: 0.9982\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 7s 967us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0049 - val_accuracy: 0.9984\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 7s 953us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 7s 998us/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0069 - val_accuracy: 0.9983\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 7s 943us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0109 - val_accuracy: 0.9976\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0027 - val_accuracy: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–ƒâ–„â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ƒâ–…â–â–†â–‡â–†â–‡â–‡â–…â–†â–‡â–‡â–…â–‡â–†â–†â–…â–‡â–„â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–‡â–†â–ˆâ–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–…</td></tr><tr><td>epoch/val_loss</td><td>â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–‚â–ƒâ–‚â–â–‚â–‚â–ƒâ–‚â–„â–â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–â–‚â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99913</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00593</td></tr><tr><td>batch/loss</td><td>0.00297</td></tr><tr><td>epoch/accuracy</td><td>0.99912</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00593</td></tr><tr><td>epoch/loss</td><td>0.00298</td></tr><tr><td>epoch/val_accuracy</td><td>0.99905</td></tr><tr><td>epoch/val_loss</td><td>0.00274</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_34</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/209pfc65' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/209pfc65</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_053855-209pfc65/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 05:50:11,161] Trial 34 finished with value: 0.0021758171962574123 and parameters: {'Layer_1_units': 96, 'Activation_1': 'sigmoid', 'n_layers': 2, 'Layer_2_units': 123, 'Activation_2': 'relu', 'Layer_3_units': 58, 'Activation_3': 'sigmoid', 'learning_rate': 0.005933910036525751, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 34 with value: 0.0021758171962574123.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_055011-hvjheely</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/hvjheely' target=\"_blank\">Trial_35</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/hvjheely' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/hvjheely</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/7000 [..............................] - ETA: 34:04 - loss: 0.6932 - accuracy: 0.6000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0007s). Check your callbacks.\n",
      "7000/7000 [==============================] - 7s 952us/step - loss: 0.0661 - accuracy: 0.9755 - val_loss: 0.0365 - val_accuracy: 0.9918\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.0115 - val_accuracy: 0.9966\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 6s 915us/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.0122 - val_accuracy: 0.9959\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 6s 928us/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0154 - val_accuracy: 0.9947\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 6s 918us/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0089 - val_accuracy: 0.9969\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 7s 951us/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0088 - val_accuracy: 0.9971\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 6s 912us/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0068 - val_accuracy: 0.9979\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0078 - val_accuracy: 0.9972\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 6s 912us/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0087 - val_accuracy: 0.9973\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 6s 890us/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0065 - val_accuracy: 0.9977\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 7s 950us/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0066 - val_accuracy: 0.9976\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 6s 908us/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 0.9977\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0064 - val_accuracy: 0.9979\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 6s 913us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0090 - val_accuracy: 0.9972\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0080 - val_accuracy: 0.9979\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 7s 967us/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0090 - val_accuracy: 0.9973\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 6s 919us/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0078 - val_accuracy: 0.9976\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 7s 950us/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 6s 905us/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 7s 929us/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0060 - val_accuracy: 0.9979\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 6s 905us/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0075 - val_accuracy: 0.9977\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 6s 895us/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0077 - val_accuracy: 0.9974\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 7s 974us/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0070 - val_accuracy: 0.9978\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0088 - val_accuracy: 0.9971\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 6s 908us/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 6s 918us/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0083 - val_accuracy: 0.9976\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 6s 928us/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0072 - val_accuracy: 0.9978\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 6s 914us/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0068 - val_accuracy: 0.9977\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 7s 972us/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0080 - val_accuracy: 0.9977\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 6s 913us/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0070 - val_accuracy: 0.9977\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0080 - val_accuracy: 0.9973\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0091 - val_accuracy: 0.9974\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0074 - val_accuracy: 0.9977\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9979\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 7s 977us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0116 - val_accuracy: 0.9973\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0082 - val_accuracy: 0.9979\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 7s 951us/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0092 - val_accuracy: 0.9975\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 7s 940us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0083 - val_accuracy: 0.9979\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0103 - val_accuracy: 0.9973\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 7s 929us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0080 - val_accuracy: 0.9979\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0079 - val_accuracy: 0.9979\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 6s 909us/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0084 - val_accuracy: 0.9981\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 7s 939us/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0078 - val_accuracy: 0.9977\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 6s 915us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0105 - val_accuracy: 0.9973\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 9.6032e-04 - accuracy: 0.9998 - val_loss: 0.0089 - val_accuracy: 0.9977\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 6s 907us/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0113 - val_accuracy: 0.9972\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0072 - val_accuracy: 0.9982\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 6s 907us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0082 - val_accuracy: 0.9976\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 8.9546e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9973\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 7s 949us/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0079 - val_accuracy: 0.9979\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 7s 941us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0070 - val_accuracy: 0.9980\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 6s 905us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0111 - val_accuracy: 0.9976\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 7s 929us/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0093 - val_accuracy: 0.9977\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 9.9392e-04 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 0.9982\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0102 - val_accuracy: 0.9973\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 9.9722e-04 - accuracy: 0.9998 - val_loss: 0.0084 - val_accuracy: 0.9980\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0266 - val_accuracy: 0.9912\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 6s 888us/step - loss: 9.1563e-04 - accuracy: 0.9998 - val_loss: 0.0082 - val_accuracy: 0.9977\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 7s 957us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0076 - val_accuracy: 0.9982\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 6s 913us/step - loss: 8.3654e-04 - accuracy: 0.9999 - val_loss: 0.0096 - val_accuracy: 0.9976\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 7s 929us/step - loss: 7.7567e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9977\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 6s 907us/step - loss: 8.0333e-04 - accuracy: 0.9999 - val_loss: 0.0096 - val_accuracy: 0.9977\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 6s 887us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0084 - val_accuracy: 0.9976\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 7s 975us/step - loss: 8.8800e-04 - accuracy: 0.9998 - val_loss: 0.0088 - val_accuracy: 0.9975\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 6.9658e-04 - accuracy: 0.9998 - val_loss: 0.0147 - val_accuracy: 0.9968\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0112 - val_accuracy: 0.9972\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0108 - val_accuracy: 0.9976\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 7s 929us/step - loss: 8.6766e-04 - accuracy: 0.9998 - val_loss: 0.0105 - val_accuracy: 0.9978\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 6s 914us/step - loss: 8.3863e-04 - accuracy: 0.9998 - val_loss: 0.0071 - val_accuracy: 0.9984\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 9.7672e-04 - accuracy: 0.9998 - val_loss: 0.0103 - val_accuracy: 0.9974\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 6s 913us/step - loss: 9.1261e-04 - accuracy: 0.9998 - val_loss: 0.0116 - val_accuracy: 0.9975\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 6s 894us/step - loss: 8.7322e-04 - accuracy: 0.9998 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 7s 967us/step - loss: 9.1655e-04 - accuracy: 0.9999 - val_loss: 0.0118 - val_accuracy: 0.9975\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 6s 915us/step - loss: 8.0083e-04 - accuracy: 0.9999 - val_loss: 0.0105 - val_accuracy: 0.9978\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 6.7413e-04 - accuracy: 0.9999 - val_loss: 0.0132 - val_accuracy: 0.9974\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 6s 912us/step - loss: 8.4533e-04 - accuracy: 0.9999 - val_loss: 0.0088 - val_accuracy: 0.9977\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 7s 949us/step - loss: 9.9351e-04 - accuracy: 0.9998 - val_loss: 0.0083 - val_accuracy: 0.9980\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 7s 958us/step - loss: 8.4551e-04 - accuracy: 0.9998 - val_loss: 0.0105 - val_accuracy: 0.9977\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 6s 917us/step - loss: 9.3061e-04 - accuracy: 0.9999 - val_loss: 0.0099 - val_accuracy: 0.9974\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 6s 896us/step - loss: 8.7803e-04 - accuracy: 0.9999 - val_loss: 0.0112 - val_accuracy: 0.9977\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 6s 890us/step - loss: 9.1370e-04 - accuracy: 0.9998 - val_loss: 0.0113 - val_accuracy: 0.9976\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 6s 888us/step - loss: 7.7797e-04 - accuracy: 0.9999 - val_loss: 0.0125 - val_accuracy: 0.9973\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 6s 889us/step - loss: 7.6722e-04 - accuracy: 0.9998 - val_loss: 0.0100 - val_accuracy: 0.9975\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 6s 888us/step - loss: 6.4888e-04 - accuracy: 0.9999 - val_loss: 0.0111 - val_accuracy: 0.9973\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 6s 888us/step - loss: 9.3956e-04 - accuracy: 0.9998 - val_loss: 0.0096 - val_accuracy: 0.9977\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 6s 891us/step - loss: 5.5127e-04 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9976\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 6s 894us/step - loss: 9.0521e-04 - accuracy: 0.9999 - val_loss: 0.0110 - val_accuracy: 0.9977\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 6s 892us/step - loss: 7.0119e-04 - accuracy: 0.9999 - val_loss: 0.0093 - val_accuracy: 0.9979\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 6s 895us/step - loss: 9.0873e-04 - accuracy: 0.9998 - val_loss: 0.0126 - val_accuracy: 0.9973\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 6s 892us/step - loss: 6.2771e-04 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9978\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 6s 888us/step - loss: 8.4897e-04 - accuracy: 0.9998 - val_loss: 0.0098 - val_accuracy: 0.9976\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 6s 886us/step - loss: 7.4653e-04 - accuracy: 0.9999 - val_loss: 0.0102 - val_accuracy: 0.9974\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 6s 889us/step - loss: 8.2994e-04 - accuracy: 0.9998 - val_loss: 0.0101 - val_accuracy: 0.9979\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 6s 886us/step - loss: 4.2881e-04 - accuracy: 0.9999 - val_loss: 0.0112 - val_accuracy: 0.9977\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 6s 891us/step - loss: 5.9422e-04 - accuracy: 0.9998 - val_loss: 0.0112 - val_accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ˆâ–‡â–…â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–„â–„â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99984</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00292</td></tr><tr><td>batch/loss</td><td>0.00059</td></tr><tr><td>epoch/accuracy</td><td>0.99984</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00292</td></tr><tr><td>epoch/loss</td><td>0.00059</td></tr><tr><td>epoch/val_accuracy</td><td>0.9975</td></tr><tr><td>epoch/val_loss</td><td>0.01122</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_35</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/hvjheely' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/hvjheely</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_055011-hvjheely/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 06:00:58,764] Trial 35 finished with value: 0.00470254068786744 and parameters: {'Layer_1_units': 98, 'Activation_1': 'sigmoid', 'n_layers': 1, 'Layer_2_units': 117, 'Activation_2': 'relu', 'learning_rate': 0.002917045209008613, 'optimizer': 'adam', 'batch_size': 20}. Best is trial 34 with value: 0.0021758171962574123.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_060058-lobpsnm2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/lobpsnm2' target=\"_blank\">Trial_36</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/lobpsnm2' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/lobpsnm2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.0664 - accuracy: 0.9784 - val_loss: 0.0285 - val_accuracy: 0.9926\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.0126 - val_accuracy: 0.9967\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0158 - accuracy: 0.9961 - val_loss: 0.0499 - val_accuracy: 0.9873\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.0122 - val_accuracy: 0.9959\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.0214 - val_accuracy: 0.9963\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.0155 - val_accuracy: 0.9961\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 0.0133 - val_accuracy: 0.9959\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.0175 - val_accuracy: 0.9967\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.0075 - val_accuracy: 0.9979\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.0130 - val_accuracy: 0.9969\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.0062 - val_accuracy: 0.9978\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0106 - val_accuracy: 0.9972\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.0103 - val_accuracy: 0.9970\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.0080 - val_accuracy: 0.9973\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0082 - val_accuracy: 0.9977\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.0248 - val_accuracy: 0.9956\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.0142 - val_accuracy: 0.9973\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.0172 - val_accuracy: 0.9969\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0068 - val_accuracy: 0.9981\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0220 - val_accuracy: 0.9959\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0101 - val_accuracy: 0.9976\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0247 - val_accuracy: 0.9959\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0099 - val_accuracy: 0.9976\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0091 - val_accuracy: 0.9980\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0114 - val_accuracy: 0.9976\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0083 - val_accuracy: 0.9978\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0094 - val_accuracy: 0.9977\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0093 - val_accuracy: 0.9981\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0170 - val_accuracy: 0.9970\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0074 - val_accuracy: 0.9980\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0158 - val_accuracy: 0.9970\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0120 - val_accuracy: 0.9973\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0085 - val_accuracy: 0.9982\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.0130 - val_accuracy: 0.9973\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0185 - val_accuracy: 0.9968\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0132 - val_accuracy: 0.9972\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0071 - val_accuracy: 0.9979\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0106 - val_accuracy: 0.9979\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0110 - val_accuracy: 0.9976\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0093 - val_accuracy: 0.9979\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0138 - val_accuracy: 0.9973\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0099 - val_accuracy: 0.9979\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0096 - val_accuracy: 0.9979\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0145 - val_accuracy: 0.9975\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0099 - val_accuracy: 0.9979\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0108 - val_accuracy: 0.9973\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0181 - val_accuracy: 0.9965\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0101 - val_accuracy: 0.9977\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0097 - val_accuracy: 0.9979\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0073 - val_accuracy: 0.9982\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0260 - val_accuracy: 0.9961\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0130 - val_accuracy: 0.9970\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0080 - val_accuracy: 0.9983\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0145 - val_accuracy: 0.9974\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0083 - val_accuracy: 0.9980\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0290 - val_accuracy: 0.9959\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0106 - val_accuracy: 0.9980\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0081 - val_accuracy: 0.9983\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0099 - val_accuracy: 0.9981\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0075 - val_accuracy: 0.9983\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0171 - val_accuracy: 0.9973\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0101 - val_accuracy: 0.9979\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0107 - val_accuracy: 0.9980\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0107 - val_accuracy: 0.9980\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0090 - val_accuracy: 0.9983\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0145 - val_accuracy: 0.9977\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0092 - val_accuracy: 0.9974\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0086 - val_accuracy: 0.9979\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0107 - val_accuracy: 0.9981\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0122 - val_accuracy: 0.9977\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0091 - val_accuracy: 0.9981\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0089 - val_accuracy: 0.9979\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0152 - val_accuracy: 0.9975\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0130 - val_accuracy: 0.9977\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0392 - val_accuracy: 0.9954\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0098 - val_accuracy: 0.9977\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0078 - val_accuracy: 0.9980\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0135 - val_accuracy: 0.9975\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0087 - val_accuracy: 0.9984\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0142 - val_accuracy: 0.9974\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0362 - val_accuracy: 0.9949\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0089 - val_accuracy: 0.9977\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0132 - val_accuracy: 0.9975\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0138 - val_accuracy: 0.9975\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0160 - val_accuracy: 0.9969\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0097 - val_accuracy: 0.9979\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0129 - val_accuracy: 0.9979\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0160 - val_accuracy: 0.9969\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0126 - val_accuracy: 0.9980\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0157 - val_accuracy: 0.9974\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0119 - val_accuracy: 0.9977\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0090 - val_accuracy: 0.9981\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0113 - val_accuracy: 0.9979\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0268 - val_accuracy: 0.9963\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0134 - val_accuracy: 0.9977\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0319 - val_accuracy: 0.9942\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0099 - val_accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–„â–…â–†â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–…â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–ƒâ–…â–†â–‡â–…â–†â–‡â–†â–…â–…â–†â–…â–†â–‡â–†â–†â–„â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–‡â–ˆâ–†â–‡â–ˆâ–†â–â–…â–…â–†â–‡â–‡â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ƒâ–‚â–‚â–â–‚â–â–â–â–ƒâ–ƒâ–â–„â–ƒâ–‚â–‚â–â–â–â–‚â–â–…â–‚â–â–ƒâ–‚â–‚â–â–â–‚â–â–â–â–‚â–â–‚â–â–‚â–‚â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99899</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00185</td></tr><tr><td>batch/loss</td><td>0.00456</td></tr><tr><td>epoch/accuracy</td><td>0.99899</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00185</td></tr><tr><td>epoch/loss</td><td>0.00456</td></tr><tr><td>epoch/val_accuracy</td><td>0.99795</td></tr><tr><td>epoch/val_loss</td><td>0.00988</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_36</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/lobpsnm2' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/lobpsnm2</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_060058-lobpsnm2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 06:13:50,549] Trial 36 finished with value: 0.005429690447635948 and parameters: {'Layer_1_units': 114, 'Activation_1': 'relu', 'n_layers': 4, 'Layer_2_units': 128, 'Activation_2': 'relu', 'Layer_3_units': 104, 'Activation_3': 'sigmoid', 'Layer_4_units': 81, 'Activation_4': 'relu', 'Layer_5_units': 85, 'Activation_5': 'relu', 'learning_rate': 0.001845566786382882, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 34 with value: 0.0021758171962574123.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_061350-1oqrw7x6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/1oqrw7x6' target=\"_blank\">Trial_37</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/1oqrw7x6' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/1oqrw7x6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 7s 977us/step - loss: 0.0684 - accuracy: 0.9758 - val_loss: 0.0360 - val_accuracy: 0.9915\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 7s 963us/step - loss: 0.0198 - accuracy: 0.9947 - val_loss: 0.0217 - val_accuracy: 0.9947\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 7s 963us/step - loss: 0.0157 - accuracy: 0.9959 - val_loss: 0.0093 - val_accuracy: 0.9969\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.0110 - val_accuracy: 0.9965\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 7s 975us/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.0214 - val_accuracy: 0.9949\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.0116 - val_accuracy: 0.9967\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0091 - val_accuracy: 0.9963\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.0073 - val_accuracy: 0.9983\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.0069 - val_accuracy: 0.9976\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.0388 - val_accuracy: 0.9935\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0100 - accuracy: 0.9975 - val_loss: 0.0134 - val_accuracy: 0.9972\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.0151 - val_accuracy: 0.9966\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 7s 958us/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.0065 - val_accuracy: 0.9978\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.0310 - val_accuracy: 0.9936\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.0095 - val_accuracy: 0.9979\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 7s 958us/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.0088 - val_accuracy: 0.9976\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 7s 956us/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0295 - val_accuracy: 0.9949\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.0087 - val_accuracy: 0.9978\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0115 - val_accuracy: 0.9967\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.0260 - val_accuracy: 0.9955\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.0051 - val_accuracy: 0.9983\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 0.0084 - val_accuracy: 0.9979\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 7s 967us/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0078 - val_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 7s 958us/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0505 - val_accuracy: 0.9890\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 7s 965us/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0088 - val_accuracy: 0.9975\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9985\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.0059 - val_accuracy: 0.9982\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 7s 963us/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.0119 - val_accuracy: 0.9973\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 7s 963us/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.0132 - val_accuracy: 0.9974\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0074 - val_accuracy: 0.9979\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0055 - val_accuracy: 0.9982\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0131 - val_accuracy: 0.9972\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.0115 - val_accuracy: 0.9974\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.0076 - val_accuracy: 0.9983\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 7s 963us/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 7s 965us/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.0071 - val_accuracy: 0.9985\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0090 - val_accuracy: 0.9983\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 7s 965us/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0039 - val_accuracy: 0.9986\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 7s 967us/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0093 - val_accuracy: 0.9975\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 7s 963us/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0071 - val_accuracy: 0.9982\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0067 - val_accuracy: 0.9982\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0109 - val_accuracy: 0.9977\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 7s 965us/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0050 - val_accuracy: 0.9988\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0105 - val_accuracy: 0.9981\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0125 - val_accuracy: 0.9975\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0069 - val_accuracy: 0.9984\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0081 - val_accuracy: 0.9980\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0123 - val_accuracy: 0.9979\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 7s 958us/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0052 - val_accuracy: 0.9984\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 7s 963us/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0043 - val_accuracy: 0.9985\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 7s 957us/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.0064 - val_accuracy: 0.9984\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 7s 966us/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 7s 963us/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0153 - val_accuracy: 0.9967\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0134 - val_accuracy: 0.9973\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.1002 - val_accuracy: 0.9726\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0068 - val_accuracy: 0.9983\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0038 - val_accuracy: 0.9989\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0050 - val_accuracy: 0.9988\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0156 - val_accuracy: 0.9973\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0094 - val_accuracy: 0.9976\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 7s 966us/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0298 - val_accuracy: 0.9955\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0045 - val_accuracy: 0.9988\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 7s 963us/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 7s 965us/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0328 - val_accuracy: 0.9948\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 7s 965us/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0142 - val_accuracy: 0.9969\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 7s 967us/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0041 - val_accuracy: 0.9989\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0050 - val_accuracy: 0.9991\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0068 - val_accuracy: 0.9983\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 7s 956us/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0072 - val_accuracy: 0.9984\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0107 - val_accuracy: 0.9983\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0141 - val_accuracy: 0.9975\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0138 - val_accuracy: 0.9976\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0075 - val_accuracy: 0.9983\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0133 - val_accuracy: 0.9973\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0078 - val_accuracy: 0.9982\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0085 - val_accuracy: 0.9984\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0043 - val_accuracy: 0.9990\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 7s 962us/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0084 - val_accuracy: 0.9985\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 7s 968us/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0071 - val_accuracy: 0.9985\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0097 - val_accuracy: 0.9979\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 7s 965us/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0122 - val_accuracy: 0.9979\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0090 - val_accuracy: 0.9987\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 7s 959us/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 7s 963us/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0122 - val_accuracy: 0.9976\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0093 - val_accuracy: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–‚â–…â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–…â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–…</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ƒâ–‚â–‚â–‚â–‚â–„â–‚â–â–ƒâ–ƒâ–„â–â–‚â–â–â–â–â–â–â–â–â–â–‚â–ˆâ–â–â–‚â–ƒâ–‚â–â–â–â–‚â–â–â–â–â–â–‚â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99864</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00593</td></tr><tr><td>batch/loss</td><td>0.0059</td></tr><tr><td>epoch/accuracy</td><td>0.99864</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00593</td></tr><tr><td>epoch/loss</td><td>0.0059</td></tr><tr><td>epoch/val_accuracy</td><td>0.99815</td></tr><tr><td>epoch/val_loss</td><td>0.00932</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_37</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/1oqrw7x6' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/1oqrw7x6</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_061350-1oqrw7x6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 06:25:07,038] Trial 37 finished with value: 0.002382646361365914 and parameters: {'Layer_1_units': 78, 'Activation_1': 'sigmoid', 'n_layers': 3, 'Layer_2_units': 110, 'Activation_2': 'relu', 'Layer_3_units': 87, 'Activation_3': 'sigmoid', 'Layer_4_units': 42, 'Activation_4': 'relu', 'learning_rate': 0.0059299351418172375, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 34 with value: 0.0021758171962574123.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_062507-s8x6dw49</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/s8x6dw49' target=\"_blank\">Trial_38</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/s8x6dw49' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/s8x6dw49</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/7000 [..............................] - ETA: 35:06 - loss: 0.7007 - accuracy: 0.6500WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0006s). Check your callbacks.\n",
      "7000/7000 [==============================] - 6s 879us/step - loss: 0.5565 - accuracy: 0.7692 - val_loss: 0.5543 - val_accuracy: 0.7689\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 6s 861us/step - loss: 0.5437 - accuracy: 0.7692 - val_loss: 0.5117 - val_accuracy: 0.7689\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 6s 863us/step - loss: 0.2882 - accuracy: 0.8793 - val_loss: 0.1589 - val_accuracy: 0.9409\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 6s 861us/step - loss: 0.1539 - accuracy: 0.9427 - val_loss: 0.1488 - val_accuracy: 0.9435\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 6s 863us/step - loss: 0.1474 - accuracy: 0.9449 - val_loss: 0.1427 - val_accuracy: 0.9468\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.1408 - accuracy: 0.9479 - val_loss: 0.1357 - val_accuracy: 0.9514\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.1294 - accuracy: 0.9542 - val_loss: 0.1216 - val_accuracy: 0.9583\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.1133 - accuracy: 0.9625 - val_loss: 0.1059 - val_accuracy: 0.9664\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0990 - accuracy: 0.9698 - val_loss: 0.0948 - val_accuracy: 0.9729\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 6s 857us/step - loss: 0.0895 - accuracy: 0.9753 - val_loss: 0.0870 - val_accuracy: 0.9770\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0824 - accuracy: 0.9789 - val_loss: 0.0799 - val_accuracy: 0.9810\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0756 - accuracy: 0.9823 - val_loss: 0.0732 - val_accuracy: 0.9844\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 6s 862us/step - loss: 0.0680 - accuracy: 0.9854 - val_loss: 0.0658 - val_accuracy: 0.9858\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0599 - accuracy: 0.9878 - val_loss: 0.0587 - val_accuracy: 0.9872\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0510 - accuracy: 0.9907 - val_loss: 0.0476 - val_accuracy: 0.9926\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 6s 862us/step - loss: 0.0428 - accuracy: 0.9932 - val_loss: 0.0409 - val_accuracy: 0.9940\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 6s 857us/step - loss: 0.0365 - accuracy: 0.9950 - val_loss: 0.0355 - val_accuracy: 0.9956\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 6s 864us/step - loss: 0.0320 - accuracy: 0.9964 - val_loss: 0.0319 - val_accuracy: 0.9962\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 6s 857us/step - loss: 0.0294 - accuracy: 0.9972 - val_loss: 0.0300 - val_accuracy: 0.9967\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0276 - accuracy: 0.9976 - val_loss: 0.0293 - val_accuracy: 0.9969\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0265 - accuracy: 0.9977 - val_loss: 0.0269 - val_accuracy: 0.9975\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0256 - accuracy: 0.9980 - val_loss: 0.0263 - val_accuracy: 0.9976\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 6s 861us/step - loss: 0.0249 - accuracy: 0.9982 - val_loss: 0.0262 - val_accuracy: 0.9974\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0243 - accuracy: 0.9983 - val_loss: 0.0254 - val_accuracy: 0.9980\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 6s 861us/step - loss: 0.0238 - accuracy: 0.9983 - val_loss: 0.0248 - val_accuracy: 0.9977\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0233 - accuracy: 0.9984 - val_loss: 0.0246 - val_accuracy: 0.9972\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0230 - accuracy: 0.9983 - val_loss: 0.0244 - val_accuracy: 0.9977\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0225 - accuracy: 0.9985 - val_loss: 0.0235 - val_accuracy: 0.9982\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0221 - accuracy: 0.9986 - val_loss: 0.0233 - val_accuracy: 0.9976\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0218 - accuracy: 0.9986 - val_loss: 0.0232 - val_accuracy: 0.9979\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0213 - accuracy: 0.9987 - val_loss: 0.0239 - val_accuracy: 0.9976\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0211 - accuracy: 0.9987 - val_loss: 0.0223 - val_accuracy: 0.9976\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 6s 866us/step - loss: 0.0208 - accuracy: 0.9987 - val_loss: 0.0219 - val_accuracy: 0.9980\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0205 - accuracy: 0.9987 - val_loss: 0.0222 - val_accuracy: 0.9977\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0202 - accuracy: 0.9987 - val_loss: 0.0212 - val_accuracy: 0.9981\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 6s 861us/step - loss: 0.0198 - accuracy: 0.9988 - val_loss: 0.0212 - val_accuracy: 0.9978\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 6s 861us/step - loss: 0.0195 - accuracy: 0.9989 - val_loss: 0.0205 - val_accuracy: 0.9984\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0194 - accuracy: 0.9988 - val_loss: 0.0212 - val_accuracy: 0.9979\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0190 - accuracy: 0.9989 - val_loss: 0.0204 - val_accuracy: 0.9979\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0188 - accuracy: 0.9990 - val_loss: 0.0201 - val_accuracy: 0.9983\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 7s 930us/step - loss: 0.0186 - accuracy: 0.9990 - val_loss: 0.0200 - val_accuracy: 0.9980\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 6s 883us/step - loss: 0.0183 - accuracy: 0.9990 - val_loss: 0.0194 - val_accuracy: 0.9984\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 6s 871us/step - loss: 0.0181 - accuracy: 0.9991 - val_loss: 0.0203 - val_accuracy: 0.9981\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0178 - accuracy: 0.9991 - val_loss: 0.0202 - val_accuracy: 0.9975\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 6s 861us/step - loss: 0.0176 - accuracy: 0.9991 - val_loss: 0.0199 - val_accuracy: 0.9974\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0174 - accuracy: 0.9991 - val_loss: 0.0191 - val_accuracy: 0.9982\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0172 - accuracy: 0.9991 - val_loss: 0.0186 - val_accuracy: 0.9981\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 6s 862us/step - loss: 0.0170 - accuracy: 0.9991 - val_loss: 0.0183 - val_accuracy: 0.9980\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 6s 863us/step - loss: 0.0168 - accuracy: 0.9993 - val_loss: 0.0183 - val_accuracy: 0.9980\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0166 - accuracy: 0.9992 - val_loss: 0.0182 - val_accuracy: 0.9981\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0164 - accuracy: 0.9992 - val_loss: 0.0185 - val_accuracy: 0.9980\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 6s 870us/step - loss: 0.0162 - accuracy: 0.9992 - val_loss: 0.0178 - val_accuracy: 0.9983\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0161 - accuracy: 0.9992 - val_loss: 0.0174 - val_accuracy: 0.9984\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0159 - accuracy: 0.9992 - val_loss: 0.0173 - val_accuracy: 0.9980\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0157 - accuracy: 0.9992 - val_loss: 0.0174 - val_accuracy: 0.9980\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0155 - accuracy: 0.9994 - val_loss: 0.0182 - val_accuracy: 0.9980\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0154 - accuracy: 0.9992 - val_loss: 0.0168 - val_accuracy: 0.9982\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0152 - accuracy: 0.9993 - val_loss: 0.0168 - val_accuracy: 0.9983\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0151 - accuracy: 0.9993 - val_loss: 0.0163 - val_accuracy: 0.9985\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0149 - accuracy: 0.9993 - val_loss: 0.0167 - val_accuracy: 0.9980\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0147 - accuracy: 0.9993 - val_loss: 0.0162 - val_accuracy: 0.9984\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0146 - accuracy: 0.9994 - val_loss: 0.0160 - val_accuracy: 0.9984\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0145 - accuracy: 0.9993 - val_loss: 0.0162 - val_accuracy: 0.9980\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 6s 854us/step - loss: 0.0143 - accuracy: 0.9994 - val_loss: 0.0157 - val_accuracy: 0.9986\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0142 - accuracy: 0.9993 - val_loss: 0.0158 - val_accuracy: 0.9983\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0141 - accuracy: 0.9995 - val_loss: 0.0156 - val_accuracy: 0.9984\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 6s 857us/step - loss: 0.0139 - accuracy: 0.9995 - val_loss: 0.0162 - val_accuracy: 0.9979\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0138 - accuracy: 0.9994 - val_loss: 0.0153 - val_accuracy: 0.9983\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0137 - accuracy: 0.9994 - val_loss: 0.0160 - val_accuracy: 0.9983\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 6s 864us/step - loss: 0.0135 - accuracy: 0.9994 - val_loss: 0.0147 - val_accuracy: 0.9988\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 6s 862us/step - loss: 0.0134 - accuracy: 0.9995 - val_loss: 0.0148 - val_accuracy: 0.9985\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 6s 867us/step - loss: 0.0133 - accuracy: 0.9994 - val_loss: 0.0148 - val_accuracy: 0.9984\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0132 - accuracy: 0.9995 - val_loss: 0.0145 - val_accuracy: 0.9987\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 6s 861us/step - loss: 0.0131 - accuracy: 0.9995 - val_loss: 0.0146 - val_accuracy: 0.9984\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 6s 874us/step - loss: 0.0129 - accuracy: 0.9995 - val_loss: 0.0147 - val_accuracy: 0.9980\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0128 - accuracy: 0.9996 - val_loss: 0.0145 - val_accuracy: 0.9984\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0127 - accuracy: 0.9995 - val_loss: 0.0144 - val_accuracy: 0.9984\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 6s 862us/step - loss: 0.0126 - accuracy: 0.9995 - val_loss: 0.0144 - val_accuracy: 0.9986\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0125 - accuracy: 0.9995 - val_loss: 0.0145 - val_accuracy: 0.9981\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 6s 860us/step - loss: 0.0125 - accuracy: 0.9995 - val_loss: 0.0140 - val_accuracy: 0.9987\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0124 - accuracy: 0.9995 - val_loss: 0.0148 - val_accuracy: 0.9981\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0122 - accuracy: 0.9995 - val_loss: 0.0139 - val_accuracy: 0.9984\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0121 - accuracy: 0.9995 - val_loss: 0.0138 - val_accuracy: 0.9983\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 6s 861us/step - loss: 0.0121 - accuracy: 0.9995 - val_loss: 0.0137 - val_accuracy: 0.9983\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 6s 861us/step - loss: 0.0120 - accuracy: 0.9995 - val_loss: 0.0133 - val_accuracy: 0.9987\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0119 - accuracy: 0.9995 - val_loss: 0.0137 - val_accuracy: 0.9983\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0118 - accuracy: 0.9995 - val_loss: 0.0135 - val_accuracy: 0.9984\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 6s 857us/step - loss: 0.0117 - accuracy: 0.9996 - val_loss: 0.0133 - val_accuracy: 0.9986\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0116 - accuracy: 0.9996 - val_loss: 0.0132 - val_accuracy: 0.9985\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0115 - accuracy: 0.9997 - val_loss: 0.0131 - val_accuracy: 0.9983\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0114 - accuracy: 0.9996 - val_loss: 0.0133 - val_accuracy: 0.9984\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 6s 863us/step - loss: 0.0114 - accuracy: 0.9996 - val_loss: 0.0130 - val_accuracy: 0.9984\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 6s 861us/step - loss: 0.0113 - accuracy: 0.9996 - val_loss: 0.0128 - val_accuracy: 0.9987\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0112 - accuracy: 0.9996 - val_loss: 0.0131 - val_accuracy: 0.9984\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 6s 865us/step - loss: 0.0112 - accuracy: 0.9996 - val_loss: 0.0127 - val_accuracy: 0.9984\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0111 - accuracy: 0.9996 - val_loss: 0.0130 - val_accuracy: 0.9983\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 6s 862us/step - loss: 0.0111 - accuracy: 0.9996 - val_loss: 0.0127 - val_accuracy: 0.9984\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 6s 863us/step - loss: 0.0109 - accuracy: 0.9996 - val_loss: 0.0127 - val_accuracy: 0.9985\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 6s 861us/step - loss: 0.0109 - accuracy: 0.9996 - val_loss: 0.0128 - val_accuracy: 0.9981\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 6s 862us/step - loss: 0.0108 - accuracy: 0.9996 - val_loss: 0.0125 - val_accuracy: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–…â–„â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–†â–…â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‡â–‡â–…â–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99961</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00869</td></tr><tr><td>batch/loss</td><td>0.01081</td></tr><tr><td>epoch/accuracy</td><td>0.99961</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00869</td></tr><tr><td>epoch/loss</td><td>0.01081</td></tr><tr><td>epoch/val_accuracy</td><td>0.99865</td></tr><tr><td>epoch/val_loss</td><td>0.01247</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_38</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/s8x6dw49' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/s8x6dw49</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_062507-s8x6dw49/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 06:35:12,001] Trial 38 finished with value: 0.012304545566439628 and parameters: {'Layer_1_units': 62, 'Activation_1': 'sigmoid', 'n_layers': 3, 'Layer_2_units': 122, 'Activation_2': 'relu', 'Layer_3_units': 34, 'Activation_3': 'sigmoid', 'Layer_4_units': 42, 'Activation_4': 'sigmoid', 'learning_rate': 0.008692565710536533, 'optimizer': 'sgd', 'batch_size': 20}. Best is trial 34 with value: 0.0021758171962574123.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_063512-mv91xzay</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/mv91xzay' target=\"_blank\">Trial_39</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/mv91xzay' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/mv91xzay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3500/3500 [==============================] - 4s 961us/step - loss: 0.0511 - accuracy: 0.9816 - val_loss: 0.0171 - val_accuracy: 0.9947\n",
      "Epoch 2/100\n",
      "3500/3500 [==============================] - 3s 934us/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0119 - val_accuracy: 0.9964\n",
      "Epoch 3/100\n",
      "3500/3500 [==============================] - 3s 936us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9952\n",
      "Epoch 4/100\n",
      "3500/3500 [==============================] - 3s 932us/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0070 - val_accuracy: 0.9974\n",
      "Epoch 5/100\n",
      "3500/3500 [==============================] - 3s 937us/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0082 - val_accuracy: 0.9972\n",
      "Epoch 6/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0103 - val_accuracy: 0.9966\n",
      "Epoch 7/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0096 - val_accuracy: 0.9977\n",
      "Epoch 8/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0102 - val_accuracy: 0.9969\n",
      "Epoch 9/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0085 - val_accuracy: 0.9973\n",
      "Epoch 10/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0097 - val_accuracy: 0.9973\n",
      "Epoch 11/100\n",
      "3500/3500 [==============================] - 3s 920us/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0114 - val_accuracy: 0.9973\n",
      "Epoch 12/100\n",
      "3500/3500 [==============================] - 3s 934us/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0121 - val_accuracy: 0.9966\n",
      "Epoch 13/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0095 - val_accuracy: 0.9976\n",
      "Epoch 14/100\n",
      "3500/3500 [==============================] - 3s 929us/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0157 - val_accuracy: 0.9962\n",
      "Epoch 15/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0104 - val_accuracy: 0.9976\n",
      "Epoch 16/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0092 - val_accuracy: 0.9976\n",
      "Epoch 17/100\n",
      "3500/3500 [==============================] - 3s 928us/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0172 - val_accuracy: 0.9972\n",
      "Epoch 18/100\n",
      "3500/3500 [==============================] - 3s 927us/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0073 - val_accuracy: 0.9977\n",
      "Epoch 19/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0087 - val_accuracy: 0.9977\n",
      "Epoch 20/100\n",
      "3500/3500 [==============================] - 3s 927us/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0122 - val_accuracy: 0.9971\n",
      "Epoch 21/100\n",
      "3500/3500 [==============================] - 3s 941us/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
      "Epoch 22/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0124 - val_accuracy: 0.9972\n",
      "Epoch 23/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0096 - val_accuracy: 0.9977\n",
      "Epoch 24/100\n",
      "3500/3500 [==============================] - 3s 934us/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0115 - val_accuracy: 0.9971\n",
      "Epoch 25/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0136 - val_accuracy: 0.9966\n",
      "Epoch 26/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0164 - val_accuracy: 0.9968\n",
      "Epoch 27/100\n",
      "3500/3500 [==============================] - 3s 932us/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0075 - val_accuracy: 0.9984\n",
      "Epoch 28/100\n",
      "3500/3500 [==============================] - 3s 936us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0123 - val_accuracy: 0.9973\n",
      "Epoch 29/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0090 - val_accuracy: 0.9979\n",
      "Epoch 30/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0063 - val_accuracy: 0.9983\n",
      "Epoch 31/100\n",
      "3500/3500 [==============================] - 3s 932us/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0124 - val_accuracy: 0.9974\n",
      "Epoch 32/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0098 - val_accuracy: 0.9983\n",
      "Epoch 33/100\n",
      "3500/3500 [==============================] - 3s 935us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0104 - val_accuracy: 0.9980\n",
      "Epoch 34/100\n",
      "3500/3500 [==============================] - 3s 929us/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0117 - val_accuracy: 0.9975\n",
      "Epoch 35/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0089 - val_accuracy: 0.9979\n",
      "Epoch 36/100\n",
      "3500/3500 [==============================] - 3s 935us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0076 - val_accuracy: 0.9979\n",
      "Epoch 37/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0149 - val_accuracy: 0.9970\n",
      "Epoch 38/100\n",
      "3500/3500 [==============================] - 3s 929us/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0091 - val_accuracy: 0.9974\n",
      "Epoch 39/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0130 - val_accuracy: 0.9978\n",
      "Epoch 40/100\n",
      "3500/3500 [==============================] - 3s 929us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0111 - val_accuracy: 0.9974\n",
      "Epoch 41/100\n",
      "3500/3500 [==============================] - 3s 928us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0143 - val_accuracy: 0.9974\n",
      "Epoch 42/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0110 - val_accuracy: 0.9980\n",
      "Epoch 43/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0103 - val_accuracy: 0.9979\n",
      "Epoch 44/100\n",
      "3500/3500 [==============================] - 3s 919us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0074 - val_accuracy: 0.9981\n",
      "Epoch 45/100\n",
      "3500/3500 [==============================] - 3s 928us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0119 - val_accuracy: 0.9980\n",
      "Epoch 46/100\n",
      "3500/3500 [==============================] - 3s 934us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0106 - val_accuracy: 0.9974\n",
      "Epoch 47/100\n",
      "3500/3500 [==============================] - 3s 937us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0093 - val_accuracy: 0.9980\n",
      "Epoch 48/100\n",
      "3500/3500 [==============================] - 3s 929us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0083 - val_accuracy: 0.9979\n",
      "Epoch 49/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0069 - val_accuracy: 0.9982\n",
      "Epoch 50/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0147 - val_accuracy: 0.9972\n",
      "Epoch 51/100\n",
      "3500/3500 [==============================] - 3s 936us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0080 - val_accuracy: 0.9977\n",
      "Epoch 52/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0094 - val_accuracy: 0.9977\n",
      "Epoch 53/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0083 - val_accuracy: 0.9982\n",
      "Epoch 54/100\n",
      "3500/3500 [==============================] - 3s 932us/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0117 - val_accuracy: 0.9980\n",
      "Epoch 55/100\n",
      "3500/3500 [==============================] - 3s 935us/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0072 - val_accuracy: 0.9979\n",
      "Epoch 56/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0113 - val_accuracy: 0.9976\n",
      "Epoch 57/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0197 - val_accuracy: 0.9969\n",
      "Epoch 58/100\n",
      "3500/3500 [==============================] - 3s 944us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0107 - val_accuracy: 0.9974\n",
      "Epoch 59/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0135 - val_accuracy: 0.9974\n",
      "Epoch 60/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0077 - val_accuracy: 0.9979\n",
      "Epoch 61/100\n",
      "3500/3500 [==============================] - 3s 928us/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0087 - val_accuracy: 0.9983\n",
      "Epoch 62/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0094 - val_accuracy: 0.9979\n",
      "Epoch 63/100\n",
      "3500/3500 [==============================] - 3s 932us/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9985\n",
      "Epoch 64/100\n",
      "3500/3500 [==============================] - 3s 942us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0104 - val_accuracy: 0.9975\n",
      "Epoch 65/100\n",
      "3500/3500 [==============================] - 3s 936us/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0125 - val_accuracy: 0.9977\n",
      "Epoch 66/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0181 - val_accuracy: 0.9970\n",
      "Epoch 67/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0113 - val_accuracy: 0.9977\n",
      "Epoch 68/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0108 - val_accuracy: 0.9977\n",
      "Epoch 69/100\n",
      "3500/3500 [==============================] - 3s 934us/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 0.9983\n",
      "Epoch 70/100\n",
      "3500/3500 [==============================] - 3s 934us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0091 - val_accuracy: 0.9982\n",
      "Epoch 71/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0173 - val_accuracy: 0.9969\n",
      "Epoch 72/100\n",
      "3500/3500 [==============================] - 3s 929us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0125 - val_accuracy: 0.9969\n",
      "Epoch 73/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0087 - val_accuracy: 0.9982\n",
      "Epoch 74/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0085 - val_accuracy: 0.9981\n",
      "Epoch 75/100\n",
      "3500/3500 [==============================] - 3s 934us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
      "Epoch 76/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0086 - val_accuracy: 0.9981\n",
      "Epoch 77/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0090 - val_accuracy: 0.9983\n",
      "Epoch 78/100\n",
      "3500/3500 [==============================] - 3s 932us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0233 - val_accuracy: 0.9966\n",
      "Epoch 79/100\n",
      "3500/3500 [==============================] - 3s 934us/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0083 - val_accuracy: 0.9982\n",
      "Epoch 80/100\n",
      "3500/3500 [==============================] - 3s 934us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0094 - val_accuracy: 0.9984\n",
      "Epoch 81/100\n",
      "3500/3500 [==============================] - 3s 935us/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0135 - val_accuracy: 0.9972\n",
      "Epoch 82/100\n",
      "3500/3500 [==============================] - 3s 935us/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0103 - val_accuracy: 0.9978\n",
      "Epoch 83/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0103 - val_accuracy: 0.9977\n",
      "Epoch 84/100\n",
      "3500/3500 [==============================] - 3s 934us/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0092 - val_accuracy: 0.9981\n",
      "Epoch 85/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0083 - val_accuracy: 0.9985\n",
      "Epoch 86/100\n",
      "3500/3500 [==============================] - 3s 928us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0096 - val_accuracy: 0.9979\n",
      "Epoch 87/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0142 - val_accuracy: 0.9976\n",
      "Epoch 88/100\n",
      "3500/3500 [==============================] - 3s 934us/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0084 - val_accuracy: 0.9983\n",
      "Epoch 89/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0080 - val_accuracy: 0.9978\n",
      "Epoch 90/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0183 - val_accuracy: 0.9970\n",
      "Epoch 91/100\n",
      "3500/3500 [==============================] - 3s 934us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0077 - val_accuracy: 0.9983\n",
      "Epoch 92/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0353 - val_accuracy: 0.9925\n",
      "Epoch 93/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0086 - val_accuracy: 0.9984\n",
      "Epoch 94/100\n",
      "3500/3500 [==============================] - 3s 971us/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0117 - val_accuracy: 0.9979\n",
      "Epoch 95/100\n",
      "3500/3500 [==============================] - 3s 941us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0109 - val_accuracy: 0.9973\n",
      "Epoch 96/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0097 - val_accuracy: 0.9981\n",
      "Epoch 97/100\n",
      "3500/3500 [==============================] - 3s 934us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0138 - val_accuracy: 0.9974\n",
      "Epoch 98/100\n",
      "3500/3500 [==============================] - 3s 933us/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0134 - val_accuracy: 0.9979\n",
      "Epoch 99/100\n",
      "3500/3500 [==============================] - 3s 930us/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0159 - val_accuracy: 0.9974\n",
      "Epoch 100/100\n",
      "3500/3500 [==============================] - 3s 931us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0102 - val_accuracy: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–‚â–…â–ƒâ–…â–…â–†â–†â–†â–…â–†â–‡â–†â–†â–‡â–‡â–†â–‡â–†â–‡â–†â–‡â–…â–ˆâ–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–‡â–†â–‡â–‡â–‡â–‡â–†â–†â–ˆâ–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–â–‡â–‡â–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–‡â–‚â–ƒâ–ƒâ–„â–†â–ƒâ–‡â–„â–‚â–‚â–â–„â–ƒâ–„â–…â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–…â–‚â–‚â–ˆâ–ƒâ–‚â–ƒâ–‡â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–…â–ƒâ–ƒ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99922</td></tr><tr><td>batch/batch_step</td><td>349995</td></tr><tr><td>batch/learning_rate</td><td>0.00513</td></tr><tr><td>batch/loss</td><td>0.00293</td></tr><tr><td>epoch/accuracy</td><td>0.99922</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00513</td></tr><tr><td>epoch/loss</td><td>0.00293</td></tr><tr><td>epoch/val_accuracy</td><td>0.99815</td></tr><tr><td>epoch/val_loss</td><td>0.01023</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_39</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/mv91xzay' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/mv91xzay</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_063512-mv91xzay/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 06:40:41,013] Trial 39 finished with value: 0.005858353828079999 and parameters: {'Layer_1_units': 74, 'Activation_1': 'relu', 'n_layers': 2, 'Layer_2_units': 110, 'Activation_2': 'relu', 'Layer_3_units': 56, 'Activation_3': 'sigmoid', 'learning_rate': 0.005126556104732452, 'optimizer': 'rmsprop', 'batch_size': 40}. Best is trial 34 with value: 0.0021758171962574123.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_064041-4jpha3y6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4jpha3y6' target=\"_blank\">Trial_40</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4jpha3y6' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4jpha3y6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 7s 917us/step - loss: 0.5607 - accuracy: 0.7692 - val_loss: 0.5529 - val_accuracy: 0.7689\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.5206 - accuracy: 0.7692 - val_loss: 0.4440 - val_accuracy: 0.7696\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.2804 - accuracy: 0.8923 - val_loss: 0.1855 - val_accuracy: 0.9338\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.1714 - accuracy: 0.9399 - val_loss: 0.1628 - val_accuracy: 0.9405\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.1616 - accuracy: 0.9420 - val_loss: 0.1589 - val_accuracy: 0.9430\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.1584 - accuracy: 0.9423 - val_loss: 0.1568 - val_accuracy: 0.9442\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.1567 - accuracy: 0.9436 - val_loss: 0.1552 - val_accuracy: 0.9459\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.1554 - accuracy: 0.9441 - val_loss: 0.1534 - val_accuracy: 0.9449\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.1540 - accuracy: 0.9445 - val_loss: 0.1515 - val_accuracy: 0.9462\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.1525 - accuracy: 0.9453 - val_loss: 0.1510 - val_accuracy: 0.9459\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.1506 - accuracy: 0.9461 - val_loss: 0.1475 - val_accuracy: 0.9481\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.1486 - accuracy: 0.9474 - val_loss: 0.1460 - val_accuracy: 0.9474\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.1458 - accuracy: 0.9485 - val_loss: 0.1434 - val_accuracy: 0.9503\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 6s 898us/step - loss: 0.1424 - accuracy: 0.9505 - val_loss: 0.1391 - val_accuracy: 0.9517\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.1378 - accuracy: 0.9527 - val_loss: 0.1343 - val_accuracy: 0.9536\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 6s 906us/step - loss: 0.1325 - accuracy: 0.9557 - val_loss: 0.1283 - val_accuracy: 0.9572\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.1261 - accuracy: 0.9589 - val_loss: 0.1224 - val_accuracy: 0.9593\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 6s 894us/step - loss: 0.1191 - accuracy: 0.9628 - val_loss: 0.1164 - val_accuracy: 0.9629\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 6s 897us/step - loss: 0.1121 - accuracy: 0.9660 - val_loss: 0.1117 - val_accuracy: 0.9647\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.1056 - accuracy: 0.9691 - val_loss: 0.1030 - val_accuracy: 0.9710\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 6s 897us/step - loss: 0.1002 - accuracy: 0.9730 - val_loss: 0.0986 - val_accuracy: 0.9747\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.0958 - accuracy: 0.9754 - val_loss: 0.0957 - val_accuracy: 0.9753\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.0922 - accuracy: 0.9774 - val_loss: 0.0938 - val_accuracy: 0.9785\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0889 - accuracy: 0.9799 - val_loss: 0.0892 - val_accuracy: 0.9805\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0857 - accuracy: 0.9812 - val_loss: 0.0882 - val_accuracy: 0.9800\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 6s 898us/step - loss: 0.0825 - accuracy: 0.9824 - val_loss: 0.0829 - val_accuracy: 0.9826\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.0794 - accuracy: 0.9839 - val_loss: 0.0807 - val_accuracy: 0.9834\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.0762 - accuracy: 0.9851 - val_loss: 0.0768 - val_accuracy: 0.9862\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.0727 - accuracy: 0.9864 - val_loss: 0.0726 - val_accuracy: 0.9874\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0689 - accuracy: 0.9874 - val_loss: 0.0684 - val_accuracy: 0.9881\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.0650 - accuracy: 0.9888 - val_loss: 0.0658 - val_accuracy: 0.9894\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 6s 906us/step - loss: 0.0609 - accuracy: 0.9899 - val_loss: 0.0610 - val_accuracy: 0.9905\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.0569 - accuracy: 0.9913 - val_loss: 0.0572 - val_accuracy: 0.9915\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.0531 - accuracy: 0.9921 - val_loss: 0.0527 - val_accuracy: 0.9927\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0495 - accuracy: 0.9933 - val_loss: 0.0504 - val_accuracy: 0.9926\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.0463 - accuracy: 0.9941 - val_loss: 0.0461 - val_accuracy: 0.9941\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.0435 - accuracy: 0.9951 - val_loss: 0.0446 - val_accuracy: 0.9952\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0412 - accuracy: 0.9957 - val_loss: 0.0417 - val_accuracy: 0.9955\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0393 - accuracy: 0.9962 - val_loss: 0.0401 - val_accuracy: 0.9958\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 6s 896us/step - loss: 0.0377 - accuracy: 0.9967 - val_loss: 0.0386 - val_accuracy: 0.9965\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.0365 - accuracy: 0.9971 - val_loss: 0.0373 - val_accuracy: 0.9965\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 6s 898us/step - loss: 0.0354 - accuracy: 0.9975 - val_loss: 0.0363 - val_accuracy: 0.9969\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0345 - accuracy: 0.9977 - val_loss: 0.0367 - val_accuracy: 0.9971\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0338 - accuracy: 0.9977 - val_loss: 0.0349 - val_accuracy: 0.9970\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.0332 - accuracy: 0.9980 - val_loss: 0.0345 - val_accuracy: 0.9972\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 6s 906us/step - loss: 0.0326 - accuracy: 0.9981 - val_loss: 0.0339 - val_accuracy: 0.9974\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 6s 898us/step - loss: 0.0322 - accuracy: 0.9982 - val_loss: 0.0344 - val_accuracy: 0.9966\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 6s 897us/step - loss: 0.0317 - accuracy: 0.9983 - val_loss: 0.0336 - val_accuracy: 0.9974\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.0314 - accuracy: 0.9983 - val_loss: 0.0327 - val_accuracy: 0.9974\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.0311 - accuracy: 0.9983 - val_loss: 0.0325 - val_accuracy: 0.9975\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.0307 - accuracy: 0.9983 - val_loss: 0.0325 - val_accuracy: 0.9975\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 6s 898us/step - loss: 0.0305 - accuracy: 0.9985 - val_loss: 0.0319 - val_accuracy: 0.9976\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.0301 - accuracy: 0.9987 - val_loss: 0.0321 - val_accuracy: 0.9972\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 6s 906us/step - loss: 0.0299 - accuracy: 0.9985 - val_loss: 0.0316 - val_accuracy: 0.9974\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0297 - accuracy: 0.9986 - val_loss: 0.0309 - val_accuracy: 0.9977\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.0295 - accuracy: 0.9985 - val_loss: 0.0313 - val_accuracy: 0.9976\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.0292 - accuracy: 0.9987 - val_loss: 0.0307 - val_accuracy: 0.9977\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.0290 - accuracy: 0.9987 - val_loss: 0.0304 - val_accuracy: 0.9979\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 6s 898us/step - loss: 0.0288 - accuracy: 0.9987 - val_loss: 0.0305 - val_accuracy: 0.9976\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0287 - accuracy: 0.9987 - val_loss: 0.0308 - val_accuracy: 0.9975\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 6s 896us/step - loss: 0.0285 - accuracy: 0.9987 - val_loss: 0.0303 - val_accuracy: 0.9978\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 6s 898us/step - loss: 0.0283 - accuracy: 0.9987 - val_loss: 0.0300 - val_accuracy: 0.9977\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 6s 896us/step - loss: 0.0281 - accuracy: 0.9987 - val_loss: 0.0298 - val_accuracy: 0.9977\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0279 - accuracy: 0.9988 - val_loss: 0.0293 - val_accuracy: 0.9977\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.0278 - accuracy: 0.9988 - val_loss: 0.0300 - val_accuracy: 0.9976\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 6s 897us/step - loss: 0.0275 - accuracy: 0.9989 - val_loss: 0.0291 - val_accuracy: 0.9980\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.0274 - accuracy: 0.9989 - val_loss: 0.0290 - val_accuracy: 0.9980\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 6s 898us/step - loss: 0.0272 - accuracy: 0.9989 - val_loss: 0.0289 - val_accuracy: 0.9977\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.0271 - accuracy: 0.9989 - val_loss: 0.0287 - val_accuracy: 0.9980\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.0269 - accuracy: 0.9990 - val_loss: 0.0288 - val_accuracy: 0.9977\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.0268 - accuracy: 0.9990 - val_loss: 0.0285 - val_accuracy: 0.9979\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.0266 - accuracy: 0.9989 - val_loss: 0.0285 - val_accuracy: 0.9979\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 6s 907us/step - loss: 0.0265 - accuracy: 0.9989 - val_loss: 0.0282 - val_accuracy: 0.9980\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0263 - accuracy: 0.9990 - val_loss: 0.0280 - val_accuracy: 0.9980\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.0262 - accuracy: 0.9990 - val_loss: 0.0279 - val_accuracy: 0.9979\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0260 - accuracy: 0.9991 - val_loss: 0.0282 - val_accuracy: 0.9980\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0259 - accuracy: 0.9991 - val_loss: 0.0274 - val_accuracy: 0.9980\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0258 - accuracy: 0.9991 - val_loss: 0.0285 - val_accuracy: 0.9976\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.0256 - accuracy: 0.9991 - val_loss: 0.0276 - val_accuracy: 0.9978\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 6s 898us/step - loss: 0.0255 - accuracy: 0.9990 - val_loss: 0.0272 - val_accuracy: 0.9981\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 6s 905us/step - loss: 0.0254 - accuracy: 0.9992 - val_loss: 0.0274 - val_accuracy: 0.9980\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0252 - accuracy: 0.9992 - val_loss: 0.0273 - val_accuracy: 0.9979\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.0251 - accuracy: 0.9993 - val_loss: 0.0268 - val_accuracy: 0.9982\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.0249 - accuracy: 0.9992 - val_loss: 0.0264 - val_accuracy: 0.9981\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0248 - accuracy: 0.9991 - val_loss: 0.0266 - val_accuracy: 0.9983\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 6s 903us/step - loss: 0.0247 - accuracy: 0.9993 - val_loss: 0.0263 - val_accuracy: 0.9982\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.0245 - accuracy: 0.9993 - val_loss: 0.0263 - val_accuracy: 0.9981\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.0244 - accuracy: 0.9993 - val_loss: 0.0264 - val_accuracy: 0.9980\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0243 - accuracy: 0.9993 - val_loss: 0.0261 - val_accuracy: 0.9981\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 6s 908us/step - loss: 0.0242 - accuracy: 0.9992 - val_loss: 0.0260 - val_accuracy: 0.9981\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0241 - accuracy: 0.9993 - val_loss: 0.0257 - val_accuracy: 0.9980\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.0239 - accuracy: 0.9993 - val_loss: 0.0257 - val_accuracy: 0.9981\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 6s 908us/step - loss: 0.0239 - accuracy: 0.9992 - val_loss: 0.0255 - val_accuracy: 0.9981\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.0237 - accuracy: 0.9993 - val_loss: 0.0256 - val_accuracy: 0.9980\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 6s 899us/step - loss: 0.0236 - accuracy: 0.9993 - val_loss: 0.0253 - val_accuracy: 0.9981\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 6s 902us/step - loss: 0.0235 - accuracy: 0.9993 - val_loss: 0.0254 - val_accuracy: 0.9981\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 6s 900us/step - loss: 0.0233 - accuracy: 0.9994 - val_loss: 0.0254 - val_accuracy: 0.9980\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 6s 904us/step - loss: 0.0233 - accuracy: 0.9993 - val_loss: 0.0251 - val_accuracy: 0.9981\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 6s 901us/step - loss: 0.0231 - accuracy: 0.9994 - val_loss: 0.0251 - val_accuracy: 0.9980\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 6s 898us/step - loss: 0.0230 - accuracy: 0.9994 - val_loss: 0.0248 - val_accuracy: 0.9982\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–â–â–ƒâ–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–„â–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99939</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00214</td></tr><tr><td>batch/loss</td><td>0.023</td></tr><tr><td>epoch/accuracy</td><td>0.99939</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00214</td></tr><tr><td>epoch/loss</td><td>0.023</td></tr><tr><td>epoch/val_accuracy</td><td>0.9982</td></tr><tr><td>epoch/val_loss</td><td>0.02478</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_40</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4jpha3y6' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/4jpha3y6</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_064041-4jpha3y6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 06:51:15,279] Trial 40 finished with value: 0.024601862579584122 and parameters: {'Layer_1_units': 80, 'Activation_1': 'sigmoid', 'n_layers': 3, 'Layer_2_units': 121, 'Activation_2': 'relu', 'Layer_3_units': 78, 'Activation_3': 'sigmoid', 'Layer_4_units': 89, 'Activation_4': 'relu', 'learning_rate': 0.002143702533115978, 'optimizer': 'sgd', 'batch_size': 20}. Best is trial 34 with value: 0.0021758171962574123.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_065115-yvcqf9t7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/yvcqf9t7' target=\"_blank\">Trial_41</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/yvcqf9t7' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/yvcqf9t7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 7s 950us/step - loss: 0.0549 - accuracy: 0.9804 - val_loss: 0.0205 - val_accuracy: 0.9943\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 7s 941us/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.0115 - val_accuracy: 0.9967\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.0131 - val_accuracy: 0.9966\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0076 - val_accuracy: 0.9977\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0116 - val_accuracy: 0.9973\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0070 - val_accuracy: 0.9977\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0389 - val_accuracy: 0.9930\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.0108 - val_accuracy: 0.9975\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0117 - val_accuracy: 0.9969\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 7s 940us/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0092 - val_accuracy: 0.9977\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.0074 - val_accuracy: 0.9979\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 7s 937us/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0074 - val_accuracy: 0.9981\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.0114 - val_accuracy: 0.9973\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0099 - val_accuracy: 0.9973\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.0060 - val_accuracy: 0.9983\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0057 - val_accuracy: 0.9980\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0126 - val_accuracy: 0.9970\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0065 - val_accuracy: 0.9981\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0057 - val_accuracy: 0.9986\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0068 - val_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0094 - val_accuracy: 0.9979\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0083 - val_accuracy: 0.9980\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0102 - val_accuracy: 0.9979\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.0069 - val_accuracy: 0.9985\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 7s 939us/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0072 - val_accuracy: 0.9980\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0098 - val_accuracy: 0.9976\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.0099 - val_accuracy: 0.9973\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0144 - val_accuracy: 0.9976\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0066 - val_accuracy: 0.9984\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0097 - val_accuracy: 0.9977\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0069 - val_accuracy: 0.9982\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0266 - val_accuracy: 0.9947\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.0082 - val_accuracy: 0.9979\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.0071 - val_accuracy: 0.9978\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0143 - val_accuracy: 0.9970\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.0107 - val_accuracy: 0.9973\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0070 - val_accuracy: 0.9987\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0182 - val_accuracy: 0.9966\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 7s 940us/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0079 - val_accuracy: 0.9984\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 7s 937us/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0144 - val_accuracy: 0.9972\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 7s 937us/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0072 - val_accuracy: 0.9983\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0078 - val_accuracy: 0.9984\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 7s 937us/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9986\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 7s 938us/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0083 - val_accuracy: 0.9983\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0055 - val_accuracy: 0.9986\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0089 - val_accuracy: 0.9982\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0118 - val_accuracy: 0.9977\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0065 - val_accuracy: 0.9984\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 7s 940us/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0196 - val_accuracy: 0.9966\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0040 - val_accuracy: 0.9990\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 7s 937us/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 7s 937us/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0077 - val_accuracy: 0.9984\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0069 - val_accuracy: 0.9981\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 7s 930us/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0090 - val_accuracy: 0.9981\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0476 - val_accuracy: 0.9920\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0113 - val_accuracy: 0.9976\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 7s 943us/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0131 - val_accuracy: 0.9979\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0053 - val_accuracy: 0.9986\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 7s 939us/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0083 - val_accuracy: 0.9984\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0048 - val_accuracy: 0.9988\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 7s 941us/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 7s 937us/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9986\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0101 - val_accuracy: 0.9982\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0042 - val_accuracy: 0.9989\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 7s 937us/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0074 - val_accuracy: 0.9984\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 7s 937us/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0161 - val_accuracy: 0.9958\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 7s 937us/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0105 - val_accuracy: 0.9983\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0218 - val_accuracy: 0.9960\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0120 - val_accuracy: 0.9976\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0164 - val_accuracy: 0.9966\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0078 - val_accuracy: 0.9984\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0033 - val_accuracy: 0.9991\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0061 - val_accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–â–ƒâ–„â–…â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–‚â–†â–†â–â–†â–†â–†â–‡â–†â–‡â–‡â–†â–†â–ƒâ–†â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–„â–„</td></tr><tr><td>epoch/val_loss</td><td>â–„â–‚â–‡â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–â–‚â–â–‚â–‚â–â–â–â–‚â–ˆâ–‚â–â–ƒâ–â–â–‚â–â–â–ƒâ–â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99901</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00987</td></tr><tr><td>batch/loss</td><td>0.00441</td></tr><tr><td>epoch/accuracy</td><td>0.99901</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00987</td></tr><tr><td>epoch/loss</td><td>0.00441</td></tr><tr><td>epoch/val_accuracy</td><td>0.9988</td></tr><tr><td>epoch/val_loss</td><td>0.0061</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_41</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/yvcqf9t7' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/yvcqf9t7</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_065115-yvcqf9t7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 07:02:13,525] Trial 41 finished with value: 0.002495984290726483 and parameters: {'Layer_1_units': 94, 'Activation_1': 'sigmoid', 'n_layers': 2, 'Layer_2_units': 109, 'Activation_2': 'relu', 'Layer_3_units': 88, 'Activation_3': 'sigmoid', 'learning_rate': 0.009866035207349095, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 34 with value: 0.0021758171962574123.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_070213-nwcbxn08</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/nwcbxn08' target=\"_blank\">Trial_42</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/nwcbxn08' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/nwcbxn08</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 7s 961us/step - loss: 0.0550 - accuracy: 0.9807 - val_loss: 0.0152 - val_accuracy: 0.9952\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0188 - val_accuracy: 0.9952\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.0105 - val_accuracy: 0.9965\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0129 - accuracy: 0.9966 - val_loss: 0.0112 - val_accuracy: 0.9972\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 7s 970us/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.0091 - val_accuracy: 0.9971\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.0073 - val_accuracy: 0.9978\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.0087 - val_accuracy: 0.9974\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.0060 - val_accuracy: 0.9984\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 7s 943us/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.0209 - val_accuracy: 0.9956\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 0.0250 - val_accuracy: 0.9952\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0095 - accuracy: 0.9978 - val_loss: 0.0081 - val_accuracy: 0.9978\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 7s 943us/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.0140 - val_accuracy: 0.9968\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0097 - accuracy: 0.9977 - val_loss: 0.0077 - val_accuracy: 0.9979\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.0111 - val_accuracy: 0.9969\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 7s 943us/step - loss: 0.0102 - accuracy: 0.9978 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.0137 - val_accuracy: 0.9966\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 7s 942us/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.0191 - val_accuracy: 0.9965\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.0214 - val_accuracy: 0.9961\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 7s 950us/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.0150 - val_accuracy: 0.9967\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.0080 - val_accuracy: 0.9983\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 7s 942us/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0053 - val_accuracy: 0.9986\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.0067 - val_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 7s 943us/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.0085 - val_accuracy: 0.9980\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.0057 - val_accuracy: 0.9981\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.0130 - val_accuracy: 0.9973\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0073 - val_accuracy: 0.9982\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.0088 - val_accuracy: 0.9977\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 7s 942us/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 7s 951us/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.0069 - val_accuracy: 0.9983\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0069 - val_accuracy: 0.9981\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0094 - val_accuracy: 0.9981\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.0076 - val_accuracy: 0.9980\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0128 - val_accuracy: 0.9977\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 7s 949us/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.0115 - val_accuracy: 0.9981\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 7s 943us/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0064 - val_accuracy: 0.9985\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.0229 - val_accuracy: 0.9964\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0093 - val_accuracy: 0.9982\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.0102 - val_accuracy: 0.9981\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 7s 942us/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0099 - val_accuracy: 0.9979\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0069 - val_accuracy: 0.9985\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 7s 952us/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0165 - val_accuracy: 0.9972\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0116 - val_accuracy: 0.9977\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0031 - val_accuracy: 0.9994\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.0072 - val_accuracy: 0.9980\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0070 - val_accuracy: 0.9984\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.0085 - val_accuracy: 0.9981\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 7s 952us/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0070 - val_accuracy: 0.9983\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0112 - val_accuracy: 0.9974\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0043 - val_accuracy: 0.9989\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0129 - val_accuracy: 0.9977\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0089 - val_accuracy: 0.9980\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0093 - val_accuracy: 0.9980\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 7s 943us/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0038 - val_accuracy: 0.9985\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0070 - val_accuracy: 0.9984\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0068 - val_accuracy: 0.9981\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0065 - val_accuracy: 0.9987\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0119 - val_accuracy: 0.9977\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0086 - val_accuracy: 0.9987\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 7s 949us/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 7s 968us/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0075 - val_accuracy: 0.9987\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 7s 949us/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9988\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 7s 950us/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0054 - val_accuracy: 0.9989\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0069 - val_accuracy: 0.9987\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0178 - val_accuracy: 0.9976\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0076 - val_accuracy: 0.9985\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0050 - val_accuracy: 0.9988\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0031 - val_accuracy: 0.9990\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0236 - val_accuracy: 0.9969\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0051 - val_accuracy: 0.9990\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 7s 958us/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0073 - val_accuracy: 0.9986\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0029 - val_accuracy: 0.9991\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 7s 949us/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0051 - val_accuracy: 0.9989\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 7s 947us/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0062 - val_accuracy: 0.9990\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0061 - val_accuracy: 0.9989\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0036 - val_accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–ƒâ–…â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–†â–…â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ƒâ–„â–…â–‚â–…â–„â–†â–ƒâ–‚â–…â–†â–„â–†â–…â–†â–…â–†â–…â–†â–†â–†â–…â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–…â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–„â–ƒâ–ƒâ–‚â–ˆâ–‡â–‚â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–„â–â–„â–‚â–‚â–†â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99865</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00974</td></tr><tr><td>batch/loss</td><td>0.00578</td></tr><tr><td>epoch/accuracy</td><td>0.99865</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00974</td></tr><tr><td>epoch/loss</td><td>0.00578</td></tr><tr><td>epoch/val_accuracy</td><td>0.9992</td></tr><tr><td>epoch/val_loss</td><td>0.00362</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_42</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/nwcbxn08' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/nwcbxn08</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_070213-nwcbxn08/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 07:13:19,236] Trial 42 finished with value: 0.002850608481094241 and parameters: {'Layer_1_units': 94, 'Activation_1': 'sigmoid', 'n_layers': 2, 'Layer_2_units': 123, 'Activation_2': 'relu', 'Layer_3_units': 96, 'Activation_3': 'sigmoid', 'learning_rate': 0.009744991058647394, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 34 with value: 0.0021758171962574123.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_071319-chyk5kil</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/chyk5kil' target=\"_blank\">Trial_43</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/chyk5kil' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/chyk5kil</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/7000 [..............................] - ETA: 43:25 - loss: 0.5976 - accuracy: 0.7500WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0007s). Check your callbacks.\n",
      "7000/7000 [==============================] - 6s 857us/step - loss: 0.0535 - accuracy: 0.9800 - val_loss: 0.0140 - val_accuracy: 0.9959\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 6s 844us/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.0218 - val_accuracy: 0.9937\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 6s 847us/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0142 - val_accuracy: 0.9960\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 6s 842us/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.0066 - val_accuracy: 0.9976\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0336 - val_accuracy: 0.9923\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0110 - val_accuracy: 0.9965\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0165 - val_accuracy: 0.9955\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.0100 - val_accuracy: 0.9969\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 6s 880us/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0075 - val_accuracy: 0.9974\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 6s 889us/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0177 - val_accuracy: 0.9958\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0049 - val_accuracy: 0.9984\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.0056 - val_accuracy: 0.9980\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.0154 - val_accuracy: 0.9962\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0090 - val_accuracy: 0.9974\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0096 - val_accuracy: 0.9975\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 6s 843us/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 6s 844us/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0077 - val_accuracy: 0.9980\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0095 - val_accuracy: 0.9975\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0089 - val_accuracy: 0.9976\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.0063 - val_accuracy: 0.9981\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0087 - val_accuracy: 0.9978\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9984\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0096 - val_accuracy: 0.9973\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.0043 - val_accuracy: 0.9984\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 6s 842us/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0101 - val_accuracy: 0.9976\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.0176 - val_accuracy: 0.9955\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.0080 - val_accuracy: 0.9983\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 0.0057 - val_accuracy: 0.9985\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.0069 - val_accuracy: 0.9979\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 6s 849us/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.0084 - val_accuracy: 0.9980\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.0082 - val_accuracy: 0.9977\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 6s 842us/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0120 - val_accuracy: 0.9967\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 6s 844us/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.0075 - val_accuracy: 0.9981\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.0089 - val_accuracy: 0.9979\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0056 - val_accuracy: 0.9982\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0091 - val_accuracy: 0.9979\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0044 - val_accuracy: 0.9985\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0069 - val_accuracy: 0.9980\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.0111 - val_accuracy: 0.9977\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.0054 - val_accuracy: 0.9982\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 6s 842us/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.0084 - val_accuracy: 0.9980\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0163 - val_accuracy: 0.9972\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0088 - val_accuracy: 0.9980\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 6s 843us/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0283 - val_accuracy: 0.9952\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0072 - val_accuracy: 0.9979\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 6s 844us/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0222 - val_accuracy: 0.9965\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0063 - val_accuracy: 0.9980\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0049 - val_accuracy: 0.9985\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0129 - val_accuracy: 0.9972\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0104 - val_accuracy: 0.9984\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0172 - val_accuracy: 0.9974\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0106 - val_accuracy: 0.9980\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.0069 - val_accuracy: 0.9984\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0303 - val_accuracy: 0.9961\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.0186 - val_accuracy: 0.9966\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0049 - val_accuracy: 0.9984\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0101 - val_accuracy: 0.9982\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0056 - val_accuracy: 0.9986\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0055 - val_accuracy: 0.9990\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0062 - val_accuracy: 0.9986\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0083 - val_accuracy: 0.9983\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0249 - val_accuracy: 0.9969\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0070 - val_accuracy: 0.9983\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0049 - val_accuracy: 0.9988\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0080 - val_accuracy: 0.9985\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0068 - val_accuracy: 0.9983\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0085 - val_accuracy: 0.9984\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0129 - val_accuracy: 0.9974\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0096 - val_accuracy: 0.9979\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0115 - val_accuracy: 0.9980\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0103 - val_accuracy: 0.9979\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0053 - val_accuracy: 0.9988\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0111 - val_accuracy: 0.9979\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0098 - val_accuracy: 0.9979\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0081 - val_accuracy: 0.9985\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0159 - val_accuracy: 0.9974\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0118 - val_accuracy: 0.9975\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0059 - val_accuracy: 0.9988\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 6s 845us/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0093 - val_accuracy: 0.9984\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0112 - val_accuracy: 0.9976\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 6s 839us/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0096 - val_accuracy: 0.9981\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0128 - val_accuracy: 0.9982\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0059 - val_accuracy: 0.9988\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0118 - val_accuracy: 0.9977\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9986\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0137 - val_accuracy: 0.9980\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.0089 - val_accuracy: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ƒâ–„â–†â–‡â–…â–†â–„â–…â–…â–†â–…â–…â–„â–…â–‡â–…â–…â–…â–…â–†â–…â–‡â–†â–‡â–†â–†â–†â–†â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–…â–ƒâ–ƒâ–ƒâ–„â–„â–„â–‚â–ƒâ–„â–„â–„â–„â–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒ</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–„â–ˆâ–„â–†â–‡â–‡â–‡â–†â–ƒâ–ˆâ–†â–…â–‡â–‡â–†â–ˆâ–ƒâ–‡â–…â–‡â–ˆâ–†â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–†â–ˆâ–ˆâ–†â–‡â–‡â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–â–ƒâ–â–‚â–‚â–â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–ƒâ–‚â–ƒâ–ƒâ–â–‚â–„â–â–‚â–‚â–ƒâ–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99896</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00627</td></tr><tr><td>batch/loss</td><td>0.00497</td></tr><tr><td>epoch/accuracy</td><td>0.99896</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00627</td></tr><tr><td>epoch/loss</td><td>0.00497</td></tr><tr><td>epoch/val_accuracy</td><td>0.99835</td></tr><tr><td>epoch/val_loss</td><td>0.0089</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_43</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/chyk5kil' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/chyk5kil</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_071319-chyk5kil/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 07:23:09,968] Trial 43 finished with value: 0.003617285075597465 and parameters: {'Layer_1_units': 84, 'Activation_1': 'sigmoid', 'n_layers': 1, 'Layer_2_units': 111, 'Activation_2': 'relu', 'learning_rate': 0.00626646458863629, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 34 with value: 0.0021758171962574123.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_072310-b54gn8ar</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/b54gn8ar' target=\"_blank\">Trial_44</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/b54gn8ar' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/b54gn8ar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/7000 [..............................] - ETA: 55:32 - loss: 1.2239 - accuracy: 0.2000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0008s). Check your callbacks.\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.0562 - accuracy: 0.9800 - val_loss: 0.0146 - val_accuracy: 0.9963\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 6s 927us/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.0205 - val_accuracy: 0.9944\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 6s 926us/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.0092 - val_accuracy: 0.9974\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0245 - val_accuracy: 0.9940\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 7s 928us/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.0385 - val_accuracy: 0.9921\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0076 - val_accuracy: 0.9973\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 7s 930us/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0075 - val_accuracy: 0.9977\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 6s 926us/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0086 - val_accuracy: 0.9974\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0059 - val_accuracy: 0.9980\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0115 - val_accuracy: 0.9967\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 6s 928us/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0101 - val_accuracy: 0.9969\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0064 - val_accuracy: 0.9981\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 6s 922us/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0084 - val_accuracy: 0.9978\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0070 - val_accuracy: 0.9977\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0076 - val_accuracy: 0.9974\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0085 - val_accuracy: 0.9974\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0078 - val_accuracy: 0.9978\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 6s 921us/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0074 - val_accuracy: 0.9977\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0060 - val_accuracy: 0.9979\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 6s 927us/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0048 - val_accuracy: 0.9982\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 6s 926us/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0045 - val_accuracy: 0.9985\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0066 - val_accuracy: 0.9976\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0078 - val_accuracy: 0.9973\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0044 - val_accuracy: 0.9986\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0088 - val_accuracy: 0.9972\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 6s 928us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0047 - val_accuracy: 0.9984\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 7s 929us/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0078 - val_accuracy: 0.9978\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 6s 927us/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0062 - val_accuracy: 0.9977\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0045 - val_accuracy: 0.9985\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 6s 926us/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0032 - val_accuracy: 0.9988\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 6s 926us/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0040 - val_accuracy: 0.9984\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0054 - val_accuracy: 0.9980\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0049 - val_accuracy: 0.9984\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 6s 919us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 0.9984\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0051 - val_accuracy: 0.9983\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 6s 921us/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 6s 922us/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9984\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0053 - val_accuracy: 0.9981\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0042 - val_accuracy: 0.9986\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0059 - val_accuracy: 0.9980\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 6s 917us/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0040 - val_accuracy: 0.9985\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9985\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 7s 929us/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9979\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9984\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 6s 927us/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0065 - val_accuracy: 0.9980\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0055 - val_accuracy: 0.9980\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0067 - val_accuracy: 0.9980\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 6s 927us/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 0.9985\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 7s 983us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 7s 965us/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0054 - val_accuracy: 0.9981\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9984\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0040 - val_accuracy: 0.9984\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 6s 921us/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9984\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0051 - val_accuracy: 0.9982\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 6s 922us/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0081 - val_accuracy: 0.9978\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 6s 921us/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0059 - val_accuracy: 0.9981\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 6s 919us/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 0.9983\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0032 - val_accuracy: 0.9990\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 7s 929us/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0063 - val_accuracy: 0.9981\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0066 - val_accuracy: 0.9983\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 6s 922us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0072 - val_accuracy: 0.9981\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 6s 921us/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 6s 925us/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 6s 921us/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9992\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 6s 921us/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0059 - val_accuracy: 0.9983\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 6s 919us/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0069 - val_accuracy: 0.9984\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 6s 921us/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0032 - val_accuracy: 0.9988\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 6s 919us/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0073 - val_accuracy: 0.9978\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9984\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 6s 918us/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 6s 917us/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0066 - val_accuracy: 0.9978\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9990\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 6s 922us/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0031 - val_accuracy: 0.9989\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 6s 919us/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0022 - val_accuracy: 0.9991\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0099 - val_accuracy: 0.9971\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0027 - val_accuracy: 0.9990\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 6s 921us/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9985\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 6s 926us/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0063 - val_accuracy: 0.9984\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 6s 924us/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0074 - val_accuracy: 0.9982\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 6s 923us/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9984\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 6s 922us/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9989\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 6s 922us/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0028 - val_accuracy: 0.9990\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 6s 921us/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0028 - val_accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–„â–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–†â–†â–„â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–ƒâ–†â–â–†â–‡â–†â–‡â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–†â–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ƒâ–…â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–â–â–â–â–â–‚â–â–â–‚â–â–â–‚â–‚â–â–â–‚â–â–â–‚â–â–‚â–â–‚â–â–‚â–â–â–â–â–‚â–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99939</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00378</td></tr><tr><td>batch/loss</td><td>0.00205</td></tr><tr><td>epoch/accuracy</td><td>0.99939</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00378</td></tr><tr><td>epoch/loss</td><td>0.00205</td></tr><tr><td>epoch/val_accuracy</td><td>0.9992</td></tr><tr><td>epoch/val_loss</td><td>0.00281</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_44</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/b54gn8ar' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/b54gn8ar</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_072310-b54gn8ar/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 07:34:00,025] Trial 44 finished with value: 0.0021604654146358373 and parameters: {'Layer_1_units': 100, 'Activation_1': 'sigmoid', 'n_layers': 2, 'Layer_2_units': 98, 'Activation_2': 'relu', 'Layer_3_units': 85, 'Activation_3': 'sigmoid', 'learning_rate': 0.0037768420579121853, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 44 with value: 0.0021604654146358373.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_073400-khekkum9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/khekkum9' target=\"_blank\">Trial_45</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/khekkum9' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/khekkum9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0722 - accuracy: 0.9761 - val_loss: 0.0517 - val_accuracy: 0.9844\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0225 - accuracy: 0.9946 - val_loss: 0.0222 - val_accuracy: 0.9950\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.0175 - accuracy: 0.9958 - val_loss: 0.0206 - val_accuracy: 0.9951\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 7s 988us/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.0149 - val_accuracy: 0.9958\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 7s 988us/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.0111 - val_accuracy: 0.9969\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.0105 - val_accuracy: 0.9970\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.0089 - val_accuracy: 0.9978\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.0087 - val_accuracy: 0.9979\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 0.0105 - val_accuracy: 0.9972\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.0063 - val_accuracy: 0.9982\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.0135 - val_accuracy: 0.9965\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 7s 980us/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0083 - val_accuracy: 0.9977\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.0091 - val_accuracy: 0.9975\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 7s 981us/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0076 - val_accuracy: 0.9977\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 7s 980us/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0098 - val_accuracy: 0.9971\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 7s 987us/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.0115 - val_accuracy: 0.9968\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 7s 983us/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0089 - val_accuracy: 0.9972\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 7s 989us/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0085 - val_accuracy: 0.9976\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0050 - val_accuracy: 0.9985\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.0080 - val_accuracy: 0.9974\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 7s 988us/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0084 - val_accuracy: 0.9979\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 7s 987us/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0160 - val_accuracy: 0.9959\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 7s 981us/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0080 - val_accuracy: 0.9975\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0049 - val_accuracy: 0.9986\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 7s 987us/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0067 - val_accuracy: 0.9979\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 7s 981us/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0052 - val_accuracy: 0.9985\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0075 - val_accuracy: 0.9977\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0091 - val_accuracy: 0.9969\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0049 - val_accuracy: 0.9988\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0149 - val_accuracy: 0.9962\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0051 - val_accuracy: 0.9982\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 7s 983us/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0049 - val_accuracy: 0.9985\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0050 - val_accuracy: 0.9983\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0040 - val_accuracy: 0.9990\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0046 - val_accuracy: 0.9984\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0061 - val_accuracy: 0.9983\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0050 - val_accuracy: 0.9986\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 7s 981us/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0091 - val_accuracy: 0.9972\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0048 - val_accuracy: 0.9985\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0075 - val_accuracy: 0.9978\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 7s 987us/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0052 - val_accuracy: 0.9984\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0057 - val_accuracy: 0.9980\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 7s 987us/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 7s 988us/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 7s 989us/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0046 - val_accuracy: 0.9984\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0089 - val_accuracy: 0.9974\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0049 - val_accuracy: 0.9986\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0042 - val_accuracy: 0.9985\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0038 - val_accuracy: 0.9988\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 7s 983us/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0078 - val_accuracy: 0.9977\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 7s 981us/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0056 - val_accuracy: 0.9981\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0071 - val_accuracy: 0.9977\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 7s 988us/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0093 - val_accuracy: 0.9974\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0294 - val_accuracy: 0.9948\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0037 - val_accuracy: 0.9989\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0064 - val_accuracy: 0.9977\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0040 - val_accuracy: 0.9990\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0085 - val_accuracy: 0.9975\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0031 - val_accuracy: 0.9988\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 7s 990us/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0094 - val_accuracy: 0.9978\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0043 - val_accuracy: 0.9985\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0055 - val_accuracy: 0.9982\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 7s 981us/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0042 - val_accuracy: 0.9984\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0077 - val_accuracy: 0.9977\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 7s 983us/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0046 - val_accuracy: 0.9986\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 7s 982us/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 7s 981us/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0028 - val_accuracy: 0.9991\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0077 - val_accuracy: 0.9979\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 7s 977us/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 7s 983us/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 7s 983us/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0027 - val_accuracy: 0.9991\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 7s 988us/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0045 - val_accuracy: 0.9990\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 7s 998us/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0074 - val_accuracy: 0.9980\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 7s 983us/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 7s 983us/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 7s 988us/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 7s 980us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 7s 986us/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0080 - val_accuracy: 0.9981\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 7s 984us/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0054 - val_accuracy: 0.9986\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 7s 983us/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0036 - val_accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–…â–…â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–ƒâ–„â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‡â–†â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–„â–†â–„â–…â–…â–‡â–†â–‚â–‡â–‡â–†â–†â–ˆâ–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–†â–ˆâ–ˆâ–‡â–ˆâ–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–â–â–‚â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–…â–â–â–‚â–â–â–â–‚â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99899</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00356</td></tr><tr><td>batch/loss</td><td>0.00383</td></tr><tr><td>epoch/accuracy</td><td>0.99899</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00356</td></tr><tr><td>epoch/loss</td><td>0.00382</td></tr><tr><td>epoch/val_accuracy</td><td>0.9988</td></tr><tr><td>epoch/val_loss</td><td>0.00356</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_45</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/khekkum9' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/khekkum9</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_073400-khekkum9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 07:45:32,883] Trial 45 finished with value: 0.002759106643497944 and parameters: {'Layer_1_units': 78, 'Activation_1': 'sigmoid', 'n_layers': 3, 'Layer_2_units': 108, 'Activation_2': 'relu', 'Layer_3_units': 84, 'Activation_3': 'sigmoid', 'Layer_4_units': 97, 'Activation_4': 'sigmoid', 'learning_rate': 0.003561436545973067, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 44 with value: 0.0021604654146358373.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_074532-z2rmodf0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/z2rmodf0' target=\"_blank\">Trial_46</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/z2rmodf0' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/z2rmodf0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/7000 [..............................] - ETA: 43:32 - loss: 0.6960 - accuracy: 0.6500WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0006s). Check your callbacks.\n",
      "7000/7000 [==============================] - 6s 863us/step - loss: 0.0542 - accuracy: 0.9792 - val_loss: 0.0135 - val_accuracy: 0.9955\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.0156 - val_accuracy: 0.9947\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0100 - val_accuracy: 0.9970\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0322 - val_accuracy: 0.9935\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.0088 - val_accuracy: 0.9969\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0060 - val_accuracy: 0.9979\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0057 - val_accuracy: 0.9977\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.0045 - val_accuracy: 0.9984\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 6s 845us/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0046 - val_accuracy: 0.9980\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 6s 917us/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.0089 - val_accuracy: 0.9979\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 6s 854us/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0053 - val_accuracy: 0.9980\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.0058 - val_accuracy: 0.9980\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.0121 - val_accuracy: 0.9977\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 6s 847us/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.0120 - val_accuracy: 0.9969\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 6s 849us/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.0073 - val_accuracy: 0.9977\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 6s 844us/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0052 - val_accuracy: 0.9982\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 6s 844us/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0075 - val_accuracy: 0.9977\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 6s 849us/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.0039 - val_accuracy: 0.9981\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 6s 847us/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0107 - val_accuracy: 0.9979\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.0093 - val_accuracy: 0.9974\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0058 - val_accuracy: 0.9980\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0070 - val_accuracy: 0.9980\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0070 - val_accuracy: 0.9979\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0041 - val_accuracy: 0.9985\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0090 - val_accuracy: 0.9977\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.0144 - val_accuracy: 0.9969\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 6s 849us/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.0088 - val_accuracy: 0.9978\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 0.0071 - val_accuracy: 0.9980\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.0064 - val_accuracy: 0.9983\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 6s 854us/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0191 - val_accuracy: 0.9962\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.0103 - val_accuracy: 0.9974\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.0054 - val_accuracy: 0.9986\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0038 - val_accuracy: 0.9984\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0074 - val_accuracy: 0.9981\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 6s 854us/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.0072 - val_accuracy: 0.9981\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0066 - val_accuracy: 0.9983\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0191 - val_accuracy: 0.9965\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0066 - val_accuracy: 0.9982\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0218 - val_accuracy: 0.9963\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0065 - val_accuracy: 0.9987\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 6s 869us/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0084 - val_accuracy: 0.9979\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 6s 918us/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 7s 992us/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0094 - val_accuracy: 0.9977\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 6s 905us/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 6s 862us/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 6s 863us/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0045 - val_accuracy: 0.9985\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 6s 859us/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0076 - val_accuracy: 0.9980\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0073 - val_accuracy: 0.9983\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0154 - val_accuracy: 0.9970\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 6s 857us/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0111 - val_accuracy: 0.9980\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0093 - val_accuracy: 0.9977\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0138 - val_accuracy: 0.9971\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0082 - val_accuracy: 0.9981\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 6s 865us/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0074 - val_accuracy: 0.9982\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0105 - val_accuracy: 0.9972\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0166 - val_accuracy: 0.9968\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0148 - val_accuracy: 0.9974\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 6s 854us/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0067 - val_accuracy: 0.9982\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0081 - val_accuracy: 0.9981\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 6s 857us/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0140 - val_accuracy: 0.9973\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 6s 854us/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 6s 876us/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0144 - val_accuracy: 0.9969\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0056 - val_accuracy: 0.9985\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 6s 858us/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0101 - val_accuracy: 0.9982\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0088 - val_accuracy: 0.9981\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0096 - val_accuracy: 0.9981\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0085 - val_accuracy: 0.9984\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0087 - val_accuracy: 0.9984\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0079 - val_accuracy: 0.9985\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 6s 857us/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0161 - val_accuracy: 0.9970\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0065 - val_accuracy: 0.9985\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 6s 850us/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0086 - val_accuracy: 0.9984\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0117 - val_accuracy: 0.9977\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 6s 848us/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0077 - val_accuracy: 0.9981\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 6s 849us/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0077 - val_accuracy: 0.9983\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 6s 852us/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0076 - val_accuracy: 0.9984\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 6s 846us/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9984\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 6s 853us/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0045 - val_accuracy: 0.9990\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 6s 855us/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0039 - val_accuracy: 0.9989\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–‚â–â–â–ƒâ–…â–…â–…â–†â–„â–…â–„â–†â–…â–…â–…â–‡â–‡â–†â–†â–„â–‡â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ƒâ–†â–‡â–‡â–ˆâ–„â–†â–‡â–‡â–†â–†â–†â–‡â–‡â–†â–…â–‡â–…â–„â–…â–ƒâ–ƒâ–„â–‚â–„â–‚â–ƒâ–â–‚â–â–ƒâ–„â–‚â–ƒâ–„â–‚â–‚â–„â–ƒâ–‚</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‡â–…â–…â–…â–…â–…â–†â–„â–„â–‡â–„â–†â–…â–„â–…â–„â–„â–ƒâ–‚â–ƒâ–â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–â–â–‚â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–ƒâ–†â–â–†â–‡â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–…â–‡â–ˆâ–‡â–‡â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–†â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–…â–â–„â–â–‚â–ƒâ–‚â–‚â–â–„â–â–„â–‚â–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99887</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00543</td></tr><tr><td>batch/loss</td><td>0.00528</td></tr><tr><td>epoch/accuracy</td><td>0.99886</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00543</td></tr><tr><td>epoch/loss</td><td>0.0053</td></tr><tr><td>epoch/val_accuracy</td><td>0.9989</td></tr><tr><td>epoch/val_loss</td><td>0.00388</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_46</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/z2rmodf0' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/z2rmodf0</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_074532-z2rmodf0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 07:55:34,576] Trial 46 finished with value: 0.0038092285860329865 and parameters: {'Layer_1_units': 104, 'Activation_1': 'sigmoid', 'n_layers': 1, 'Layer_2_units': 97, 'Activation_2': 'relu', 'learning_rate': 0.005433797309390521, 'optimizer': 'rmsprop', 'batch_size': 20}. Best is trial 44 with value: 0.0021604654146358373.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_075534-bi01xla4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/bi01xla4' target=\"_blank\">Trial_47</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/bi01xla4' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/bi01xla4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0767 - accuracy: 0.9731 - val_loss: 0.0342 - val_accuracy: 0.9916\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0226 - accuracy: 0.9948 - val_loss: 0.0228 - val_accuracy: 0.9941\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 0.0156 - val_accuracy: 0.9966\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0135 - accuracy: 0.9971 - val_loss: 0.0141 - val_accuracy: 0.9969\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0114 - accuracy: 0.9973 - val_loss: 0.0117 - val_accuracy: 0.9966\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.0120 - val_accuracy: 0.9967\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.0100 - val_accuracy: 0.9976\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.0132 - val_accuracy: 0.9972\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.0159 - val_accuracy: 0.9961\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.0115 - val_accuracy: 0.9969\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0097 - val_accuracy: 0.9977\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0113 - val_accuracy: 0.9974\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0102 - val_accuracy: 0.9979\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.0099 - val_accuracy: 0.9974\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.0099 - val_accuracy: 0.9975\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.0089 - val_accuracy: 0.9977\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.0069 - val_accuracy: 0.9981\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.0165 - val_accuracy: 0.9962\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0114 - val_accuracy: 0.9974\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.0153 - val_accuracy: 0.9965\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0092 - val_accuracy: 0.9979\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0087 - val_accuracy: 0.9979\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0089 - val_accuracy: 0.9981\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.0101 - val_accuracy: 0.9976\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0094 - val_accuracy: 0.9978\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0126 - val_accuracy: 0.9979\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.0099 - val_accuracy: 0.9979\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0112 - val_accuracy: 0.9978\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0098 - val_accuracy: 0.9976\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0107 - val_accuracy: 0.9978\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.0096 - val_accuracy: 0.9978\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.0126 - val_accuracy: 0.9976\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0097 - val_accuracy: 0.9983\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.0102 - val_accuracy: 0.9979\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.0113 - val_accuracy: 0.9979\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0135 - val_accuracy: 0.9977\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0154 - val_accuracy: 0.9969\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.0096 - val_accuracy: 0.9979\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0203 - val_accuracy: 0.9967\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0113 - val_accuracy: 0.9977\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0093 - val_accuracy: 0.9983\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0079 - val_accuracy: 0.9984\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0200 - val_accuracy: 0.9970\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0116 - val_accuracy: 0.9978\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0066 - val_accuracy: 0.9988\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0210 - val_accuracy: 0.9965\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0115 - val_accuracy: 0.9977\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0130 - val_accuracy: 0.9973\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0079 - val_accuracy: 0.9984\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0085 - val_accuracy: 0.9977\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0130 - val_accuracy: 0.9975\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0114 - val_accuracy: 0.9977\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0094 - val_accuracy: 0.9977\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0092 - val_accuracy: 0.9980\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0080 - val_accuracy: 0.9981\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.0122 - val_accuracy: 0.9974\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0106 - val_accuracy: 0.9977\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0072 - val_accuracy: 0.9984\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0089 - val_accuracy: 0.9983\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0072 - val_accuracy: 0.9983\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0083 - val_accuracy: 0.9981\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0086 - val_accuracy: 0.9983\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0231 - val_accuracy: 0.9957\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0085 - val_accuracy: 0.9981\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0181 - val_accuracy: 0.9971\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0071 - val_accuracy: 0.9983\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0086 - val_accuracy: 0.9979\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0051 - val_accuracy: 0.9988\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0052 - val_accuracy: 0.9985\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0076 - val_accuracy: 0.9982\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0066 - val_accuracy: 0.9982\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0161 - val_accuracy: 0.9967\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0068 - val_accuracy: 0.9982\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0064 - val_accuracy: 0.9984\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0070 - val_accuracy: 0.9981\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0084 - val_accuracy: 0.9982\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0082 - val_accuracy: 0.9984\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 0.9984\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0161 - val_accuracy: 0.9972\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0088 - val_accuracy: 0.9979\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0072 - val_accuracy: 0.9984\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0166 - val_accuracy: 0.9965\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0085 - val_accuracy: 0.9981\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0075 - val_accuracy: 0.9985\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0082 - val_accuracy: 0.9981\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0299 - val_accuracy: 0.9934\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0071 - val_accuracy: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–‚â–‚â–‚â–…â–„â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–†â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–…â–…â–†â–†â–†â–†â–‡â–†â–‡â–†â–‡â–‡â–†â–‡â–‡â–…â–‡â–‡â–ˆâ–…â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–…â–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–„â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–…â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–…â–‚â–â–‚â–„â–â–â–‚â–„â–â–â–‚â–„â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99979</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00263</td></tr><tr><td>batch/loss</td><td>0.00217</td></tr><tr><td>epoch/accuracy</td><td>0.99979</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00263</td></tr><tr><td>epoch/loss</td><td>0.00217</td></tr><tr><td>epoch/val_accuracy</td><td>0.99845</td></tr><tr><td>epoch/val_loss</td><td>0.00711</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_47</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/bi01xla4' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/bi01xla4</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_075534-bi01xla4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 08:08:30,537] Trial 47 finished with value: 0.004662901721894741 and parameters: {'Layer_1_units': 69, 'Activation_1': 'sigmoid', 'n_layers': 4, 'Layer_2_units': 120, 'Activation_2': 'relu', 'Layer_3_units': 70, 'Activation_3': 'sigmoid', 'Layer_4_units': 109, 'Activation_4': 'relu', 'Layer_5_units': 115, 'Activation_5': 'sigmoid', 'learning_rate': 0.0026347892300049983, 'optimizer': 'adam', 'batch_size': 20}. Best is trial 44 with value: 0.0021604654146358373.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_080830-8uez04jd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/8uez04jd' target=\"_blank\">Trial_48</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/8uez04jd' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/8uez04jd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3500/3500 [==============================] - 4s 985us/step - loss: 0.0603 - accuracy: 0.9783 - val_loss: 0.0463 - val_accuracy: 0.9847\n",
      "Epoch 2/100\n",
      "3500/3500 [==============================] - 3s 952us/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.0156 - val_accuracy: 0.9954\n",
      "Epoch 3/100\n",
      "3500/3500 [==============================] - 3s 952us/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.0105 - val_accuracy: 0.9973\n",
      "Epoch 4/100\n",
      "3500/3500 [==============================] - 3s 955us/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.0081 - val_accuracy: 0.9976\n",
      "Epoch 5/100\n",
      "3500/3500 [==============================] - 3s 952us/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.0154 - val_accuracy: 0.9965\n",
      "Epoch 6/100\n",
      "3500/3500 [==============================] - 3s 950us/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0096 - val_accuracy: 0.9966\n",
      "Epoch 7/100\n",
      "3500/3500 [==============================] - 3s 954us/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.0169 - val_accuracy: 0.9953\n",
      "Epoch 8/100\n",
      "3500/3500 [==============================] - 3s 955us/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0101 - val_accuracy: 0.9969\n",
      "Epoch 9/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0062 - val_accuracy: 0.9984\n",
      "Epoch 10/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0077 - val_accuracy: 0.9973\n",
      "Epoch 11/100\n",
      "3500/3500 [==============================] - 3s 951us/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0061 - val_accuracy: 0.9977\n",
      "Epoch 12/100\n",
      "3500/3500 [==============================] - 3s 954us/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0094 - val_accuracy: 0.9973\n",
      "Epoch 13/100\n",
      "3500/3500 [==============================] - 3s 952us/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0102 - val_accuracy: 0.9972\n",
      "Epoch 14/100\n",
      "3500/3500 [==============================] - 3s 958us/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
      "Epoch 15/100\n",
      "3500/3500 [==============================] - 3s 955us/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0055 - val_accuracy: 0.9983\n",
      "Epoch 16/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0084 - val_accuracy: 0.9977\n",
      "Epoch 17/100\n",
      "3500/3500 [==============================] - 3s 951us/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0066 - val_accuracy: 0.9984\n",
      "Epoch 18/100\n",
      "3500/3500 [==============================] - 3s 956us/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0084 - val_accuracy: 0.9979\n",
      "Epoch 19/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0064 - val_accuracy: 0.9980\n",
      "Epoch 20/100\n",
      "3500/3500 [==============================] - 3s 949us/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9983\n",
      "Epoch 21/100\n",
      "3500/3500 [==============================] - 3s 954us/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0082 - val_accuracy: 0.9977\n",
      "Epoch 22/100\n",
      "3500/3500 [==============================] - 3s 950us/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0062 - val_accuracy: 0.9981\n",
      "Epoch 23/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0066 - val_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0062 - val_accuracy: 0.9983\n",
      "Epoch 25/100\n",
      "3500/3500 [==============================] - 3s 949us/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
      "Epoch 26/100\n",
      "3500/3500 [==============================] - 3s 949us/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0120 - val_accuracy: 0.9973\n",
      "Epoch 27/100\n",
      "3500/3500 [==============================] - 3s 952us/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0066 - val_accuracy: 0.9980\n",
      "Epoch 28/100\n",
      "3500/3500 [==============================] - 3s 951us/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0105 - val_accuracy: 0.9975\n",
      "Epoch 29/100\n",
      "3500/3500 [==============================] - 3s 994us/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0083 - val_accuracy: 0.9975\n",
      "Epoch 30/100\n",
      "3500/3500 [==============================] - 3s 952us/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
      "Epoch 31/100\n",
      "3500/3500 [==============================] - 3s 950us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0071 - val_accuracy: 0.9979\n",
      "Epoch 32/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0069 - val_accuracy: 0.9979\n",
      "Epoch 33/100\n",
      "3500/3500 [==============================] - 3s 961us/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0108 - val_accuracy: 0.9972\n",
      "Epoch 34/100\n",
      "3500/3500 [==============================] - 3s 951us/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0097 - val_accuracy: 0.9972\n",
      "Epoch 35/100\n",
      "3500/3500 [==============================] - 3s 949us/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 0.9984\n",
      "Epoch 36/100\n",
      "3500/3500 [==============================] - 3s 956us/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0079 - val_accuracy: 0.9982\n",
      "Epoch 37/100\n",
      "3500/3500 [==============================] - 3s 956us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
      "Epoch 38/100\n",
      "3500/3500 [==============================] - 3s 951us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0079 - val_accuracy: 0.9980\n",
      "Epoch 39/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
      "Epoch 40/100\n",
      "3500/3500 [==============================] - 3s 951us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0050 - val_accuracy: 0.9985\n",
      "Epoch 41/100\n",
      "3500/3500 [==============================] - 3s 957us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0083 - val_accuracy: 0.9982\n",
      "Epoch 42/100\n",
      "3500/3500 [==============================] - 3s 957us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9986\n",
      "Epoch 43/100\n",
      "3500/3500 [==============================] - 3s 951us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
      "Epoch 44/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9985\n",
      "Epoch 45/100\n",
      "3500/3500 [==============================] - 3s 955us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0083 - val_accuracy: 0.9975\n",
      "Epoch 46/100\n",
      "3500/3500 [==============================] - 3s 954us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0130 - val_accuracy: 0.9972\n",
      "Epoch 47/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
      "Epoch 48/100\n",
      "3500/3500 [==============================] - 3s 956us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
      "Epoch 49/100\n",
      "3500/3500 [==============================] - 3s 951us/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
      "Epoch 50/100\n",
      "3500/3500 [==============================] - 3s 955us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
      "Epoch 51/100\n",
      "3500/3500 [==============================] - 3s 954us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0176 - val_accuracy: 0.9962\n",
      "Epoch 52/100\n",
      "3500/3500 [==============================] - 3s 959us/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0105 - val_accuracy: 0.9977\n",
      "Epoch 53/100\n",
      "3500/3500 [==============================] - 3s 950us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
      "Epoch 54/100\n",
      "3500/3500 [==============================] - 3s 958us/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
      "Epoch 55/100\n",
      "3500/3500 [==============================] - 3s 956us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
      "Epoch 56/100\n",
      "3500/3500 [==============================] - 3s 952us/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 57/100\n",
      "3500/3500 [==============================] - 3s 960us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0066 - val_accuracy: 0.9983\n",
      "Epoch 58/100\n",
      "3500/3500 [==============================] - 3s 958us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0029 - val_accuracy: 0.9990\n",
      "Epoch 59/100\n",
      "3500/3500 [==============================] - 3s 958us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 0.9988\n",
      "Epoch 60/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0069 - val_accuracy: 0.9981\n",
      "Epoch 61/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
      "Epoch 62/100\n",
      "3500/3500 [==============================] - 3s 954us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
      "Epoch 63/100\n",
      "3500/3500 [==============================] - 3s 955us/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
      "Epoch 64/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
      "Epoch 65/100\n",
      "3500/3500 [==============================] - 3s 950us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 66/100\n",
      "3500/3500 [==============================] - 3s 949us/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0114 - val_accuracy: 0.9973\n",
      "Epoch 67/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0070 - val_accuracy: 0.9984\n",
      "Epoch 68/100\n",
      "3500/3500 [==============================] - 3s 951us/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0129 - val_accuracy: 0.9972\n",
      "Epoch 69/100\n",
      "3500/3500 [==============================] - 3s 963us/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0215 - val_accuracy: 0.9965\n",
      "Epoch 70/100\n",
      "3500/3500 [==============================] - 3s 949us/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0106 - val_accuracy: 0.9975\n",
      "Epoch 71/100\n",
      "3500/3500 [==============================] - 3s 950us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
      "Epoch 72/100\n",
      "3500/3500 [==============================] - 3s 956us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0029 - val_accuracy: 0.9991\n",
      "Epoch 73/100\n",
      "3500/3500 [==============================] - 3s 949us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9985\n",
      "Epoch 74/100\n",
      "3500/3500 [==============================] - 3s 949us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
      "Epoch 75/100\n",
      "3500/3500 [==============================] - 3s 956us/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0164 - val_accuracy: 0.9968\n",
      "Epoch 76/100\n",
      "3500/3500 [==============================] - 3s 949us/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0033 - val_accuracy: 0.9988\n",
      "Epoch 77/100\n",
      "3500/3500 [==============================] - 3s 952us/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
      "Epoch 78/100\n",
      "3500/3500 [==============================] - 3s 950us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
      "Epoch 79/100\n",
      "3500/3500 [==============================] - 3s 950us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 80/100\n",
      "3500/3500 [==============================] - 3s 952us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0069 - val_accuracy: 0.9987\n",
      "Epoch 81/100\n",
      "3500/3500 [==============================] - 3s 953us/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 0.9984\n",
      "Epoch 82/100\n",
      "3500/3500 [==============================] - 3s 955us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 83/100\n",
      "3500/3500 [==============================] - 3s 952us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0027 - val_accuracy: 0.9991\n",
      "Epoch 84/100\n",
      "3500/3500 [==============================] - 3s 966us/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0075 - val_accuracy: 0.9983\n",
      "Epoch 85/100\n",
      "3500/3500 [==============================] - 3s 955us/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0167 - val_accuracy: 0.9973\n",
      "Epoch 86/100\n",
      "3500/3500 [==============================] - 3s 958us/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
      "Epoch 87/100\n",
      "3500/3500 [==============================] - 3s 961us/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
      "Epoch 88/100\n",
      "3500/3500 [==============================] - 3s 957us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0108 - val_accuracy: 0.9979\n",
      "Epoch 89/100\n",
      "3500/3500 [==============================] - 3s 954us/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
      "Epoch 90/100\n",
      "3500/3500 [==============================] - 3s 959us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0124 - val_accuracy: 0.9978\n",
      "Epoch 91/100\n",
      "3500/3500 [==============================] - 3s 954us/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0060 - val_accuracy: 0.9984\n",
      "Epoch 92/100\n",
      "3500/3500 [==============================] - 3s 957us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0080 - val_accuracy: 0.9981\n",
      "Epoch 93/100\n",
      "3500/3500 [==============================] - 3s 956us/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
      "Epoch 94/100\n",
      "3500/3500 [==============================] - 3s 956us/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0057 - val_accuracy: 0.9987\n",
      "Epoch 95/100\n",
      "3500/3500 [==============================] - 3s 955us/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0185 - val_accuracy: 0.9971\n",
      "Epoch 96/100\n",
      "3500/3500 [==============================] - 3s 954us/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0052 - val_accuracy: 0.9986\n",
      "Epoch 97/100\n",
      "3500/3500 [==============================] - 3s 954us/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9991\n",
      "Epoch 98/100\n",
      "3500/3500 [==============================] - 3s 954us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
      "Epoch 99/100\n",
      "3500/3500 [==============================] - 3s 954us/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
      "Epoch 100/100\n",
      "3500/3500 [==============================] - 3s 952us/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0030 - val_accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–‚â–‚â–„â–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–…â–„â–ƒâ–ƒâ–†â–…â–„â–ƒâ–‡â–‚â–„â–ˆâ–‡â–ƒâ–…â–…â–†â–†â–‚â–â–‚â–„â–â–ƒâ–„â–‚â–ˆâ–‡â–â–â–‚â–‚â–„â–â–…â–‚â–‡â–‚â–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99944</td></tr><tr><td>batch/batch_step</td><td>349995</td></tr><tr><td>batch/learning_rate</td><td>0.00719</td></tr><tr><td>batch/loss</td><td>0.00221</td></tr><tr><td>epoch/accuracy</td><td>0.99944</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00719</td></tr><tr><td>epoch/loss</td><td>0.00221</td></tr><tr><td>epoch/val_accuracy</td><td>0.999</td></tr><tr><td>epoch/val_loss</td><td>0.00301</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_48</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/8uez04jd' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/8uez04jd</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_080830-8uez04jd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 08:14:06,813] Trial 48 finished with value: 0.0026296530617401005 and parameters: {'Layer_1_units': 101, 'Activation_1': 'sigmoid', 'n_layers': 2, 'Layer_2_units': 89, 'Activation_2': 'relu', 'Layer_3_units': 67, 'Activation_3': 'sigmoid', 'learning_rate': 0.007187541088495983, 'optimizer': 'rmsprop', 'batch_size': 40}. Best is trial 44 with value: 0.0021604654146358373.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_081406-zbz6nrrn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/zbz6nrrn' target=\"_blank\">Trial_49</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/zbz6nrrn' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/zbz6nrrn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/7000 [..............................] - ETA: 27:27 - loss: 0.7156 - accuracy: 0.4000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0005s vs `on_train_batch_end` time: 0.0006s). Check your callbacks.\n",
      "7000/7000 [==============================] - 6s 794us/step - loss: 0.3774 - accuracy: 0.8339 - val_loss: 0.1903 - val_accuracy: 0.9342\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 6s 851us/step - loss: 0.1582 - accuracy: 0.9381 - val_loss: 0.1438 - val_accuracy: 0.9413\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 6s 792us/step - loss: 0.1406 - accuracy: 0.9421 - val_loss: 0.1386 - val_accuracy: 0.9448\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 5s 777us/step - loss: 0.1355 - accuracy: 0.9441 - val_loss: 0.1325 - val_accuracy: 0.9448\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 5s 772us/step - loss: 0.1317 - accuracy: 0.9463 - val_loss: 0.1293 - val_accuracy: 0.9462\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 5s 772us/step - loss: 0.1269 - accuracy: 0.9483 - val_loss: 0.1240 - val_accuracy: 0.9488\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 5s 775us/step - loss: 0.1200 - accuracy: 0.9518 - val_loss: 0.1151 - val_accuracy: 0.9539\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 5s 769us/step - loss: 0.1101 - accuracy: 0.9574 - val_loss: 0.1047 - val_accuracy: 0.9597\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 5s 768us/step - loss: 0.0986 - accuracy: 0.9637 - val_loss: 0.0937 - val_accuracy: 0.9658\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 5s 766us/step - loss: 0.0875 - accuracy: 0.9699 - val_loss: 0.0831 - val_accuracy: 0.9722\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0779 - accuracy: 0.9749 - val_loss: 0.0751 - val_accuracy: 0.9779\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 6s 864us/step - loss: 0.0702 - accuracy: 0.9797 - val_loss: 0.0678 - val_accuracy: 0.9818\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 6s 841us/step - loss: 0.0637 - accuracy: 0.9830 - val_loss: 0.0622 - val_accuracy: 0.9840\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 6s 847us/step - loss: 0.0579 - accuracy: 0.9854 - val_loss: 0.0569 - val_accuracy: 0.9859\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0526 - accuracy: 0.9874 - val_loss: 0.0514 - val_accuracy: 0.9876\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 6s 813us/step - loss: 0.0478 - accuracy: 0.9889 - val_loss: 0.0468 - val_accuracy: 0.9894\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 6s 836us/step - loss: 0.0432 - accuracy: 0.9901 - val_loss: 0.0423 - val_accuracy: 0.9901\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0392 - accuracy: 0.9913 - val_loss: 0.0383 - val_accuracy: 0.9913\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 6s 829us/step - loss: 0.0355 - accuracy: 0.9923 - val_loss: 0.0354 - val_accuracy: 0.9927\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 6s 821us/step - loss: 0.0323 - accuracy: 0.9934 - val_loss: 0.0320 - val_accuracy: 0.9936\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 6s 810us/step - loss: 0.0297 - accuracy: 0.9940 - val_loss: 0.0293 - val_accuracy: 0.9944\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 6s 805us/step - loss: 0.0273 - accuracy: 0.9947 - val_loss: 0.0272 - val_accuracy: 0.9948\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 6s 802us/step - loss: 0.0253 - accuracy: 0.9954 - val_loss: 0.0255 - val_accuracy: 0.9952\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 6s 800us/step - loss: 0.0236 - accuracy: 0.9959 - val_loss: 0.0240 - val_accuracy: 0.9960\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 6s 790us/step - loss: 0.0223 - accuracy: 0.9963 - val_loss: 0.0227 - val_accuracy: 0.9962\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 6s 786us/step - loss: 0.0211 - accuracy: 0.9966 - val_loss: 0.0215 - val_accuracy: 0.9965\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 6s 791us/step - loss: 0.0201 - accuracy: 0.9969 - val_loss: 0.0207 - val_accuracy: 0.9966\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 5s 785us/step - loss: 0.0192 - accuracy: 0.9971 - val_loss: 0.0202 - val_accuracy: 0.9967\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 6s 809us/step - loss: 0.0185 - accuracy: 0.9974 - val_loss: 0.0192 - val_accuracy: 0.9969\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 6s 817us/step - loss: 0.0179 - accuracy: 0.9975 - val_loss: 0.0188 - val_accuracy: 0.9969\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 6s 799us/step - loss: 0.0173 - accuracy: 0.9976 - val_loss: 0.0185 - val_accuracy: 0.9967\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 6s 799us/step - loss: 0.0169 - accuracy: 0.9978 - val_loss: 0.0178 - val_accuracy: 0.9970\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 6s 792us/step - loss: 0.0164 - accuracy: 0.9978 - val_loss: 0.0177 - val_accuracy: 0.9970\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 6s 796us/step - loss: 0.0161 - accuracy: 0.9980 - val_loss: 0.0170 - val_accuracy: 0.9971\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 6s 798us/step - loss: 0.0157 - accuracy: 0.9981 - val_loss: 0.0168 - val_accuracy: 0.9973\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 6s 795us/step - loss: 0.0154 - accuracy: 0.9980 - val_loss: 0.0164 - val_accuracy: 0.9970\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 6s 813us/step - loss: 0.0151 - accuracy: 0.9982 - val_loss: 0.0162 - val_accuracy: 0.9977\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 6s 799us/step - loss: 0.0149 - accuracy: 0.9984 - val_loss: 0.0159 - val_accuracy: 0.9976\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 6s 800us/step - loss: 0.0146 - accuracy: 0.9983 - val_loss: 0.0156 - val_accuracy: 0.9974\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 6s 790us/step - loss: 0.0144 - accuracy: 0.9983 - val_loss: 0.0155 - val_accuracy: 0.9972\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 6s 786us/step - loss: 0.0142 - accuracy: 0.9984 - val_loss: 0.0152 - val_accuracy: 0.9977\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 6s 789us/step - loss: 0.0139 - accuracy: 0.9985 - val_loss: 0.0150 - val_accuracy: 0.9977\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 6s 804us/step - loss: 0.0138 - accuracy: 0.9985 - val_loss: 0.0149 - val_accuracy: 0.9971\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 6s 796us/step - loss: 0.0136 - accuracy: 0.9985 - val_loss: 0.0147 - val_accuracy: 0.9973\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 6s 811us/step - loss: 0.0134 - accuracy: 0.9985 - val_loss: 0.0145 - val_accuracy: 0.9980\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 6s 798us/step - loss: 0.0132 - accuracy: 0.9985 - val_loss: 0.0143 - val_accuracy: 0.9979\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 6s 802us/step - loss: 0.0131 - accuracy: 0.9985 - val_loss: 0.0142 - val_accuracy: 0.9978\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 6s 797us/step - loss: 0.0130 - accuracy: 0.9986 - val_loss: 0.0141 - val_accuracy: 0.9975\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 6s 807us/step - loss: 0.0128 - accuracy: 0.9987 - val_loss: 0.0139 - val_accuracy: 0.9981\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 6s 805us/step - loss: 0.0127 - accuracy: 0.9987 - val_loss: 0.0141 - val_accuracy: 0.9975\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 6s 810us/step - loss: 0.0125 - accuracy: 0.9987 - val_loss: 0.0138 - val_accuracy: 0.9976\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 6s 795us/step - loss: 0.0124 - accuracy: 0.9987 - val_loss: 0.0135 - val_accuracy: 0.9979\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 6s 810us/step - loss: 0.0123 - accuracy: 0.9987 - val_loss: 0.0134 - val_accuracy: 0.9979\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 6s 832us/step - loss: 0.0121 - accuracy: 0.9988 - val_loss: 0.0134 - val_accuracy: 0.9977\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 6s 873us/step - loss: 0.0120 - accuracy: 0.9988 - val_loss: 0.0132 - val_accuracy: 0.9981\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 6s 856us/step - loss: 0.0119 - accuracy: 0.9988 - val_loss: 0.0132 - val_accuracy: 0.9976\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 6s 840us/step - loss: 0.0118 - accuracy: 0.9989 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 6s 828us/step - loss: 0.0117 - accuracy: 0.9989 - val_loss: 0.0129 - val_accuracy: 0.9979\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 6s 835us/step - loss: 0.0116 - accuracy: 0.9989 - val_loss: 0.0128 - val_accuracy: 0.9977\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 6s 838us/step - loss: 0.0115 - accuracy: 0.9989 - val_loss: 0.0126 - val_accuracy: 0.9984\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 6s 837us/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 0.0126 - val_accuracy: 0.9979\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 6s 824us/step - loss: 0.0113 - accuracy: 0.9989 - val_loss: 0.0125 - val_accuracy: 0.9980\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 6s 834us/step - loss: 0.0112 - accuracy: 0.9990 - val_loss: 0.0126 - val_accuracy: 0.9977\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 6s 812us/step - loss: 0.0111 - accuracy: 0.9990 - val_loss: 0.0123 - val_accuracy: 0.9980\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 6s 812us/step - loss: 0.0110 - accuracy: 0.9990 - val_loss: 0.0123 - val_accuracy: 0.9978\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 6s 821us/step - loss: 0.0109 - accuracy: 0.9990 - val_loss: 0.0121 - val_accuracy: 0.9979\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 6s 797us/step - loss: 0.0108 - accuracy: 0.9990 - val_loss: 0.0123 - val_accuracy: 0.9977\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 6s 799us/step - loss: 0.0107 - accuracy: 0.9990 - val_loss: 0.0123 - val_accuracy: 0.9980\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 6s 794us/step - loss: 0.0107 - accuracy: 0.9990 - val_loss: 0.0120 - val_accuracy: 0.9982\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 6s 789us/step - loss: 0.0106 - accuracy: 0.9990 - val_loss: 0.0119 - val_accuracy: 0.9981\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 6s 806us/step - loss: 0.0105 - accuracy: 0.9990 - val_loss: 0.0118 - val_accuracy: 0.9980\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 6s 796us/step - loss: 0.0104 - accuracy: 0.9991 - val_loss: 0.0118 - val_accuracy: 0.9981\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 6s 801us/step - loss: 0.0103 - accuracy: 0.9991 - val_loss: 0.0118 - val_accuracy: 0.9980\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 6s 792us/step - loss: 0.0102 - accuracy: 0.9990 - val_loss: 0.0114 - val_accuracy: 0.9981\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 6s 800us/step - loss: 0.0101 - accuracy: 0.9992 - val_loss: 0.0120 - val_accuracy: 0.9977\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 6s 794us/step - loss: 0.0101 - accuracy: 0.9991 - val_loss: 0.0115 - val_accuracy: 0.9981\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 6s 787us/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 0.0113 - val_accuracy: 0.9982\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 5s 785us/step - loss: 0.0099 - accuracy: 0.9991 - val_loss: 0.0113 - val_accuracy: 0.9980\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 5s 777us/step - loss: 0.0099 - accuracy: 0.9991 - val_loss: 0.0114 - val_accuracy: 0.9981\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 5s 783us/step - loss: 0.0098 - accuracy: 0.9992 - val_loss: 0.0112 - val_accuracy: 0.9981\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 5s 777us/step - loss: 0.0097 - accuracy: 0.9992 - val_loss: 0.0111 - val_accuracy: 0.9984\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 5s 779us/step - loss: 0.0097 - accuracy: 0.9992 - val_loss: 0.0109 - val_accuracy: 0.9983\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 5s 780us/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 0.0110 - val_accuracy: 0.9980\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 6s 786us/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 0.0109 - val_accuracy: 0.9982\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 5s 776us/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.0108 - val_accuracy: 0.9983\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 5s 783us/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 0.0109 - val_accuracy: 0.9981\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 5s 777us/step - loss: 0.0093 - accuracy: 0.9993 - val_loss: 0.0106 - val_accuracy: 0.9984\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 5s 784us/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 0.0109 - val_accuracy: 0.9982\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 5s 781us/step - loss: 0.0092 - accuracy: 0.9992 - val_loss: 0.0109 - val_accuracy: 0.9978\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 5s 773us/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 0.0109 - val_accuracy: 0.9980\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 5s 779us/step - loss: 0.0091 - accuracy: 0.9993 - val_loss: 0.0104 - val_accuracy: 0.9980\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 5s 776us/step - loss: 0.0091 - accuracy: 0.9993 - val_loss: 0.0104 - val_accuracy: 0.9981\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 5s 774us/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 0.0103 - val_accuracy: 0.9982\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 5s 784us/step - loss: 0.0089 - accuracy: 0.9993 - val_loss: 0.0104 - val_accuracy: 0.9983\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 5s 778us/step - loss: 0.0089 - accuracy: 0.9993 - val_loss: 0.0103 - val_accuracy: 0.9984\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 5s 780us/step - loss: 0.0088 - accuracy: 0.9994 - val_loss: 0.0102 - val_accuracy: 0.9983\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 6s 786us/step - loss: 0.0087 - accuracy: 0.9993 - val_loss: 0.0101 - val_accuracy: 0.9984\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 5s 783us/step - loss: 0.0087 - accuracy: 0.9993 - val_loss: 0.0101 - val_accuracy: 0.9983\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 6s 807us/step - loss: 0.0086 - accuracy: 0.9993 - val_loss: 0.0101 - val_accuracy: 0.9980\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 5s 782us/step - loss: 0.0086 - accuracy: 0.9993 - val_loss: 0.0100 - val_accuracy: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–ƒâ–„â–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–†â–…â–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‚â–‚â–‚â–ƒâ–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ˆâ–‡â–†â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.99931</td></tr><tr><td>batch/batch_step</td><td>699995</td></tr><tr><td>batch/learning_rate</td><td>0.00454</td></tr><tr><td>batch/loss</td><td>0.00858</td></tr><tr><td>epoch/accuracy</td><td>0.99931</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.00454</td></tr><tr><td>epoch/loss</td><td>0.00857</td></tr><tr><td>epoch/val_accuracy</td><td>0.9985</td></tr><tr><td>epoch/val_loss</td><td>0.01</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_49</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/zbz6nrrn' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/zbz6nrrn</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_081406-zbz6nrrn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 08:23:31,430] Trial 49 finished with value: 0.0098554365336895 and parameters: {'Layer_1_units': 45, 'Activation_1': 'sigmoid', 'n_layers': 1, 'Layer_2_units': 113, 'Activation_2': 'relu', 'learning_rate': 0.0045376867330565035, 'optimizer': 'sgd', 'batch_size': 20}. Best is trial 44 with value: 0.0021604654146358373.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_082331-6bhy1qq5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/6bhy1qq5' target=\"_blank\">Trial_50</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/6bhy1qq5' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/6bhy1qq5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5692 - accuracy: 0.7691 - val_loss: 0.5395 - val_accuracy: 0.7689\n",
      "Epoch 2/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.5213 - accuracy: 0.7692 - val_loss: 0.5011 - val_accuracy: 0.7689\n",
      "Epoch 3/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.4723 - accuracy: 0.7713 - val_loss: 0.4410 - val_accuracy: 0.7793\n",
      "Epoch 4/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.4042 - accuracy: 0.8074 - val_loss: 0.3658 - val_accuracy: 0.8431\n",
      "Epoch 5/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.3288 - accuracy: 0.8682 - val_loss: 0.2926 - val_accuracy: 0.8941\n",
      "Epoch 6/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.2657 - accuracy: 0.9043 - val_loss: 0.2403 - val_accuracy: 0.9133\n",
      "Epoch 7/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.2239 - accuracy: 0.9187 - val_loss: 0.2092 - val_accuracy: 0.9236\n",
      "Epoch 8/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1997 - accuracy: 0.9257 - val_loss: 0.1920 - val_accuracy: 0.9290\n",
      "Epoch 9/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1862 - accuracy: 0.9297 - val_loss: 0.1823 - val_accuracy: 0.9316\n",
      "Epoch 10/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1779 - accuracy: 0.9324 - val_loss: 0.1759 - val_accuracy: 0.9334\n",
      "Epoch 11/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1722 - accuracy: 0.9342 - val_loss: 0.1713 - val_accuracy: 0.9355\n",
      "Epoch 12/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1678 - accuracy: 0.9358 - val_loss: 0.1677 - val_accuracy: 0.9370\n",
      "Epoch 13/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1643 - accuracy: 0.9370 - val_loss: 0.1646 - val_accuracy: 0.9380\n",
      "Epoch 14/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1613 - accuracy: 0.9382 - val_loss: 0.1620 - val_accuracy: 0.9390\n",
      "Epoch 15/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1586 - accuracy: 0.9391 - val_loss: 0.1597 - val_accuracy: 0.9402\n",
      "Epoch 16/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1561 - accuracy: 0.9401 - val_loss: 0.1575 - val_accuracy: 0.9409\n",
      "Epoch 17/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1538 - accuracy: 0.9411 - val_loss: 0.1555 - val_accuracy: 0.9419\n",
      "Epoch 18/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1518 - accuracy: 0.9420 - val_loss: 0.1536 - val_accuracy: 0.9419\n",
      "Epoch 19/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1497 - accuracy: 0.9429 - val_loss: 0.1518 - val_accuracy: 0.9427\n",
      "Epoch 20/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1478 - accuracy: 0.9437 - val_loss: 0.1499 - val_accuracy: 0.9441\n",
      "Epoch 21/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1459 - accuracy: 0.9446 - val_loss: 0.1484 - val_accuracy: 0.9446\n",
      "Epoch 22/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1441 - accuracy: 0.9453 - val_loss: 0.1468 - val_accuracy: 0.9452\n",
      "Epoch 23/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1423 - accuracy: 0.9463 - val_loss: 0.1451 - val_accuracy: 0.9453\n",
      "Epoch 24/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1406 - accuracy: 0.9470 - val_loss: 0.1435 - val_accuracy: 0.9459\n",
      "Epoch 25/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1389 - accuracy: 0.9477 - val_loss: 0.1421 - val_accuracy: 0.9467\n",
      "Epoch 26/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1372 - accuracy: 0.9485 - val_loss: 0.1405 - val_accuracy: 0.9474\n",
      "Epoch 27/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1355 - accuracy: 0.9494 - val_loss: 0.1389 - val_accuracy: 0.9479\n",
      "Epoch 28/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1338 - accuracy: 0.9502 - val_loss: 0.1374 - val_accuracy: 0.9482\n",
      "Epoch 29/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1321 - accuracy: 0.9510 - val_loss: 0.1360 - val_accuracy: 0.9489\n",
      "Epoch 30/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1305 - accuracy: 0.9519 - val_loss: 0.1345 - val_accuracy: 0.9498\n",
      "Epoch 31/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1288 - accuracy: 0.9526 - val_loss: 0.1329 - val_accuracy: 0.9505\n",
      "Epoch 32/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1271 - accuracy: 0.9535 - val_loss: 0.1314 - val_accuracy: 0.9510\n",
      "Epoch 33/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1254 - accuracy: 0.9540 - val_loss: 0.1299 - val_accuracy: 0.9520\n",
      "Epoch 34/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1236 - accuracy: 0.9550 - val_loss: 0.1282 - val_accuracy: 0.9523\n",
      "Epoch 35/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1219 - accuracy: 0.9560 - val_loss: 0.1269 - val_accuracy: 0.9535\n",
      "Epoch 36/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1201 - accuracy: 0.9565 - val_loss: 0.1249 - val_accuracy: 0.9539\n",
      "Epoch 37/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1183 - accuracy: 0.9577 - val_loss: 0.1233 - val_accuracy: 0.9545\n",
      "Epoch 38/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1164 - accuracy: 0.9586 - val_loss: 0.1216 - val_accuracy: 0.9553\n",
      "Epoch 39/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1145 - accuracy: 0.9594 - val_loss: 0.1197 - val_accuracy: 0.9567\n",
      "Epoch 40/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1126 - accuracy: 0.9606 - val_loss: 0.1181 - val_accuracy: 0.9564\n",
      "Epoch 41/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1106 - accuracy: 0.9613 - val_loss: 0.1162 - val_accuracy: 0.9572\n",
      "Epoch 42/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1086 - accuracy: 0.9623 - val_loss: 0.1145 - val_accuracy: 0.9579\n",
      "Epoch 43/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1066 - accuracy: 0.9632 - val_loss: 0.1124 - val_accuracy: 0.9587\n",
      "Epoch 44/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1046 - accuracy: 0.9643 - val_loss: 0.1105 - val_accuracy: 0.9597\n",
      "Epoch 45/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1025 - accuracy: 0.9652 - val_loss: 0.1086 - val_accuracy: 0.9609\n",
      "Epoch 46/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.1005 - accuracy: 0.9663 - val_loss: 0.1070 - val_accuracy: 0.9617\n",
      "Epoch 47/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0984 - accuracy: 0.9671 - val_loss: 0.1050 - val_accuracy: 0.9622\n",
      "Epoch 48/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0964 - accuracy: 0.9684 - val_loss: 0.1031 - val_accuracy: 0.9632\n",
      "Epoch 49/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0944 - accuracy: 0.9692 - val_loss: 0.1011 - val_accuracy: 0.9640\n",
      "Epoch 50/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0924 - accuracy: 0.9703 - val_loss: 0.0993 - val_accuracy: 0.9651\n",
      "Epoch 51/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0904 - accuracy: 0.9713 - val_loss: 0.0973 - val_accuracy: 0.9660\n",
      "Epoch 52/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0884 - accuracy: 0.9722 - val_loss: 0.0957 - val_accuracy: 0.9672\n",
      "Epoch 53/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0865 - accuracy: 0.9733 - val_loss: 0.0939 - val_accuracy: 0.9683\n",
      "Epoch 54/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0847 - accuracy: 0.9743 - val_loss: 0.0921 - val_accuracy: 0.9693\n",
      "Epoch 55/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0830 - accuracy: 0.9754 - val_loss: 0.0903 - val_accuracy: 0.9703\n",
      "Epoch 56/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0812 - accuracy: 0.9762 - val_loss: 0.0887 - val_accuracy: 0.9712\n",
      "Epoch 57/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0796 - accuracy: 0.9771 - val_loss: 0.0871 - val_accuracy: 0.9721\n",
      "Epoch 58/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0780 - accuracy: 0.9778 - val_loss: 0.0856 - val_accuracy: 0.9732\n",
      "Epoch 59/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0765 - accuracy: 0.9786 - val_loss: 0.0840 - val_accuracy: 0.9739\n",
      "Epoch 60/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0750 - accuracy: 0.9793 - val_loss: 0.0826 - val_accuracy: 0.9744\n",
      "Epoch 61/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0736 - accuracy: 0.9799 - val_loss: 0.0812 - val_accuracy: 0.9748\n",
      "Epoch 62/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0722 - accuracy: 0.9807 - val_loss: 0.0798 - val_accuracy: 0.9756\n",
      "Epoch 63/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0708 - accuracy: 0.9811 - val_loss: 0.0784 - val_accuracy: 0.9762\n",
      "Epoch 64/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0695 - accuracy: 0.9818 - val_loss: 0.0770 - val_accuracy: 0.9772\n",
      "Epoch 65/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0682 - accuracy: 0.9824 - val_loss: 0.0757 - val_accuracy: 0.9777\n",
      "Epoch 66/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0669 - accuracy: 0.9829 - val_loss: 0.0745 - val_accuracy: 0.9782\n",
      "Epoch 67/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0657 - accuracy: 0.9834 - val_loss: 0.0731 - val_accuracy: 0.9791\n",
      "Epoch 68/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0645 - accuracy: 0.9839 - val_loss: 0.0719 - val_accuracy: 0.9797\n",
      "Epoch 69/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0633 - accuracy: 0.9844 - val_loss: 0.0706 - val_accuracy: 0.9801\n",
      "Epoch 70/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0621 - accuracy: 0.9848 - val_loss: 0.0694 - val_accuracy: 0.9806\n",
      "Epoch 71/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0609 - accuracy: 0.9854 - val_loss: 0.0682 - val_accuracy: 0.9812\n",
      "Epoch 72/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0598 - accuracy: 0.9858 - val_loss: 0.0670 - val_accuracy: 0.9821\n",
      "Epoch 73/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0587 - accuracy: 0.9861 - val_loss: 0.0660 - val_accuracy: 0.9820\n",
      "Epoch 74/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0576 - accuracy: 0.9865 - val_loss: 0.0646 - val_accuracy: 0.9829\n",
      "Epoch 75/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0565 - accuracy: 0.9870 - val_loss: 0.0634 - val_accuracy: 0.9834\n",
      "Epoch 76/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0554 - accuracy: 0.9873 - val_loss: 0.0622 - val_accuracy: 0.9840\n",
      "Epoch 77/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0543 - accuracy: 0.9876 - val_loss: 0.0610 - val_accuracy: 0.9847\n",
      "Epoch 78/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0533 - accuracy: 0.9880 - val_loss: 0.0599 - val_accuracy: 0.9850\n",
      "Epoch 79/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0522 - accuracy: 0.9883 - val_loss: 0.0588 - val_accuracy: 0.9858\n",
      "Epoch 80/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0512 - accuracy: 0.9887 - val_loss: 0.0576 - val_accuracy: 0.9862\n",
      "Epoch 81/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0502 - accuracy: 0.9891 - val_loss: 0.0565 - val_accuracy: 0.9865\n",
      "Epoch 82/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0492 - accuracy: 0.9895 - val_loss: 0.0555 - val_accuracy: 0.9866\n",
      "Epoch 83/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0482 - accuracy: 0.9898 - val_loss: 0.0543 - val_accuracy: 0.9873\n",
      "Epoch 84/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0472 - accuracy: 0.9901 - val_loss: 0.0532 - val_accuracy: 0.9876\n",
      "Epoch 85/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0462 - accuracy: 0.9903 - val_loss: 0.0521 - val_accuracy: 0.9879\n",
      "Epoch 86/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0453 - accuracy: 0.9907 - val_loss: 0.0510 - val_accuracy: 0.9882\n",
      "Epoch 87/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0444 - accuracy: 0.9909 - val_loss: 0.0500 - val_accuracy: 0.9886\n",
      "Epoch 88/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0435 - accuracy: 0.9912 - val_loss: 0.0491 - val_accuracy: 0.9888\n",
      "Epoch 89/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0426 - accuracy: 0.9915 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "Epoch 90/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0417 - accuracy: 0.9917 - val_loss: 0.0471 - val_accuracy: 0.9894\n",
      "Epoch 91/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0409 - accuracy: 0.9919 - val_loss: 0.0462 - val_accuracy: 0.9898\n",
      "Epoch 92/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0401 - accuracy: 0.9922 - val_loss: 0.0452 - val_accuracy: 0.9901\n",
      "Epoch 93/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0393 - accuracy: 0.9923 - val_loss: 0.0443 - val_accuracy: 0.9903\n",
      "Epoch 94/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0384 - accuracy: 0.9926 - val_loss: 0.0434 - val_accuracy: 0.9903\n",
      "Epoch 95/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0377 - accuracy: 0.9928 - val_loss: 0.0426 - val_accuracy: 0.9906\n",
      "Epoch 96/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0369 - accuracy: 0.9931 - val_loss: 0.0418 - val_accuracy: 0.9908\n",
      "Epoch 97/100\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.0362 - accuracy: 0.9933 - val_loss: 0.0410 - val_accuracy: 0.9909\n",
      "Epoch 98/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0354 - accuracy: 0.9934 - val_loss: 0.0402 - val_accuracy: 0.9915\n",
      "Epoch 99/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0347 - accuracy: 0.9937 - val_loss: 0.0395 - val_accuracy: 0.9916\n",
      "Epoch 100/100\n",
      "1400/1400 [==============================] - 1s 1ms/step - loss: 0.0341 - accuracy: 0.9938 - val_loss: 0.0388 - val_accuracy: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–â–‚â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–ˆâ–‡â–†â–†â–†â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–â–â–„â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‡â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–â–ƒâ–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‡â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.9938</td></tr><tr><td>batch/batch_step</td><td>139995</td></tr><tr><td>batch/learning_rate</td><td>1e-05</td></tr><tr><td>batch/loss</td><td>0.03408</td></tr><tr><td>epoch/accuracy</td><td>0.9938</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>1e-05</td></tr><tr><td>epoch/loss</td><td>0.03408</td></tr><tr><td>epoch/val_accuracy</td><td>0.99155</td></tr><tr><td>epoch/val_loss</td><td>0.0388</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Trial_50</strong> at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/6bhy1qq5' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/6bhy1qq5</a><br> View project at: <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251014_082331-6bhy1qq5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 08:26:03,441] Trial 50 finished with value: 0.03832869566977024 and parameters: {'Layer_1_units': 77, 'Activation_1': 'relu', 'n_layers': 2, 'Layer_2_units': 104, 'Activation_2': 'relu', 'Layer_3_units': 76, 'Activation_3': 'sigmoid', 'learning_rate': 1.077698412678219e-05, 'optimizer': 'rmsprop', 'batch_size': 100}. Best is trial 44 with value: 0.0021604654146358373.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Global-House-Purchase-Decision-ANN/wandb/run-20251014_082603-02qsm39o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/02qsm39o' target=\"_blank\">Trial_51</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/02qsm39o' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Global-House-Purchase-Decision-ANN-Trials-3/runs/02qsm39o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 7s 950us/step - loss: 0.0585 - accuracy: 0.9789 - val_loss: 0.0435 - val_accuracy: 0.9882\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 0.0131 - val_accuracy: 0.9966\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 7s 940us/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0147 - val_accuracy: 0.9961\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 7s 954us/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0111 - val_accuracy: 0.9967\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.0099 - val_accuracy: 0.9972\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0058 - val_accuracy: 0.9980\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0073 - val_accuracy: 0.9976\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0080 - val_accuracy: 0.9975\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0103 - val_accuracy: 0.9969\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0107 - val_accuracy: 0.9966\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0120 - val_accuracy: 0.9965\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0066 - val_accuracy: 0.9977\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0130 - val_accuracy: 0.9962\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0067 - val_accuracy: 0.9974\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0068 - val_accuracy: 0.9977\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0247 - val_accuracy: 0.9943\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0089 - val_accuracy: 0.9972\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 6s 928us/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0058 - val_accuracy: 0.9978\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0062 - val_accuracy: 0.9981\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 7s 931us/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0066 - val_accuracy: 0.9980\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 7s 939us/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0070 - val_accuracy: 0.9977\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 7s 930us/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0057 - val_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 7s 929us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0044 - val_accuracy: 0.9985\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 7s 933us/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0086 - val_accuracy: 0.9972\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 7s 929us/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0081 - val_accuracy: 0.9977\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 6s 926us/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0068 - val_accuracy: 0.9979\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 0.9973\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0052 - val_accuracy: 0.9979\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 7s 988us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0050 - val_accuracy: 0.9980\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 7s 963us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 7s 958us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0052 - val_accuracy: 0.9982\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0052 - val_accuracy: 0.9980\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 26s 4ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0064 - val_accuracy: 0.9976\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 25s 3ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0067 - val_accuracy: 0.9976\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 7s 968us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 7s 968us/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 7s 960us/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 7s 977us/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0070 - val_accuracy: 0.9979\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 7s 970us/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0048 - val_accuracy: 0.9982\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 7s 955us/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 0.9980\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 298s 43ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 26s 4ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0061 - val_accuracy: 0.9980\n",
      "Epoch 46/100\n",
      "6001/7000 [========================>.....] - ETA: 34s - loss: 0.0022 - accuracy: 0.9993"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name = \"Proyecto\", direction = \"minimize\")\n",
    "study.optimize(objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NÃºmero de pruebas terminadas: \", len(study.trials))\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"Mejor intento: \", trial)\n",
    "\n",
    "print(\"Valor: \", trial.value)\n",
    "print(\"HiperparÃ¡metros: \", trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(study.trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
