{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras import regularizers, models, layers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `wandb.require('core')` is a no-op as it is now the default behavior.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import optuna\n",
    "\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint, WandbCallback\n",
    "\n",
    "wandb.require(\"core\")\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de los datos\n",
    "\n",
    "ds = pd.read_csv(\"/global_house_purchase_dataset.csv\")\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaN values: \\n \\n \", ds.isna().sum(),\n",
    "      \"\\n \\n Types: \\n \\n\", ds.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize = (10,10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "sns.countplot(ds, x = \"country\", color = \"purple\", ax = axes[0])\n",
    "axes[0].tick_params(axis=\"x\", rotation=90)\n",
    "axes[0].set_title(\"country\")\n",
    "\n",
    "sns.countplot(ds, x = \"city\", color = \"grey\", ax = axes[1])\n",
    "axes[1].tick_params(rotation = 90)\n",
    "axes[1].set_title(\"city\")\n",
    "\n",
    "sns.countplot(ds, x = \"property_type\", color = \"orange\", ax = axes[2])\n",
    "axes[2].tick_params(rotation = 90)\n",
    "axes[2].set_title(\"property_type\")\n",
    "\n",
    "sns.countplot(ds, x = \"furnishing_status\", color = \"green\", ax = axes[3])\n",
    "axes[3].tick_params(rotation = 90)\n",
    "axes[3].set_title(\"furnishing_status\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "\n",
    "ds = pd.get_dummies(ds, columns = [\"country\", \"city\", \"property_type\", \"furnishing_status\"],\n",
    "                            drop_first = False)\n",
    "ds.drop(\"property_id\", axis = 1, inplace = True)\n",
    "ds = ds.astype(\"float32\")\n",
    "\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n \\n Types: \\n \\n\", ds.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = ds.drop(\"decision\", axis=1)\n",
    "y = ds[\"decision\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(x, y, test_size = 0.3, random_state = 5)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size = 1/3, random_state = 5)\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Validation size:\", len(X_val))\n",
    "print(\"Test size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Optuna suggest activation function and neurons for the first layer\n",
    "    \n",
    "    n_units1 = trial.suggest_int(\"Layer_1\", 32, 128)\n",
    "    \n",
    "    Activation_1_options = [\"sigmoid\", \"relu\"]\n",
    "    Activation_1 = trial.suggest_categorical(\"Activation_1\", Activation_1_options)\n",
    "\n",
    "    if Activation_1 == \"sigmoid\":\n",
    "        model.add(layers.Dense(n_units1, activation = \"sigmoid\", input_shape=(X_train.shape[1],)))\n",
    "\n",
    "    elif Activation_1 == \"relu\":\n",
    "        model.add(layers.Dense(n_units1, activation = \"relu\", input_shape=(X_train.shape[1],)))\n",
    "    \n",
    "    # Optuna suggest number of layers\n",
    "    \n",
    "    n_layers = trial.suggest_int(\"n_layers\", 10, 20)\n",
    "\n",
    "    # Optuna suggests number of neurons and activation function per layer\n",
    "    \n",
    "    units_per_layer = [n_units1]\n",
    "    function_per_layer = [Activation_1]\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        \n",
    "        n_units = trial.suggest_int(f\"Neurons in layer_{i}\", 32, 128)\n",
    "        \n",
    "        function_options = [\"sigmoid\", \"relu\"]\n",
    "        function_selected = trial.suggest_categorical(f\"Activation_{i}\", function_options)\n",
    "        \n",
    "        units_per_layer.append(n_units)\n",
    "        function_per_layer.append(function_selected)\n",
    "\n",
    "        if function_selected == \"sigmoid\":\n",
    "            model.add(layers.Dense(n_units, activation = \"sigmoid\"))\n",
    "\n",
    "        elif function_selected == \"relu\":\n",
    "            model.add(layers.Dense(n_units, activation = \"relu\"))\n",
    "    \n",
    "    model.add(layers.Dense(16, activation = \"softmax\"))\n",
    "    model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "    \n",
    "    units_per_layer += [16, 1]\n",
    "    function_per_layer += [\"softmax\", \"sigmoid\"]\n",
    "\n",
    "    # Optuna suggests learning rate\n",
    "\n",
    "    lr = trial.suggest_float(\"Learning_rate\", 1e-5, 1e-1, log = True)\n",
    "\n",
    "    # Optuna suggests optimizer\n",
    "    \n",
    "    optimizer_options = [\"sgd\", \"adam\", \"rmsprop\"]\n",
    "    optimizer_selected = trial.suggest_categorical(\"Optimizer\", optimizer_options)\n",
    "\n",
    "    if optimizer_selected == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "\n",
    "    elif optimizer_selected == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate = lr)\n",
    "\n",
    "    elif optimizer_selected == \"rmsprop\":\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate = lr)\n",
    "        \n",
    "    # Optuna suggests batch size\n",
    "    \n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [20, 40, 50, 100])\n",
    "        \n",
    "    wandb.init(\n",
    "        project = \"Global-House-Purchase-Decision-ANN-Trials-2\",\n",
    "        name = f\"Trial_{trial.number}\",\n",
    "        reinit=True,\n",
    "        config = {\n",
    "            \"N_layers\": n_layers,\n",
    "            \"Units_per_layer\": units_per_layer,\n",
    "            \"Activations_per_layer\": function_per_layer,\n",
    "            \"Learning_rate\": lr,\n",
    "            \"batch_size\": batch_size\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Compilamos el modelo\n",
    "\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = \"binary_crossentropy\",\n",
    "                  metrics = [\"accuracy\"])\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs = 100, batch_size = batch_size,\n",
    "              callbacks = [WandbMetricsLogger(log_freq = 5)],\n",
    "              verbose = 1)\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    val_loss = min(model.history[\"val_loss\"])\n",
    "    train_loss = min(model.history[\"loss\"])\n",
    "    score = val_loss + 0.1 * (train_loss - val_loss) # Para penalizar el overfitting\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(study_name = \"Proyecto\", direction = \"minimize\")\n",
    "study.optimize(objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número de pruebas terminadas: \", len(study.trials))\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"Mejor intento: \", trial)\n",
    "\n",
    "print(\"Valor: \", trial.value)\n",
    "print(\"Hiperparámetros: \", trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(study.trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
